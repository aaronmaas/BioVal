{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e5de916",
   "metadata": {},
   "source": [
    "# Biorepsoitory Validation Code - BioVal \n",
    "\n",
    "Code validates individually the current redcap repository and the biorep data intended to be uploaded.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f397938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLOBAL PARAMS\n",
    "\n",
    "REQUIRED_FIELDS = [\n",
    "    \"pat_id\",    #does sophie use this? yes! we want to use this but need to find a solution here\n",
    "    \"redcap_event_name\",\n",
    "    \"visit_date\",\n",
    "    \"material\",\n",
    "    \"pos\",\n",
    "    \"tube_id\",\n",
    "    \"box_id\",\n",
    "    \"freezer\",\n",
    "    \"rack\",\n",
    "    \"box\",\n",
    "    \"inf_deseas\"\n",
    "]\n",
    "\n",
    "#Biorep Sampel Materials\n",
    "VALID_MATERIALS = [\n",
    "    \"CSF\", \"CSF Pellet\", \"DNA\", \"EDTA Plasma\", \"Fibroblasten\",\n",
    "    \"PAXgene\", \"PBMC\", \"Serum\", \"Urin\"\n",
    "]\n",
    "\n",
    "VALID_EVENTS = [\"baseline_arm_1\", \"screening_arm_1\", \"follow_up_arm_1\"]\n",
    "\n",
    "# Allowed matrices (positions) per material\n",
    "VALID_POS_FLUIDS = [f\"{row}{col}\" for row in \"ABCDEFGH\" for col in range(1, 13)]\n",
    "VALID_POS_PAXGENE = [f\"{row}{col}\" for row in \"ABCDEFG\" for col in range(1, 8)]\n",
    "VALID_POS_DNA_CELLS_PBMC =  [f\"{row}{col}\" for row in \"ABCDEFGHJ\" for col in range(1, 11)]\n",
    "\n",
    "# Freezers\n",
    "VALID_FREEZER = [\"1\", \"2\", \"3\", \"nitrogen\", \"4deg\"]\n",
    "\n",
    "# Boxes (same for all, unless exception later)\n",
    "VALID_BOX = [str(i) for i in range(1, 43)]  # 1–42\n",
    "\n",
    "# Racks\n",
    "VALID_RACK = [str(i) for i in range(1, 101)]  # 1–100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f2e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import re\n",
    "\n",
    "# --- Define allowed values and required fields ---\n",
    "\n",
    "REQUIRED_FIELDS = [\n",
    "    \"pat_id\", \"redcap_event_name\", \"visit_date\", \"material\", \"pos\",\n",
    "    \"tube_id\", \"box_id\", \"freezer\", \"rack\", \"box\"\n",
    "]\n",
    "\n",
    "VALID_MATERIALS = [\n",
    "    \"csf\", \"csf pellet\", \"dna\", \"edta plasma\", \"fibroblasten\",\n",
    "    \"paxgene\", \"pbmc\", \"serum\", \"urin\"\n",
    "]\n",
    "\n",
    "### Unterschied zwischen Biofluids und Cells \n",
    "\"\"\"\n",
    "Biofluids: CSF (Cerebrospinalfluid), EDTA Plasam (Also nicht geronnen), Serum (geronnen abzentrifugiert), Urin, CSF Pellets\n",
    "Cells: Fibroblasten, PBMC (Peripher mononukläre Blutzellen)?, \n",
    "Other: DNA, PAXgene (RNA)\n",
    "\n",
    "Specific Fluids/Cells go into specific locations. \n",
    "\"\"\"\n",
    "\n",
    "### Für Positions: \n",
    "\"\"\"\n",
    "Für die Biofluids gibt es pro Rack (Gestell); 7 Schubladen a 6 Boxpositionen; die Boxen haben dann widerum ABCDEFGH 1-12. \n",
    "\n",
    "Variable\tWertbeispiel\tBedeutung\n",
    "pos\tB3\tRaster-Position in der Box\n",
    "tube_id\t20250123-1\tEindeutige Probenkennung\n",
    "box_id\tBX-00017\tBox-Nummer\n",
    "freezer\t2\tTiefkühler Nummer 2\n",
    "rack\t14\tRack (Gestell) Nummer 14 im Schrank\n",
    "box\t31\tBox Nummer 31 im Rack (die Schulade wird nicht spezifisch genannt)\n",
    "A1-H12\tD7\tAlternative Positionsangabe in 96er-Box\n",
    "nitrogen\t-\tLagerort im Stickstofftank (anstelle von „freezer“)\n",
    "\n",
    "Ok box meint die position 1-42 im Rack.!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Positions A1–H12 (plate layout)\n",
    "#VALID_POS = [f\"{row}{col}\" for row in \"ABCDEFGH\" for col in range(1, 13)]\n",
    "#VALID_RACK = list(map(str, range(1, 101)))  # 1–100\n",
    "#VALID_BOX = [f\"{box}\" for box in range(1,43)] #42 positions per Rack\n",
    "#VALID_FREEZER = [\"1\", \"2\", \"3\", \"nitrogen\"]\n",
    "VALID_EVENTS = [\"baseline_arm_1\", \"screening_arm_1\", \"follow_up_arm_1\"]\n",
    "\n",
    "# Allowed matrices (positions) per material\n",
    "VALID_POS_FLUIDS = [f\"{row}{col}\" for row in \"ABCDEFGH\" for col in range(1, 13)]\n",
    "VALID_POS_PAXGENE = [f\"{row}{col}\" for row in \"ABCDEFG\" for col in range(1, 8)]\n",
    "VALID_POS_DNA_CELLS_PBMC =  [f\"{row}{col}\" for row in \"ABCDEFGHJ\" for col in range(1, 11)]\n",
    "\n",
    "# Freezers\n",
    "VALID_FREEZER = [\"1\", \"2\", \"3\", \"nitrogen\", \"4deg\"]\n",
    "\n",
    "# Boxes (same for all, unless exception later)\n",
    "VALID_BOX = [str(i) for i in range(1, 43)]  # 1–42\n",
    "\n",
    "# Racks\n",
    "VALID_RACK = [str(i) for i in range(1, 101)]  # 1–100\n",
    "\n",
    "# === Functions ===\n",
    "\n",
    "def read_csv(path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns its headers and row data.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the CSV file\n",
    "\n",
    "    Returns:\n",
    "        tuple: (List[str] headers, List[Dict] rows)\n",
    "    \"\"\"\n",
    "    with open(path, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        rows = list(reader)\n",
    "    return reader.fieldnames, rows\n",
    "\n",
    "\n",
    "def check_structure(headers):\n",
    "    \"\"\"\n",
    "    Checks whether all required fields are present in the CSV headers.\n",
    "\n",
    "    Args:\n",
    "        headers (List[str]): Column headers from the CSV\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of missing required fields (if any)\n",
    "    \"\"\"\n",
    "    missing = [field for field in REQUIRED_FIELDS if field not in headers]\n",
    "    return missing\n",
    "\n",
    "\n",
    "def validate_row_v0(row, index):\n",
    "    \"\"\"\n",
    "    Old version\n",
    "    Validates a single row for required values and correct formats.\n",
    "\n",
    "    Args:\n",
    "        row (Dict): A row from the CSV as a dictionary\n",
    "        index (int): The row number (for error reporting)\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of validation error messages for this row\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "\n",
    "    # Check if all required fields are non-empty\n",
    "    for field in REQUIRED_FIELDS:\n",
    "        if row.get(field, \"\").strip() == \"\":\n",
    "            errors.append(f\"Row {index}: Missing value in '{field}'\")\n",
    "\n",
    "    ######## General Validation - is everything there?         \n",
    "            \n",
    "    # Validate pat_id format (3x alphanumeric with spaces)\n",
    "    pat_id = row.get(\"pat_id\", \"\").strip()\n",
    "    if pat_id and not re.match(r\"^[A-Za-z0-9]{3} [A-Za-z0-9]{3} [A-Za-z0-9]{3}$\", pat_id):\n",
    "        errors.append(f\"Row {index}: Invalid pat_id format: '{pat_id}'\")\n",
    "        #that is not necessary anymore sophie will use something else\n",
    "\n",
    "    # Validate other fields only if they're present\n",
    "    if row.get(\"material\") and row[\"material\"] not in VALID_MATERIALS:\n",
    "        errors.append(f\"Row {index}: Invalid material: '{row['material']}'\")\n",
    "\n",
    "    if row.get(\"pos\") and row[\"pos\"] not in VALID_POS:\n",
    "        errors.append(f\"Row {index}: Invalid pos: '{row['pos']}'\")\n",
    "\n",
    "    if row.get(\"freezer\") and row[\"freezer\"] not in VALID_FREEZER:\n",
    "        errors.append(f\"Row {index}: Invalid freezer: '{row['freezer']}'\")\n",
    "\n",
    "    if row.get(\"rack\") and row[\"rack\"] not in VALID_RACK:\n",
    "        errors.append(f\"Row {index}: Invalid rack: '{row['rack']}'\")\n",
    "\n",
    "    if row.get(\"box\") and row[\"box\"] not in VALID_BOX:\n",
    "        errors.append(f\"Row {index}: Invalid box: '{row['box']}'\")\n",
    "\n",
    "    if row.get(\"redcap_event_name\") and row[\"redcap_event_name\"] not in VALID_EVENTS:\n",
    "        errors.append(f\"Row {index}: Invalid redcap_event_name: '{row['redcap_event_name']}'\")\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "# === Material → Freezer mapping === Import for sepparation of the different materials\n",
    "BIOFLUIDS = [\"urin\", \"edta plasma\", \"serum\", \"csf\", \"csf pellet\"]\n",
    "PAXGENE = [\"paxgene\"]\n",
    "DNA = [\"dna\"]\n",
    "CELLS = [\"fibroblasten\", \"pbmc\"]\n",
    "\n",
    "#lets normalize to lower case\n",
    "\n",
    "MATERIAL_TO_FREEZER = {\n",
    "    **{m: [\"1\", \"2\", \"3\"] for m in BIOFLUIDS},   # Biofluids → -80 freezers\n",
    "    **{m: [\"nitrogen\"] for m in CELLS},          # Cells → nitrogen\n",
    "    **{m: [\"4deg\"] for m in DNA},                # DNA -> 4 Deg freezer\n",
    "    **{m: [\"1\", \"2\", \"3\"] for m in PAXGENE}      # Paxgene -> -80 freezers\n",
    "}\n",
    "\n",
    "def validate_row_v1(row, index):\n",
    "    \"\"\"\n",
    "    Validates a single row for required values and correct formats.\n",
    "\n",
    "    Args:\n",
    "        row (Dict): A row from the CSV as a dictionary\n",
    "        index (int): The row number (for error reporting)\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of validation error messages for this row\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "\n",
    "    # Check if all required fields are non-empty\n",
    "    for field in REQUIRED_FIELDS:\n",
    "        if row.get(field, \"\").strip() == \"\":\n",
    "            errors.append(f\"Row {index}: Missing value in '{field}'\")\n",
    "\n",
    "    ######## General Validation ########\n",
    "            \n",
    "    # Validate pat_id format (DISABLED if Sophie will use different format)\n",
    "    # pat_id = row.get(\"pat_id\", \"\").strip()\n",
    "    # if pat_id and not re.match(r\"^[A-Za-z0-9]{3} [A-Za-z0-9]{3} [A-Za-z0-9]{3}$\", pat_id):\n",
    "    #     errors.append(f\"Row {index}: Invalid pat_id format: '{pat_id}'\")\n",
    "\n",
    "    # Validate material\n",
    "    if row.get(\"material\") and row[\"material\"] not in VALID_MATERIALS:\n",
    "        errors.append(f\"Row {index}: Invalid material: '{row['material']}'\")\n",
    "\n",
    "    # Validate pos\n",
    "    if row.get(\"pos\") and row[\"pos\"] not in VALID_POS:\n",
    "        errors.append(f\"Row {index}: Invalid pos: '{row['pos']}'\")\n",
    "\n",
    "    # Validate freezer\n",
    "    if row.get(\"freezer\") and row[\"freezer\"] not in VALID_FREEZER:\n",
    "        errors.append(f\"Row {index}: Invalid freezer: '{row['freezer']}'\")\n",
    "\n",
    "    # Validate rack\n",
    "    if row.get(\"rack\") and row[\"rack\"] not in VALID_RACK:\n",
    "        errors.append(f\"Row {index}: Invalid rack: '{row['rack']}'\")\n",
    "\n",
    "    # Validate box\n",
    "    if row.get(\"box\") and row[\"box\"] not in VALID_BOX:\n",
    "        errors.append(f\"Row {index}: Invalid box: '{row['box']}'\")\n",
    "\n",
    "    # Validate event name\n",
    "    if row.get(\"redcap_event_name\") and row[\"redcap_event_name\"] not in VALID_EVENTS:\n",
    "        errors.append(f\"Row {index}: Invalid redcap_event_name: '{row['redcap_event_name']}'\")\n",
    "\n",
    "    ######## Material-specific Freezer Rule ########\n",
    "    material = row.get(\"material\", \"\").strip()\n",
    "    freezer = row.get(\"freezer\", \"\").strip()\n",
    "\n",
    "    if material and freezer:\n",
    "        allowed_freezers = MATERIAL_TO_FREEZER.get(material, [])\n",
    "        if allowed_freezers and freezer not in allowed_freezers:\n",
    "            errors.append(\n",
    "                f\"Row {index}: Invalid freezer '{freezer}' for material '{material}'. \"\n",
    "                f\"Allowed freezers: {allowed_freezers}\"\n",
    "            )\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "def validate_row(row, index):\n",
    "    errors = []\n",
    "\n",
    "    # --- Required fields ---\n",
    "    for field in REQUIRED_FIELDS:\n",
    "        if row.get(field, \"\").strip() == \"\":\n",
    "            errors.append(f\"Row {index}: Missing value in '{field}'\")\n",
    "\n",
    "    # --- Get material ---\n",
    "    material = row.get(\"material\", \"\").strip().lower()\n",
    "    pos = row.get(\"pos\", \"\").strip()\n",
    "    freezer = row.get(\"freezer\", \"\").strip()\n",
    "    rack = row.get(\"rack\", \"\").strip()\n",
    "    box = row.get(\"box\", \"\").strip()\n",
    "    # --- Material-specific storage rules ---\n",
    "    if material in BIOFLUIDS:  # fluids\n",
    "        if pos not in VALID_POS_FLUIDS:\n",
    "            errors.append(f\"Row {index}: Invalid pos '{pos}' for {material} (must be A1–H10)\")\n",
    "        if freezer not in [\"1\", \"2\", \"3\"]:\n",
    "            errors.append(f\"Row {index}: {material} must be stored in -80 freezers (1–3).\")\n",
    "\n",
    "    elif material in PAXGENE:\n",
    "        if pos not in VALID_POS_PAXGENE:\n",
    "            errors.append(f\"Row {index}: Invalid pos '{pos}' for PAXgene (must be A1–G7)\")\n",
    "        if freezer not in [\"1\", \"2\", \"3\"]:\n",
    "            errors.append(f\"Row {index}: PAXgene must be stored in -80 freezers (1–3).\")\n",
    "\n",
    "    elif material in DNA:\n",
    "        if pos not in VALID_POS_DNA_CELLS_PBMC:\n",
    "            errors.append(f\"Row {index}: Invalid pos '{pos}' for DNA (must be A1–J10)\")\n",
    "        if freezer != \"4deg\":\n",
    "            errors.append(f\"Row {index}: DNA must be stored in 4-degree freezer.\")\n",
    "\n",
    "    elif material in CELLS:\n",
    "        if pos not in VALID_POS_DNA_CELLS_PBMC:\n",
    "            errors.append(f\"Row {index}: Invalid pos '{pos}' for {material} (must be A1–J10)\")\n",
    "        if freezer != \"nitrogen\":\n",
    "            errors.append(f\"Row {index}: {material} must be stored in nitrogen tank.\")\n",
    "\n",
    "    else:\n",
    "        errors.append(f\"Row {index}: Unknown or unsupported material '{material}'\")\n",
    "        \n",
    "    #Fängt Material ab\n",
    "\n",
    "    # --- General checks still valid ---\n",
    "    if rack and rack not in VALID_RACK:\n",
    "        errors.append(f\"Row {index}: Invalid rack '{rack}'\")\n",
    "\n",
    "    if box and box not in VALID_BOX:\n",
    "        errors.append(f\"Row {index}: Invalid box '{box}'\")\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "\n",
    "def validate_file_v1(path, label):\n",
    "    \"\"\"\n",
    "    Validates an entire CSV file for structure and row-level values.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the CSV file\n",
    "        label (str): Descriptive label (e.g. \"Import file\")\n",
    "\n",
    "    Returns:\n",
    "        None – exits with error if validation fails\n",
    "    \"\"\"\n",
    "    print(f\" Checking {label}: {path}\")\n",
    "    headers, rows = read_csv(path)\n",
    "\n",
    "    # Check for required column headers\n",
    "    structure_errors = check_structure(headers)\n",
    "    if structure_errors:\n",
    "        print(f\" Missing required columns in {label}: {structure_errors}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Validate each row\n",
    "    all_errors = []\n",
    "    for i, row in enumerate(rows, start=2):  # Line 1 is header\n",
    "        #calls validate row in for loop\n",
    "        row_errors = validate_row(row, i)\n",
    "        all_errors.extend(row_errors)\n",
    "    \n",
    "    #returns evaluation errors if any of the above occurs\n",
    "    if all_errors:\n",
    "        print(f\" {len(all_errors)} validation error(s) in {label}:\")  ##mach hier auch eher ein error rais\n",
    "        for e in all_errors:\n",
    "            print(\" -\", e)\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(f\" {label} passed all validation checks.\\n\")\n",
    "        \n",
    "        \n",
    "def validate_file(path, label):\n",
    "    \"\"\"\n",
    "    Validates an entire CSV file and raises ValueError if anything is wrong.\n",
    "    \"\"\"\n",
    "    print(f\" Checking {label}: {path}\")\n",
    "    headers, rows = read_csv(path)\n",
    "\n",
    "    # Check for required column headers\n",
    "    structure_errors = check_structure(headers)\n",
    "    if structure_errors:\n",
    "        raise ValueError(f\"Missing required columns in {label}: {structure_errors}\")\n",
    "\n",
    "    # Validate each row\n",
    "    for i, row in enumerate(rows, start=2):\n",
    "        validate_row(row, i)  # will raise immediately if invalid\n",
    "\n",
    "    print(f\" {label} passed all validation checks.\\n\")\n",
    "    return rows  # return rows if valid\n",
    "\n",
    "\n",
    "\n",
    "def get_occupied_positions(rows):\n",
    "    \"\"\"\n",
    "    Extracts all occupied positions from a list of data rows.\n",
    "\n",
    "    Args:\n",
    "        rows (List[Dict]): Data rows (e.g. from reference file)\n",
    "\n",
    "    Returns:\n",
    "        Set[Tuple[str, str, str, str]]: Set of (freezer, rack, box, pos)\n",
    "    \"\"\"\n",
    "    positions = set()\n",
    "    for row in rows:\n",
    "        key = (\n",
    "            row.get(\"freezer\", \"\").strip(),\n",
    "            row.get(\"rack\", \"\").strip(),\n",
    "            row.get(\"box\", \"\").strip(),\n",
    "            row.get(\"pos\", \"\").strip(),\n",
    "        )\n",
    "        if all(key):\n",
    "            positions.add(key)\n",
    "    return positions\n",
    "\n",
    "\n",
    "def check_duplicate_positions_v1(import_rows, occupied_positions):\n",
    "    \"\"\"\n",
    "    Compares import rows against existing positions and raises errors for conflicts.\n",
    "\n",
    "    Args:\n",
    "        import_rows (List[Dict]): Rows from the import file\n",
    "        occupied_positions (Set[Tuple]): Set of existing (freezer, rack, box, pos)\n",
    "\n",
    "    Returns:\n",
    "        None – prints and exits if duplicates are found\n",
    "    \"\"\"\n",
    "    duplicate_count = 0\n",
    "    for i, row in enumerate(import_rows, start=2):\n",
    "        key = (\n",
    "            row.get(\"freezer\", \"\").strip(),\n",
    "            row.get(\"rack\", \"\").strip(),\n",
    "            row.get(\"box\", \"\").strip(),\n",
    "            row.get(\"pos\", \"\").strip(),\n",
    "        )\n",
    "        if key in occupied_positions:\n",
    "            print(f\"Row {i}: Position {key} is already occupied in existing data.\")\n",
    "            duplicate_count += 1\n",
    "\n",
    "    if duplicate_count == 0:\n",
    "        print(\"No duplicate positions found between import and reference data.\")\n",
    "    else:\n",
    "        print(f\"{duplicate_count} duplicate position error(s) found.\")\n",
    "    return duplicate_count\n",
    "\n",
    "\n",
    "def check_duplicate_positions(import_rows, occupied_positions, label=\"Import vs Reference\"):\n",
    "    \"\"\"\n",
    "    Compares import rows against existing positions and raises errors for conflicts.\n",
    "\n",
    "    Args:\n",
    "        import_rows (List[Dict]): Rows from the import file\n",
    "        occupied_positions (Set[Tuple]): Set of existing (freezer, rack, box, pos)\n",
    "        label (str): Descriptive name for error reporting\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if duplicate positions are found\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    for i, row in enumerate(import_rows, start=2):\n",
    "        key = (\n",
    "            row.get(\"freezer\", \"\").strip(),\n",
    "            row.get(\"rack\", \"\").strip(),\n",
    "            row.get(\"box\", \"\").strip(),\n",
    "            row.get(\"pos\", \"\").strip(),\n",
    "        )\n",
    "        if key in occupied_positions:\n",
    "            errors.append(f\"Row {i}: Position {key} is already occupied in reference data.\")\n",
    "\n",
    "    if errors:\n",
    "        raise ValueError(f\"{label} – {len(errors)} duplicate position error(s):\\n\" + \"\\n\".join(errors))\n",
    "    else:\n",
    "        print(f\"No duplicate positions found between import and reference data.\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "def check_internal_duplicates(rows, label):\n",
    "    \"\"\"\n",
    "    Checks for duplicate positions within a single file (usually the reference data).\n",
    "\n",
    "    Args:\n",
    "        rows (List[Dict]): Rows to check\n",
    "        label (str): Descriptive name for error output\n",
    "\n",
    "    Returns:\n",
    "        None – prints warning and exits if internal duplicates found\n",
    "    \"\"\"\n",
    "    position_map = {}\n",
    "\n",
    "    for i, row in enumerate(rows, start=2):  # row index starts from line 2\n",
    "        key = (\n",
    "            row.get(\"freezer\", \"\").strip(),\n",
    "            row.get(\"rack\", \"\").strip(),\n",
    "            row.get(\"box\", \"\").strip(),\n",
    "            row.get(\"pos\", \"\").strip(),\n",
    "        )\n",
    "\n",
    "        if all(key):\n",
    "            position_map.setdefault(key, []).append(i)\n",
    "\n",
    "    # Look for positions used more than once\n",
    "    duplicates = {k: v for k, v in position_map.items() if len(v) > 1}\n",
    "    if duplicates:\n",
    "        details = \"\\n\".join([f\" - Position {k} found on rows {v}\" for k, v in duplicates.items()])\n",
    "        raise ValueError(f\"Duplicate positions found within {label}:\\n{details}\")\n",
    "    else:\n",
    "        print(f\"No duplicate positions found within {label}.\")\n",
    "        \n",
    "    return \n",
    "\n",
    "def check_internal_tube_id_duplicates(rows, label):\n",
    "    \"\"\"\n",
    "    Checks for duplicate tube_id values within a single dataset (e.g. the reference file).\n",
    "\n",
    "    Args:\n",
    "        rows (List[Dict]): Data rows to check\n",
    "        label (str): Name of the file being checked (for reporting)\n",
    "\n",
    "    Returns:\n",
    "        None – exits if duplicates are found\n",
    "    \"\"\"\n",
    "    tube_id_map = {}\n",
    "\n",
    "    for i, row in enumerate(rows, start=2):\n",
    "        tid = row.get(\"tube_id\", \"\").strip()\n",
    "        if tid:\n",
    "            tube_id_map.setdefault(tid, []).append(i)\n",
    "\n",
    "    duplicates = {tid: idxs for tid, idxs in tube_id_map.items() if len(idxs) > 1}\n",
    "\n",
    "    if duplicates:\n",
    "        print(f\"Duplicate tube_id(s) found in {label}:\")\n",
    "        for tid, idxs in duplicates.items():\n",
    "            print(f\" - tube_id '{tid}' appears in rows {idxs}\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(f\"All tube_id values in {label} are unique.\")\n",
    "\n",
    "def assign_redcap_ids(import_rows, reference_rows):\n",
    "    \n",
    "    \n",
    "    #### This is probably not necessary - because the study ID on recap will go!!!\n",
    "    \n",
    "    \"\"\"\n",
    "    Assigns REDCap record_id based on pat_id (patient ID).\n",
    "    If pat_id exists in reference, reuse the same REDCap ID.\n",
    "    If not, assign a new one (max ID + 1).\n",
    "    \n",
    "    ##this needs to be changed. The pat ID is the lokal ID of sophie. Wenn ich nur pat_id benutze \n",
    "    was macht dann die Zuordnung? Das ist wirklich tricky. \n",
    "\n",
    "    Args:\n",
    "        import_rows (List[Dict]): Rows to be imported\n",
    "        reference_rows (List[Dict]): Existing REDCap data\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[Dict], int]: Updated import_rows with assigned record_id, \n",
    "                                and number of new record_ids assigned\n",
    "    \"\"\"\n",
    "    pat_to_record = {}\n",
    "    existing_ids = set()\n",
    "\n",
    "    for row in reference_rows:\n",
    "        record_id = row.get(\"record_id\", \"\").strip()\n",
    "        pat_id = row.get(\"pat_id\", \"\").strip()\n",
    "        if record_id and pat_id:\n",
    "            pat_to_record[pat_id] = record_id\n",
    "            existing_ids.add(int(record_id))\n",
    "\n",
    "    next_record_id = max(existing_ids) + 1 if existing_ids else 1\n",
    "    new_ids_count = 0\n",
    "\n",
    "    for row in import_rows:\n",
    "        pat_id = row.get(\"pat_id\", \"\").strip()\n",
    "\n",
    "        if not pat_id:\n",
    "            print(\"Missing pat_id in import row.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        if pat_id in pat_to_record:\n",
    "            row[\"record_id\"] = pat_to_record[pat_id]\n",
    "        else:\n",
    "            row[\"record_id\"] = str(next_record_id)\n",
    "            pat_to_record[pat_id] = str(next_record_id)\n",
    "            next_record_id += 1\n",
    "            new_ids_count += 1\n",
    "\n",
    "    print(\"REDCap record_id assigned based on pat_id.\")\n",
    "    return import_rows, new_ids_count\n",
    "\n",
    "def is_position_occupied(freezer, rack, box, pos, occupied_positions):\n",
    "    \"\"\"\n",
    "    Validates the position and checks if it is occupied.\n",
    "\n",
    "    Args:\n",
    "        freezer (str): Freezer number or name (e.g. \"1\", \"2\", \"nitrogen\")\n",
    "        rack (str): Rack number (1–100)\n",
    "        box (str): Box number (1–100)\n",
    "        pos (str): Position (e.g., A1–H12)\n",
    "        occupied_positions (Set[Tuple[str, str, str, str]]): Known used positions\n",
    "\n",
    "    Returns:\n",
    "        bool: True if occupied, False if available\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If input values are invalid\n",
    "    \"\"\"\n",
    "\n",
    "    freezer = str(freezer).strip()\n",
    "    rack = str(rack).strip()\n",
    "    box = str(box).strip()\n",
    "    pos = str(pos).strip().upper()\n",
    "\n",
    "    valid_freezers = {\"1\", \"2\", \"3\", \"nitrogen\"}\n",
    "    if freezer not in valid_freezers:\n",
    "        raise ValueError(f\"Invalid freezer: '{freezer}' (must be 1, 2, 3, or nitrogen)\")\n",
    "\n",
    "    if not rack.isdigit() or not (1 <= int(rack) <= 100):\n",
    "        raise ValueError(f\"Invalid rack: '{rack}' (must be integer 1–100)\")\n",
    "\n",
    "    if not box.isdigit() or not (1 <= int(box) <= 100):\n",
    "        raise ValueError(f\"Invalid box: '{box}' (must be integer 1–100)\")\n",
    "\n",
    "    if not re.match(r\"^[A-H](?:[1-9]|1[0-2])$\", pos):\n",
    "        raise ValueError(f\"Invalid position: '{pos}' (must be A1–H12)\")\n",
    "\n",
    "    key = (freezer, rack, box, pos)\n",
    "    return key in occupied_positions\n",
    "\n",
    "from datetime import datetime\n",
    "'''\n",
    "def write_report(filename, import_file, reference_file, import_rows, duplicate_positions_count): #new_ids_count ist aktuell nicht dabei\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Biorepository Data Validation Report\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\\n\")\n",
    "        f.write(\"Input files:\\n\")\n",
    "        f.write(f\" - Import: {import_file}\\n\")\n",
    "        f.write(f\" - Reference: {reference_file}\\n\\n\")\n",
    "        f.write(\"Summary:\\n\")\n",
    "        f.write(f\" - Number of import rows processed: {len(import_rows)}\\n\")\n",
    "        #f.write(f\" - Number of new pat_ids added: {new_ids_count}\\n\")\n",
    "        f.write(f\" - Number of duplicate positions found: {duplicate_positions_count}\\n\")\n",
    "        record_ids = [int(row[\"record_id\"]) for row in import_rows if \"record_id\" in row]\n",
    "        if record_ids:\n",
    "            f.write(f\" - Assigned record_id range: {min(record_ids)} to {max(record_ids)}\\n\")\n",
    "        f.write(\"\\nWarnings / Errors:\\n\")\n",
    "        f.write(\" - None\\n\\n\")\n",
    "        f.write(\"Validation completed successfully!\\n\")\n",
    "'''    \n",
    "        \n",
    "from datetime import datetime\n",
    "\n",
    "def write_report(filename, import_file, reference_file, import_rows, success, error_message=None):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Biorepository Data Validation Report\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\\n\")\n",
    "        f.write(\"Input files:\\n\")\n",
    "        f.write(f\" - Import: {import_file}\\n\")\n",
    "        f.write(f\" - Reference: {reference_file}\\n\\n\")\n",
    "\n",
    "        if success:\n",
    "            f.write(\"✅ Validation completed successfully.\\n\")\n",
    "            f.write(\"Recommendation: Safe to upload to REDCap.\\n\")\n",
    "        else:\n",
    "            f.write(\"❌ Validation failed.\\n\")\n",
    "            f.write(\"Error details:\\n\")\n",
    "            f.write(error_message + \"\\n\\n\")\n",
    "            f.write(\"Recommendation: Do NOT upload to REDCap.\\n\")\n",
    "            \n",
    "            \n",
    "\n",
    "            from datetime import datetime\n",
    "\n",
    "def write_report(filename, import_file, reference_file, import_rows=None,\n",
    "                 errors=None, recommendation=None):\n",
    "    \"\"\"\n",
    "    Writes a validation report to a text file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to save the report\n",
    "        import_file (str): Path to import CSV\n",
    "        reference_file (str): Path to reference CSV\n",
    "        import_rows (List[Dict], optional): Imported rows, for summary stats\n",
    "        errors (List[str], optional): List of error messages collected\n",
    "        recommendation (str, optional): Recommendation to upload or not\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Biorepository Data Validation Report\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "\n",
    "        f.write(\"Input files:\\n\")\n",
    "        f.write(f\" - Import: {import_file}\\n\")\n",
    "        f.write(f\" - Reference: {reference_file}\\n\\n\")\n",
    "\n",
    "        # Summary\n",
    "        f.write(\"Summary:\\n\")\n",
    "        if import_rows:\n",
    "            f.write(f\" - Number of import rows processed: {len(import_rows)}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        # Errors\n",
    "        f.write(\"Errors / Warnings:\\n\")\n",
    "        if errors and len(errors) > 0:\n",
    "            for e in errors:\n",
    "                f.write(f\" - {e}\\n\")\n",
    "        else:\n",
    "            f.write(\" - None\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        # Recommendation\n",
    "        f.write(\"Recommendation:\\n\")\n",
    "        if recommendation:\n",
    "            f.write(f\"{recommendation}\\n\")\n",
    "        else:\n",
    "            f.write(\"No recommendation provided.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20699e7e",
   "metadata": {},
   "source": [
    "# RUN IT Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59f7f1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checking Import file: /home/aaron/Desktop/BioVal/data/NDEGTest_import_file_double_position.csv\n",
      " Import file passed all validation checks.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'record_id': '1',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'pat_id': '124 123 4ll',\n",
       "  'visit_date': '12.09.2023',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'material': 'CSF',\n",
       "  'pos': 'A1',\n",
       "  'posval': '',\n",
       "  'tube_id': '2345',\n",
       "  'box_id': '1',\n",
       "  'freezer': '1',\n",
       "  'rack': '1',\n",
       "  'box': '1',\n",
       "  'fibro_passage': '',\n",
       "  'einfrierdatum_minus80': '',\n",
       "  'aufgetaut': '',\n",
       "  'volumen': '',\n",
       "  'kommentar': '',\n",
       "  'zellzahl_ampulle': '',\n",
       "  'verschickt_am': '',\n",
       "  'verschickt_empfaenger': '',\n",
       "  'verschickt_projekt': '',\n",
       "  'reserviert_am': '',\n",
       "  'reserviert_fuer': '',\n",
       "  'extern_prozessiert': '',\n",
       "  'visit_time': '',\n",
       "  'freeze_time': '',\n",
       "  'nuechtern': '',\n",
       "  'abholort': '',\n",
       "  'probenabnahme': '',\n",
       "  'aufarbeitung': '',\n",
       "  'visit_nr': '',\n",
       "  'neurolabor_nummer': '',\n",
       "  'pat_nr_study': '',\n",
       "  'accession_nr': '',\n",
       "  'dna_versandtyp': '',\n",
       "  'cohort': '',\n",
       "  'beschriftung': '',\n",
       "  'bereits_erkrankt': '',\n",
       "  'fibro_kontrolle': '',\n",
       "  'extern_verwendbar': '',\n",
       "  'ips_zellen': '',\n",
       "  'ips_zellen_char': '',\n",
       "  'fibro_mutation': '',\n",
       "  'fibro_abnahmeort': '',\n",
       "  'prep_time': '',\n",
       "  'pbmc_roehrchen': '',\n",
       "  'anzahl_roehrchen': '',\n",
       "  'zmf_cmv_status': '',\n",
       "  'zmf_blutmenge': '',\n",
       "  'zmf_gesamtzellzahl': '',\n",
       "  'zmf_plasma_ampulle': '',\n",
       "  'zmf_plasma_lagerort': '',\n",
       "  'zmf_einfrierdatum_n2': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'record_id': '2',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'pat_id': '111 111 111',\n",
       "  'visit_date': '2023-01-11',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'material': 'Serum',\n",
       "  'pos': 'A2',\n",
       "  'posval': '',\n",
       "  'tube_id': '12234',\n",
       "  'box_id': '1',\n",
       "  'freezer': '1',\n",
       "  'rack': '1',\n",
       "  'box': '1',\n",
       "  'fibro_passage': '',\n",
       "  'einfrierdatum_minus80': '',\n",
       "  'aufgetaut': '',\n",
       "  'volumen': '',\n",
       "  'kommentar': '',\n",
       "  'zellzahl_ampulle': '',\n",
       "  'verschickt_am': '',\n",
       "  'verschickt_empfaenger': '',\n",
       "  'verschickt_projekt': '',\n",
       "  'reserviert_am': '',\n",
       "  'reserviert_fuer': '',\n",
       "  'extern_prozessiert': '',\n",
       "  'visit_time': '',\n",
       "  'freeze_time': '',\n",
       "  'nuechtern': '',\n",
       "  'abholort': '',\n",
       "  'probenabnahme': '',\n",
       "  'aufarbeitung': '',\n",
       "  'visit_nr': '',\n",
       "  'neurolabor_nummer': '',\n",
       "  'pat_nr_study': '',\n",
       "  'accession_nr': '',\n",
       "  'dna_versandtyp': '',\n",
       "  'cohort': '',\n",
       "  'beschriftung': '',\n",
       "  'bereits_erkrankt': '',\n",
       "  'fibro_kontrolle': '',\n",
       "  'extern_verwendbar': '',\n",
       "  'ips_zellen': '',\n",
       "  'ips_zellen_char': '',\n",
       "  'fibro_mutation': '',\n",
       "  'fibro_abnahmeort': '',\n",
       "  'prep_time': '',\n",
       "  'pbmc_roehrchen': '',\n",
       "  'anzahl_roehrchen': '',\n",
       "  'zmf_cmv_status': '',\n",
       "  'zmf_blutmenge': '',\n",
       "  'zmf_gesamtzellzahl': '',\n",
       "  'zmf_plasma_ampulle': '',\n",
       "  'zmf_plasma_lagerort': '',\n",
       "  'zmf_einfrierdatum_n2': '',\n",
       "  'biorepository_complete': '0'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate test data\n",
    "validate_file(\"/home/aaron/Desktop/BioVal/data/NDEGTest_import_file_double_position.csv\", \"Import file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b41270f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, import_rows = read_csv(\"/home/aaron/Desktop/BioVal/data/NDEGTest_import_file_double_position.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25bbe540",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ref_rows = read_csv(\"/home/aaron/Desktop/BioVal/data/NDEGTest_ref_file.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af9ed53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checking Import file: /home/aaron/Desktop/BioVal/data/NDEGTest_import_file.csv\n",
      " Import file passed all validation checks.\n",
      "\n",
      " Checking data file: /home/aaron/Desktop/BioVal/data/NDEGTest_ref_file.csv\n",
      " data file passed all validation checks.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'record_id': '1',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'pat_id': '123 456 789',\n",
       "  'visit_date': '2023-01-11',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'material': 'Urin',\n",
       "  'pos': 'A1',\n",
       "  'posval': '',\n",
       "  'tube_id': '2345',\n",
       "  'box_id': '1',\n",
       "  'freezer': '1',\n",
       "  'rack': '1',\n",
       "  'box': '1',\n",
       "  'fibro_passage': '',\n",
       "  'einfrierdatum_minus80': '',\n",
       "  'aufgetaut': '',\n",
       "  'volumen': '',\n",
       "  'kommentar': '',\n",
       "  'zellzahl_ampulle': '',\n",
       "  'verschickt_am': '',\n",
       "  'verschickt_empfaenger': '',\n",
       "  'verschickt_projekt': '',\n",
       "  'reserviert_am': '',\n",
       "  'reserviert_fuer': '',\n",
       "  'extern_prozessiert': '',\n",
       "  'visit_time': '',\n",
       "  'freeze_time': '',\n",
       "  'nuechtern': '',\n",
       "  'abholort': '',\n",
       "  'probenabnahme': '',\n",
       "  'aufarbeitung': '',\n",
       "  'visit_nr': '',\n",
       "  'neurolabor_nummer': '',\n",
       "  'pat_nr_study': '',\n",
       "  'accession_nr': '',\n",
       "  'dna_versandtyp': '',\n",
       "  'cohort': '',\n",
       "  'beschriftung': '',\n",
       "  'bereits_erkrankt': '',\n",
       "  'fibro_kontrolle': '',\n",
       "  'extern_verwendbar': '',\n",
       "  'ips_zellen': '',\n",
       "  'ips_zellen_char': '',\n",
       "  'fibro_mutation': '',\n",
       "  'fibro_abnahmeort': '',\n",
       "  'prep_time': '',\n",
       "  'pbmc_roehrchen': '',\n",
       "  'anzahl_roehrchen': '',\n",
       "  'zmf_cmv_status': '',\n",
       "  'zmf_blutmenge': '',\n",
       "  'zmf_gesamtzellzahl': '',\n",
       "  'zmf_plasma_ampulle': '',\n",
       "  'zmf_plasma_lagerort': '',\n",
       "  'zmf_einfrierdatum_n2': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'record_id': '1',\n",
       "  'redcap_event_name': 'baseline_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'pat_id': '123 456 789',\n",
       "  'visit_date': '2023-01-11',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'material': 'Urin',\n",
       "  'pos': 'A7',\n",
       "  'posval': '',\n",
       "  'tube_id': '23456',\n",
       "  'box_id': '1',\n",
       "  'freezer': '1',\n",
       "  'rack': '1',\n",
       "  'box': '1',\n",
       "  'fibro_passage': '',\n",
       "  'einfrierdatum_minus80': '',\n",
       "  'aufgetaut': '',\n",
       "  'volumen': '',\n",
       "  'kommentar': '',\n",
       "  'zellzahl_ampulle': '',\n",
       "  'verschickt_am': '',\n",
       "  'verschickt_empfaenger': '',\n",
       "  'verschickt_projekt': '',\n",
       "  'reserviert_am': '',\n",
       "  'reserviert_fuer': '',\n",
       "  'extern_prozessiert': '',\n",
       "  'visit_time': '',\n",
       "  'freeze_time': '',\n",
       "  'nuechtern': '',\n",
       "  'abholort': '',\n",
       "  'probenabnahme': '',\n",
       "  'aufarbeitung': '',\n",
       "  'visit_nr': '',\n",
       "  'neurolabor_nummer': '',\n",
       "  'pat_nr_study': '',\n",
       "  'accession_nr': '',\n",
       "  'dna_versandtyp': '',\n",
       "  'cohort': '',\n",
       "  'beschriftung': '',\n",
       "  'bereits_erkrankt': '',\n",
       "  'fibro_kontrolle': '',\n",
       "  'extern_verwendbar': '',\n",
       "  'ips_zellen': '',\n",
       "  'ips_zellen_char': '',\n",
       "  'fibro_mutation': '',\n",
       "  'fibro_abnahmeort': '',\n",
       "  'prep_time': '',\n",
       "  'pbmc_roehrchen': '',\n",
       "  'anzahl_roehrchen': '',\n",
       "  'zmf_cmv_status': '',\n",
       "  'zmf_blutmenge': '',\n",
       "  'zmf_gesamtzellzahl': '',\n",
       "  'zmf_plasma_ampulle': '',\n",
       "  'zmf_plasma_lagerort': '',\n",
       "  'zmf_einfrierdatum_n2': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'record_id': '2',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'pat_id': '111 111 111',\n",
       "  'visit_date': '2023-01-11',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'material': 'Serum',\n",
       "  'pos': 'A2',\n",
       "  'posval': '',\n",
       "  'tube_id': '12234',\n",
       "  'box_id': '1',\n",
       "  'freezer': '1',\n",
       "  'rack': '1',\n",
       "  'box': '1',\n",
       "  'fibro_passage': '',\n",
       "  'einfrierdatum_minus80': '',\n",
       "  'aufgetaut': '',\n",
       "  'volumen': '',\n",
       "  'kommentar': '',\n",
       "  'zellzahl_ampulle': '',\n",
       "  'verschickt_am': '',\n",
       "  'verschickt_empfaenger': '',\n",
       "  'verschickt_projekt': '',\n",
       "  'reserviert_am': '',\n",
       "  'reserviert_fuer': '',\n",
       "  'extern_prozessiert': '',\n",
       "  'visit_time': '',\n",
       "  'freeze_time': '',\n",
       "  'nuechtern': '',\n",
       "  'abholort': '',\n",
       "  'probenabnahme': '',\n",
       "  'aufarbeitung': '',\n",
       "  'visit_nr': '',\n",
       "  'neurolabor_nummer': '',\n",
       "  'pat_nr_study': '',\n",
       "  'accession_nr': '',\n",
       "  'dna_versandtyp': '',\n",
       "  'cohort': '',\n",
       "  'beschriftung': '',\n",
       "  'bereits_erkrankt': '',\n",
       "  'fibro_kontrolle': '',\n",
       "  'extern_verwendbar': '',\n",
       "  'ips_zellen': '',\n",
       "  'ips_zellen_char': '',\n",
       "  'fibro_mutation': '',\n",
       "  'fibro_abnahmeort': '',\n",
       "  'prep_time': '',\n",
       "  'pbmc_roehrchen': '',\n",
       "  'anzahl_roehrchen': '',\n",
       "  'zmf_cmv_status': '',\n",
       "  'zmf_blutmenge': '',\n",
       "  'zmf_gesamtzellzahl': '',\n",
       "  'zmf_plasma_ampulle': '',\n",
       "  'zmf_plasma_lagerort': '',\n",
       "  'zmf_einfrierdatum_n2': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'record_id': '2',\n",
       "  'redcap_event_name': 'baseline_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'pat_id': '111 111 111',\n",
       "  'visit_date': '2023-01-11',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'material': 'Serum',\n",
       "  'pos': 'A3',\n",
       "  'posval': '',\n",
       "  'tube_id': '23333',\n",
       "  'box_id': '1',\n",
       "  'freezer': '1',\n",
       "  'rack': '1',\n",
       "  'box': '1',\n",
       "  'fibro_passage': '',\n",
       "  'einfrierdatum_minus80': '',\n",
       "  'aufgetaut': '',\n",
       "  'volumen': '',\n",
       "  'kommentar': '',\n",
       "  'zellzahl_ampulle': '',\n",
       "  'verschickt_am': '',\n",
       "  'verschickt_empfaenger': '',\n",
       "  'verschickt_projekt': '',\n",
       "  'reserviert_am': '',\n",
       "  'reserviert_fuer': '',\n",
       "  'extern_prozessiert': '',\n",
       "  'visit_time': '',\n",
       "  'freeze_time': '',\n",
       "  'nuechtern': '',\n",
       "  'abholort': '',\n",
       "  'probenabnahme': '',\n",
       "  'aufarbeitung': '',\n",
       "  'visit_nr': '',\n",
       "  'neurolabor_nummer': '',\n",
       "  'pat_nr_study': '',\n",
       "  'accession_nr': '',\n",
       "  'dna_versandtyp': '',\n",
       "  'cohort': '',\n",
       "  'beschriftung': '',\n",
       "  'bereits_erkrankt': '',\n",
       "  'fibro_kontrolle': '',\n",
       "  'extern_verwendbar': '',\n",
       "  'ips_zellen': '',\n",
       "  'ips_zellen_char': '',\n",
       "  'fibro_mutation': '',\n",
       "  'fibro_abnahmeort': '',\n",
       "  'prep_time': '',\n",
       "  'pbmc_roehrchen': '',\n",
       "  'anzahl_roehrchen': '',\n",
       "  'zmf_cmv_status': '',\n",
       "  'zmf_blutmenge': '',\n",
       "  'zmf_gesamtzellzahl': '',\n",
       "  'zmf_plasma_ampulle': '',\n",
       "  'zmf_plasma_lagerort': '',\n",
       "  'zmf_einfrierdatum_n2': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'record_id': '2',\n",
       "  'redcap_event_name': 'follow_up_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '1',\n",
       "  'pat_id': '111 111 111',\n",
       "  'visit_date': '2023-01-11',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'material': 'Serum',\n",
       "  'pos': 'A4',\n",
       "  'posval': '',\n",
       "  'tube_id': '45677',\n",
       "  'box_id': '1',\n",
       "  'freezer': '1',\n",
       "  'rack': '1',\n",
       "  'box': '1',\n",
       "  'fibro_passage': '',\n",
       "  'einfrierdatum_minus80': '',\n",
       "  'aufgetaut': '',\n",
       "  'volumen': '',\n",
       "  'kommentar': '',\n",
       "  'zellzahl_ampulle': '',\n",
       "  'verschickt_am': '',\n",
       "  'verschickt_empfaenger': '',\n",
       "  'verschickt_projekt': '',\n",
       "  'reserviert_am': '',\n",
       "  'reserviert_fuer': '',\n",
       "  'extern_prozessiert': '',\n",
       "  'visit_time': '',\n",
       "  'freeze_time': '',\n",
       "  'nuechtern': '',\n",
       "  'abholort': '',\n",
       "  'probenabnahme': '',\n",
       "  'aufarbeitung': '',\n",
       "  'visit_nr': '',\n",
       "  'neurolabor_nummer': '',\n",
       "  'pat_nr_study': '',\n",
       "  'accession_nr': '',\n",
       "  'dna_versandtyp': '',\n",
       "  'cohort': '',\n",
       "  'beschriftung': '',\n",
       "  'bereits_erkrankt': '',\n",
       "  'fibro_kontrolle': '',\n",
       "  'extern_verwendbar': '',\n",
       "  'ips_zellen': '',\n",
       "  'ips_zellen_char': '',\n",
       "  'fibro_mutation': '',\n",
       "  'fibro_abnahmeort': '',\n",
       "  'prep_time': '',\n",
       "  'pbmc_roehrchen': '',\n",
       "  'anzahl_roehrchen': '',\n",
       "  'zmf_cmv_status': '',\n",
       "  'zmf_blutmenge': '',\n",
       "  'zmf_gesamtzellzahl': '',\n",
       "  'zmf_plasma_ampulle': '',\n",
       "  'zmf_plasma_lagerort': '',\n",
       "  'zmf_einfrierdatum_n2': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'record_id': '3',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'pat_id': '124 123 4ll',\n",
       "  'visit_date': '2023-01-11',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'material': 'EDTA Plasma',\n",
       "  'pos': 'A5',\n",
       "  'posval': '',\n",
       "  'tube_id': '1223456',\n",
       "  'box_id': '1',\n",
       "  'freezer': '1',\n",
       "  'rack': '1',\n",
       "  'box': '1',\n",
       "  'fibro_passage': '',\n",
       "  'einfrierdatum_minus80': '',\n",
       "  'aufgetaut': '',\n",
       "  'volumen': '',\n",
       "  'kommentar': '',\n",
       "  'zellzahl_ampulle': '',\n",
       "  'verschickt_am': '',\n",
       "  'verschickt_empfaenger': '',\n",
       "  'verschickt_projekt': '',\n",
       "  'reserviert_am': '',\n",
       "  'reserviert_fuer': '',\n",
       "  'extern_prozessiert': '',\n",
       "  'visit_time': '',\n",
       "  'freeze_time': '',\n",
       "  'nuechtern': '',\n",
       "  'abholort': '',\n",
       "  'probenabnahme': '',\n",
       "  'aufarbeitung': '',\n",
       "  'visit_nr': '',\n",
       "  'neurolabor_nummer': '',\n",
       "  'pat_nr_study': '',\n",
       "  'accession_nr': '',\n",
       "  'dna_versandtyp': '',\n",
       "  'cohort': '',\n",
       "  'beschriftung': '',\n",
       "  'bereits_erkrankt': '',\n",
       "  'fibro_kontrolle': '',\n",
       "  'extern_verwendbar': '',\n",
       "  'ips_zellen': '',\n",
       "  'ips_zellen_char': '',\n",
       "  'fibro_mutation': '',\n",
       "  'fibro_abnahmeort': '',\n",
       "  'prep_time': '',\n",
       "  'pbmc_roehrchen': '',\n",
       "  'anzahl_roehrchen': '',\n",
       "  'zmf_cmv_status': '',\n",
       "  'zmf_blutmenge': '',\n",
       "  'zmf_gesamtzellzahl': '',\n",
       "  'zmf_plasma_ampulle': '',\n",
       "  'zmf_plasma_lagerort': '',\n",
       "  'zmf_einfrierdatum_n2': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'record_id': '3',\n",
       "  'redcap_event_name': 'follow_up_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '1',\n",
       "  'pat_id': '124 123 4ll',\n",
       "  'visit_date': '2023-01-11',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'material': 'EDTA Plasma',\n",
       "  'pos': 'A6',\n",
       "  'posval': '',\n",
       "  'tube_id': '56454',\n",
       "  'box_id': '1',\n",
       "  'freezer': '1',\n",
       "  'rack': '1',\n",
       "  'box': '1',\n",
       "  'fibro_passage': '',\n",
       "  'einfrierdatum_minus80': '',\n",
       "  'aufgetaut': '',\n",
       "  'volumen': '',\n",
       "  'kommentar': '',\n",
       "  'zellzahl_ampulle': '',\n",
       "  'verschickt_am': '',\n",
       "  'verschickt_empfaenger': '',\n",
       "  'verschickt_projekt': '',\n",
       "  'reserviert_am': '',\n",
       "  'reserviert_fuer': '',\n",
       "  'extern_prozessiert': '',\n",
       "  'visit_time': '',\n",
       "  'freeze_time': '',\n",
       "  'nuechtern': '',\n",
       "  'abholort': '',\n",
       "  'probenabnahme': '',\n",
       "  'aufarbeitung': '',\n",
       "  'visit_nr': '',\n",
       "  'neurolabor_nummer': '',\n",
       "  'pat_nr_study': '',\n",
       "  'accession_nr': '',\n",
       "  'dna_versandtyp': '',\n",
       "  'cohort': '',\n",
       "  'beschriftung': '',\n",
       "  'bereits_erkrankt': '',\n",
       "  'fibro_kontrolle': '',\n",
       "  'extern_verwendbar': '',\n",
       "  'ips_zellen': '',\n",
       "  'ips_zellen_char': '',\n",
       "  'fibro_mutation': '',\n",
       "  'fibro_abnahmeort': '',\n",
       "  'prep_time': '',\n",
       "  'pbmc_roehrchen': '',\n",
       "  'anzahl_roehrchen': '',\n",
       "  'zmf_cmv_status': '',\n",
       "  'zmf_blutmenge': '',\n",
       "  'zmf_gesamtzellzahl': '',\n",
       "  'zmf_plasma_ampulle': '',\n",
       "  'zmf_plasma_lagerort': '',\n",
       "  'zmf_einfrierdatum_n2': '',\n",
       "  'biorepository_complete': '0'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_file(\"/home/aaron/Desktop/BioVal/data/NDEGTest_import_file.csv\", \"Import file\")\n",
    "validate_file(\"/home/aaron/Desktop/BioVal/data/NDEGTest_ref_file.csv\", \"data file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a32c9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate positions found within data file.\n",
      "All tube_id values in Reference data file are unique.\n"
     ]
    }
   ],
   "source": [
    "check_internal_duplicates(ref_rows, \"data file\")\n",
    "check_internal_tube_id_duplicates(ref_rows, \"Reference data file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "275fd2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDCap record_id assigned based on pat_id.\n"
     ]
    }
   ],
   "source": [
    "import_rows, account_id = assign_redcap_ids(import_rows, ref_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c1dca9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Import vs Reference – 2 duplicate position error(s):\nRow 2: Position ('1', '1', '1', 'A1') is already occupied in reference data.\nRow 3: Position ('1', '1', '1', 'A2') is already occupied in reference data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m occupied \u001b[38;5;241m=\u001b[39m get_occupied_positions(ref_rows)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcheck_duplicate_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimport_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moccupied\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mcheck_duplicate_positions\u001b[0;34m(import_rows, occupied_positions, label)\u001b[0m\n\u001b[1;32m    413\u001b[0m         errors\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Position \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is already occupied in reference data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors:\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m – \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(errors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m duplicate position error(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(errors))\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo duplicate positions found between import and reference data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Import vs Reference – 2 duplicate position error(s):\nRow 2: Position ('1', '1', '1', 'A1') is already occupied in reference data.\nRow 3: Position ('1', '1', '1', 'A2') is already occupied in reference data."
     ]
    }
   ],
   "source": [
    "occupied = get_occupied_positions(ref_rows)\n",
    "check_duplicate_positions(import_rows, occupied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23ed5690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position (1, 1, 1, G1) is free. \n"
     ]
    }
   ],
   "source": [
    "occupied = get_occupied_positions(ref_rows)\n",
    "\n",
    "# Check a specific position manually\n",
    "freezer = \"1\"\n",
    "rack = \"1\"\n",
    "box = \"1\"\n",
    "pos = \"G1\"\n",
    "\n",
    "if is_position_occupied(freezer, rack, box, pos, occupied):\n",
    "    print(f\"Position ({freezer}, {rack}, {box}, {pos}) is already occupied. Please try another one.\")\n",
    "else:\n",
    "    print(f\"Position ({freezer}, {rack}, {box}, {pos}) is free. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07442fb3",
   "metadata": {},
   "source": [
    "# GUI - BioVal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01af74c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checking Import file: /home/aaron/Desktop/BioVal/data/NDEGTest_import_file_double_position.csv\n",
      " Import file passed all validation checks.\n",
      "\n",
      " Checking Reference file: /home/aaron/Desktop/BioVal/data/NDEGTest_ref_file.csv\n",
      " Reference file passed all validation checks.\n",
      "\n",
      "No duplicate positions found within Import file.\n",
      "No duplicate positions found within Reference file.\n",
      "[\"Import vs Reference – 2 duplicate position error(s):\\nRow 2: Position ('1', '1', '1', 'A1') is already occupied in reference data.\\nRow 3: Position ('1', '1', '1', 'A2') is already occupied in reference data.\"]\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk  # Pillow muss installiert sein: pip install pillow\n",
    "\n",
    "def run_validation():\n",
    "    import_path = filedialog.askopenfilename(title=\"Select Import CSV\")\n",
    "    ref_path = filedialog.askopenfilename(title=\"Select Reference CSV\")\n",
    "    \n",
    "    if not import_path or not ref_path:\n",
    "        messagebox.showerror(\"Error\", \"Both files must be selected.\")\n",
    "        return\n",
    "    \n",
    "    errors = []\n",
    "\n",
    "    try:\n",
    "        validate_file(import_path, \"Import file\")\n",
    "    except ValueError as e:\n",
    "        errors.append(str(e))\n",
    "\n",
    "    try:\n",
    "        validate_file(ref_path, \"Reference file\")\n",
    "    except ValueError as e:\n",
    "        errors.append(str(e))\n",
    "\n",
    "    try:\n",
    "        check_internal_duplicates(read_csv(import_path)[1], \"Import file\")\n",
    "    except ValueError as e:\n",
    "        errors.append(str(e))\n",
    "\n",
    "    try:\n",
    "        check_internal_duplicates(read_csv(ref_path)[1], \"Reference file\")\n",
    "    except ValueError as e:\n",
    "        errors.append(str(e))\n",
    "\n",
    "    try:\n",
    "        occupied_pos = get_occupied_positions(read_csv(ref_path)[1])\n",
    "        duplicate_positions_count = check_duplicate_positions(\n",
    "            read_csv(import_path)[1], occupied_pos)\n",
    "    except ValueError as e:\n",
    "        errors.append(str(e))\n",
    "    print(errors)\n",
    "    # === Decide what to do based on errors ===\n",
    "    if errors:\n",
    "        recommendation = \"❌ No upload. Errors must be fixed first.\"\n",
    "    else:\n",
    "        recommendation = \"✅ Upload safe.\"\n",
    "\n",
    "    report_path = filedialog.asksaveasfilename(\n",
    "        defaultextension=\".txt\",\n",
    "        filetypes=[(\"Text files\", \"*.txt\")],\n",
    "        title=\"Save Validation Report As\"\n",
    "    )\n",
    "    if report_path:\n",
    "        write_report(report_path, import_path, ref_path, read_csv(import_path)[1] , errors, recommendation)\n",
    "        messagebox.showinfo(\"Report\", f\"Report saved at {report_path}\")\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "# --- GUI Setup ---\n",
    "root = tk.Tk()\n",
    "root.title(\"BioVal – Biorepository Validator\")\n",
    "root.geometry(\"600x400\")\n",
    "\n",
    "main_frame = ttk.Frame(root, padding=20)\n",
    "main_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "# --- Optional Image ---\n",
    "try:\n",
    "    img = Image.open(\"logo.jpeg\")  # <-- Dein Bildpfad\n",
    "    img = img.resize((150, 150))\n",
    "    photo = ImageTk.PhotoImage(img)\n",
    "    logo_label = ttk.Label(main_frame, image=photo)\n",
    "    logo_label.image = photo\n",
    "    logo_label.pack(pady=(0, 10))\n",
    "except Exception:\n",
    "    print(\"No image found – skipping logo.\")\n",
    "\n",
    "# --- Welcome Text ---\n",
    "welcome = ttk.Label(\n",
    "    main_frame,\n",
    "    text=(\n",
    "        \"Welcome to BioVal!\\n\\n\"\n",
    "        \"This tool helps you validate biorepository REDCap import files.\\n\"\n",
    "        \"You’ll be prompted to select:\\n\"\n",
    "        \" - A new import CSV file\\n - the data you want to upload\"\n",
    "        \" - A reference dataset for comparison - the data already stored in RedCap \\n\\n\"\n",
    "        \"The tool checks patient IDs, sample positions, and generates a report.\"\n",
    "    ),\n",
    "    justify=\"center\",\n",
    "    wraplength=500\n",
    ")\n",
    "welcome.pack(pady=10)\n",
    "\n",
    "# --- Start Button ---\n",
    "start_button = ttk.Button(main_frame, text=\"Run Validation\", command=run_validation)\n",
    "start_button.pack(pady=20)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b25174c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checking Import file: /home/aaron/Desktop/BioVal/data/NDEGTest_import_file_double_position.csv\n",
      " Import file passed all validation checks.\n",
      "\n",
      " Checking Reference data: /home/aaron/Desktop/BioVal/data/NDEGTest_ref_file.csv\n",
      " Reference data passed all validation checks.\n",
      "\n",
      "No duplicate positions found within Import file.\n",
      "No duplicate positions found within Reference date.\n",
      "Row 2: Position ('1', '1', '1', 'A1') is already occupied in existing data.\n",
      "Row 3: Position ('1', '1', '1', 'A2') is already occupied in existing data.\n",
      "2 duplicate position error(s) found.\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk  # Pillow muss installiert sein: pip install pillow\n",
    "\n",
    "def run_validation():\n",
    "    import_path = filedialog.askopenfilename(title=\"Select Import CSV\")\n",
    "    ref_path = filedialog.askopenfilename(title=\"Select Reference CSV\")\n",
    "\n",
    "    if not import_path or not ref_path:\n",
    "        messagebox.showerror(\"Error\", \"Both files must be selected.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Beispiel: CSV lesen & validieren (Funktionen müssen definiert sein)\n",
    "        _, import_rows = read_csv(import_path)\n",
    "        _, ref_rows = read_csv(ref_path)\n",
    "        #Check if either of the files have not the required fields and structure\n",
    "        validate_file(import_path, \"Import file\")\n",
    "        validate_file(ref_path, \"Reference data\")\n",
    "        #Check if they have internal dublicates\n",
    "        check_internal_duplicates(import_rows, \"Import file\")\n",
    "        check_internal_duplicates(ref_rows,\"Reference date\")\n",
    "        #Die Red cap ID function muss geändert werden, wegen PaTID da brauchen wir aber das Gespräch mit Rebecca\n",
    "        #import_rows, new_ids_count = assign_redcap_ids(import_rows, ref_rows)\n",
    "        #Die Funktion macht nicht was sie soll.\n",
    "        occupied_pos = get_occupied_positions(ref_rows)\n",
    "        duplicate_positions_count = check_duplicate_positions(import_rows, occupied_pos)\n",
    "\n",
    "        # Bericht speichern\n",
    "        report_path = filedialog.asksaveasfilename(\n",
    "            defaultextension=\".txt\",\n",
    "            filetypes=[(\"Text files\", \"*.txt\")],\n",
    "            title=\"Save Validation Report As\"\n",
    "        )\n",
    "        if report_path:\n",
    "            #Write report . \n",
    "            write_report(report_path, import_path, ref_path, import_rows, duplicate_positions_count) #new_ids_count ist weg\n",
    "            messagebox.showinfo(\"Success\", f\"Validation completed!\\nReport saved at:\\n{report_path}\")\n",
    "        else:\n",
    "            messagebox.showinfo(\"Success\", \"Validation completed! No report was saved.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Validation Error\", str(e))\n",
    "\n",
    "\n",
    "# --- GUI Setup ---\n",
    "root = tk.Tk()\n",
    "root.title(\"BioVal – Biorepository Validator\")\n",
    "root.geometry(\"600x400\")\n",
    "\n",
    "main_frame = ttk.Frame(root, padding=20)\n",
    "main_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "# --- Optional Image ---\n",
    "try:\n",
    "    img = Image.open(\"logo.jpeg\")  # <-- Dein Bildpfad\n",
    "    img = img.resize((150, 150))\n",
    "    photo = ImageTk.PhotoImage(img)\n",
    "    logo_label = ttk.Label(main_frame, image=photo)\n",
    "    logo_label.image = photo\n",
    "    logo_label.pack(pady=(0, 10))\n",
    "except Exception:\n",
    "    print(\"No image found – skipping logo.\")\n",
    "\n",
    "# --- Welcome Text ---\n",
    "welcome = ttk.Label(\n",
    "    main_frame,\n",
    "    text=(\n",
    "        \"Welcome to BioVal!\\n\\n\"\n",
    "        \"This tool helps you validate biorepository REDCap import files.\\n\"\n",
    "        \"You’ll be prompted to select:\\n\"\n",
    "        \" - A new import CSV file\\n - the data you want to upload\"\n",
    "        \" - A reference dataset for comparison - the data already stored in RedCap \\n\\n\"\n",
    "        \"The tool checks patient IDs, sample positions, and generates a report.\"\n",
    "    ),\n",
    "    justify=\"center\",\n",
    "    wraplength=500\n",
    ")\n",
    "welcome.pack(pady=10)\n",
    "\n",
    "# --- Start Button ---\n",
    "start_button = ttk.Button(main_frame, text=\"Run Validation\", command=run_validation)\n",
    "start_button.pack(pady=20)\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
