{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e5de916",
   "metadata": {},
   "source": [
    "# Biorepsoitory Validation Code - BioVal \n",
    "\n",
    "Code validates individually the current redcap repository and the biorep data intended to be uploaded.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f397938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLOBAL PARAMS\n",
    "\n",
    "REQUIRED_FIELDS = [\n",
    "    \"pat_id\",    #does sophie use this? yes! we want to use this but need to find a solution here\n",
    "    \"redcap_event_name\",\n",
    "    \"visit_date\",\n",
    "    \"material\",\n",
    "    \"pos\",\n",
    "    \"tube_id\",\n",
    "    \"box_id\",\n",
    "    \"freezer\",\n",
    "    \"rack\",\n",
    "    \"box\",\n",
    "    \"inf_deseas\"\n",
    "]\n",
    "\n",
    "#Biorep Sampel Materials\n",
    "VALID_MATERIALS = [\n",
    "    \"CSF\", \"CSF Pellet\", \"DNA\", \"EDTA Plasma\", \"Fibroblasten\",\n",
    "    \"PAXgene\", \"PBMC\", \"Serum\", \"Urin\"\n",
    "]\n",
    "\n",
    "VALID_EVENTS = [\"baseline_arm_1\", \"screening_arm_1\", \"follow_up_arm_1\"]\n",
    "\n",
    "# Allowed matrices (positions) per material\n",
    "VALID_POS_FLUIDS = [f\"{row}{col}\" for row in \"ABCDEFGH\" for col in range(1, 13)]\n",
    "VALID_POS_PAXGENE = [f\"{row}{col}\" for row in \"ABCDEFG\" for col in range(1, 8)]\n",
    "VALID_POS_DNA_CELLS_PBMC =  [f\"{row}{col}\" for row in \"ABCDEFGHJ\" for col in range(1, 11)]\n",
    "\n",
    "# Freezers\n",
    "VALID_FREEZER = [\"1\", \"2\", \"3\", \"nitrogen\", \"4deg\"]\n",
    "\n",
    "# Boxes (same for all, unless exception later)\n",
    "VALID_BOX = [str(i) for i in range(1, 43)]  # 1–42\n",
    "\n",
    "# Racks\n",
    "VALID_RACK = [str(i) for i in range(1, 101)]  # 1–100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3f2e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import re\n",
    "\n",
    "# --- Define allowed values and required fields ---\n",
    "\n",
    "REQUIRED_FIELDS = [\n",
    "    \"pat_id\", \"redcap_event_name\", \"visit_date\", \"material\", \"pos\",\n",
    "    \"tube_id\", \"box_id\", \"freezer\", \"rack\", \"box\"\n",
    "]\n",
    "\n",
    "VALID_MATERIALS = [\n",
    "    \"csf\", \"csf pellet\", \"dna\", \"edta plasma\", \"fibroblasten\",\n",
    "    \"paxgene\", \"pbmc\", \"serum\", \"urin\"\n",
    "]\n",
    "\n",
    "### Unterschied zwischen Biofluids und Cells \n",
    "\"\"\"\n",
    "Biofluids: CSF (Cerebrospinalfluid), EDTA Plasam (Also nicht geronnen), Serum (geronnen abzentrifugiert), Urin, CSF Pellets\n",
    "Cells: Fibroblasten, PBMC (Peripher mononukläre Blutzellen)?, \n",
    "Other: DNA, PAXgene (RNA)\n",
    "\n",
    "Specific Fluids/Cells go into specific locations. \n",
    "\"\"\"\n",
    "\n",
    "### Für Positions: \n",
    "\"\"\"\n",
    "Für die Biofluids gibt es pro Rack (Gestell); 7 Schubladen a 6 Boxpositionen; die Boxen haben dann widerum ABCDEFGH 1-12. \n",
    "\n",
    "Variable\tWertbeispiel\tBedeutung\n",
    "pos\tB3\tRaster-Position in der Box\n",
    "tube_id\t20250123-1\tEindeutige Probenkennung\n",
    "box_id\tBX-00017\tBox-Nummer\n",
    "freezer\t2\tTiefkühler Nummer 2\n",
    "rack\t14\tRack (Gestell) Nummer 14 im Schrank\n",
    "box\t31\tBox Nummer 31 im Rack (die Schulade wird nicht spezifisch genannt)\n",
    "A1-H12\tD7\tAlternative Positionsangabe in 96er-Box\n",
    "nitrogen\t-\tLagerort im Stickstofftank (anstelle von „freezer“)\n",
    "\n",
    "Ok box meint die position 1-42 im Rack.!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Positions A1–H12 (plate layout)\n",
    "#VALID_POS = [f\"{row}{col}\" for row in \"ABCDEFGH\" for col in range(1, 13)]\n",
    "#VALID_RACK = list(map(str, range(1, 101)))  # 1–100\n",
    "#VALID_BOX = [f\"{box}\" for box in range(1,43)] #42 positions per Rack\n",
    "#VALID_FREEZER = [\"1\", \"2\", \"3\", \"nitrogen\"]\n",
    "VALID_EVENTS = [\"baseline_arm_1\", \"screening_arm_1\", \"follow_up_arm_1\"]\n",
    "\n",
    "# Allowed matrices (positions) per material\n",
    "VALID_POS_FLUIDS = [f\"{row}{col}\" for row in \"ABCDEFGH\" for col in range(1, 13)]\n",
    "VALID_POS_PAXGENE = [f\"{row}{col}\" for row in \"ABCDEFG\" for col in range(1, 8)]\n",
    "VALID_POS_DNA_CELLS_PBMC =  [f\"{row}{col}\" for row in \"ABCDEFGHJ\" for col in range(1, 11)]\n",
    "\n",
    "# Freezers\n",
    "VALID_FREEZER = [\"1\", \"2\", \"3\", \"nitrogen\", \"4deg\"]\n",
    "\n",
    "# Boxes (same for all, unless exception later)\n",
    "VALID_BOX = [str(i) for i in range(1, 43)]  # 1–42\n",
    "\n",
    "# Racks\n",
    "VALID_RACK = [str(i) for i in range(1, 101)]  # 1–100\n",
    "\n",
    "# === Functions ===\n",
    "\n",
    "def read_csv(path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns its headers and row data.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the CSV file\n",
    "\n",
    "    Returns:\n",
    "        tuple: (List[str] headers, List[Dict] rows)\n",
    "    \"\"\"\n",
    "    with open(path, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        rows = list(reader)\n",
    "    return reader.fieldnames, rows\n",
    "\n",
    "\n",
    "def check_structure(headers):\n",
    "    \"\"\"\n",
    "    Checks whether all required fields are present in the CSV headers.\n",
    "\n",
    "    Args:\n",
    "        headers (List[str]): Column headers from the CSV\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of missing required fields (if any)\n",
    "    \"\"\"\n",
    "    missing = [field for field in REQUIRED_FIELDS if field not in headers]\n",
    "    return missing\n",
    "\n",
    "\n",
    "def validate_row_v0(row, index):\n",
    "    \"\"\"\n",
    "    Old version\n",
    "    Validates a single row for required values and correct formats.\n",
    "\n",
    "    Args:\n",
    "        row (Dict): A row from the CSV as a dictionary\n",
    "        index (int): The row number (for error reporting)\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of validation error messages for this row\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "\n",
    "    # Check if all required fields are non-empty\n",
    "    for field in REQUIRED_FIELDS:\n",
    "        if row.get(field, \"\").strip() == \"\":\n",
    "            errors.append(f\"Row {index}: Missing value in '{field}'\")\n",
    "\n",
    "    ######## General Validation - is everything there?         \n",
    "            \n",
    "    # Validate pat_id format (3x alphanumeric with spaces)\n",
    "    pat_id = row.get(\"pat_id\", \"\").strip()\n",
    "    if pat_id and not re.match(r\"^[A-Za-z0-9]{3} [A-Za-z0-9]{3} [A-Za-z0-9]{3}$\", pat_id):\n",
    "        errors.append(f\"Row {index}: Invalid pat_id format: '{pat_id}'\")\n",
    "        #that is not necessary anymore sophie will use something else\n",
    "\n",
    "    # Validate other fields only if they're present\n",
    "    if row.get(\"material\") and row[\"material\"] not in VALID_MATERIALS:\n",
    "        errors.append(f\"Row {index}: Invalid material: '{row['material']}'\")\n",
    "\n",
    "    if row.get(\"pos\") and row[\"pos\"] not in VALID_POS:\n",
    "        errors.append(f\"Row {index}: Invalid pos: '{row['pos']}'\")\n",
    "\n",
    "    if row.get(\"freezer\") and row[\"freezer\"] not in VALID_FREEZER:\n",
    "        errors.append(f\"Row {index}: Invalid freezer: '{row['freezer']}'\")\n",
    "\n",
    "    if row.get(\"rack\") and row[\"rack\"] not in VALID_RACK:\n",
    "        errors.append(f\"Row {index}: Invalid rack: '{row['rack']}'\")\n",
    "\n",
    "    if row.get(\"box\") and row[\"box\"] not in VALID_BOX:\n",
    "        errors.append(f\"Row {index}: Invalid box: '{row['box']}'\")\n",
    "\n",
    "    if row.get(\"redcap_event_name\") and row[\"redcap_event_name\"] not in VALID_EVENTS:\n",
    "        errors.append(f\"Row {index}: Invalid redcap_event_name: '{row['redcap_event_name']}'\")\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "# === Material → Freezer mapping === Import for sepparation of the different materials\n",
    "BIOFLUIDS = [\"urin\", \"edta plasma\", \"serum\", \"csf\", \"csf pellet\"]\n",
    "PAXGENE = [\"paxgene\"]\n",
    "DNA = [\"dna\"]\n",
    "CELLS = [\"fibroblasten\", \"pbmc\"]\n",
    "\n",
    "#lets normalize to lower case\n",
    "\n",
    "MATERIAL_TO_FREEZER = {\n",
    "    **{m: [\"1\", \"2\", \"3\"] for m in BIOFLUIDS},   # Biofluids → -80 freezers\n",
    "    **{m: [\"nitrogen\"] for m in CELLS},          # Cells → nitrogen\n",
    "    **{m: [\"4deg\"] for m in DNA},                # DNA -> 4 Deg freezer\n",
    "    **{m: [\"1\", \"2\", \"3\"] for m in PAXGENE}      # Paxgene -> -80 freezers\n",
    "}\n",
    "\n",
    "def validate_row_v1(row, index):\n",
    "    \"\"\"\n",
    "    Validates a single row for required values and correct formats.\n",
    "\n",
    "    Args:\n",
    "        row (Dict): A row from the CSV as a dictionary\n",
    "        index (int): The row number (for error reporting)\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of validation error messages for this row\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "\n",
    "    # Check if all required fields are non-empty\n",
    "    for field in REQUIRED_FIELDS:\n",
    "        if row.get(field, \"\").strip() == \"\":\n",
    "            errors.append(f\"Row {index}: Missing value in '{field}'\")\n",
    "\n",
    "    ######## General Validation ########\n",
    "            \n",
    "    # Validate pat_id format (DISABLED if Sophie will use different format)\n",
    "    # pat_id = row.get(\"pat_id\", \"\").strip()\n",
    "    # if pat_id and not re.match(r\"^[A-Za-z0-9]{3} [A-Za-z0-9]{3} [A-Za-z0-9]{3}$\", pat_id):\n",
    "    #     errors.append(f\"Row {index}: Invalid pat_id format: '{pat_id}'\")\n",
    "\n",
    "    # Validate material\n",
    "    if row.get(\"material\") and row[\"material\"] not in VALID_MATERIALS:\n",
    "        errors.append(f\"Row {index}: Invalid material: '{row['material']}'\")\n",
    "\n",
    "    # Validate pos\n",
    "    if row.get(\"pos\") and row[\"pos\"] not in VALID_POS:\n",
    "        errors.append(f\"Row {index}: Invalid pos: '{row['pos']}'\")\n",
    "\n",
    "    # Validate freezer\n",
    "    if row.get(\"freezer\") and row[\"freezer\"] not in VALID_FREEZER:\n",
    "        errors.append(f\"Row {index}: Invalid freezer: '{row['freezer']}'\")\n",
    "\n",
    "    # Validate rack\n",
    "    if row.get(\"rack\") and row[\"rack\"] not in VALID_RACK:\n",
    "        errors.append(f\"Row {index}: Invalid rack: '{row['rack']}'\")\n",
    "\n",
    "    # Validate box\n",
    "    if row.get(\"box\") and row[\"box\"] not in VALID_BOX:\n",
    "        errors.append(f\"Row {index}: Invalid box: '{row['box']}'\")\n",
    "\n",
    "    # Validate event name\n",
    "    if row.get(\"redcap_event_name\") and row[\"redcap_event_name\"] not in VALID_EVENTS:\n",
    "        errors.append(f\"Row {index}: Invalid redcap_event_name: '{row['redcap_event_name']}'\")\n",
    "\n",
    "    ######## Material-specific Freezer Rule ########\n",
    "    material = row.get(\"material\", \"\").strip()\n",
    "    freezer = row.get(\"freezer\", \"\").strip()\n",
    "\n",
    "    if material and freezer:\n",
    "        allowed_freezers = MATERIAL_TO_FREEZER.get(material, [])\n",
    "        if allowed_freezers and freezer not in allowed_freezers:\n",
    "            errors.append(\n",
    "                f\"Row {index}: Invalid freezer '{freezer}' for material '{material}'. \"\n",
    "                f\"Allowed freezers: {allowed_freezers}\"\n",
    "            )\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "def validate_row(row, index):\n",
    "    errors = []\n",
    "\n",
    "    # --- Required fields ---\n",
    "    for field in REQUIRED_FIELDS:\n",
    "        if row.get(field, \"\").strip() == \"\":\n",
    "            errors.append(f\"Row {index}: Missing value in '{field}'\")\n",
    "\n",
    "    # --- Get material ---\n",
    "    material = row.get(\"material\", \"\").strip().lower()\n",
    "    pos = row.get(\"pos\", \"\").strip()\n",
    "    freezer = row.get(\"freezer\", \"\").strip()\n",
    "    rack = row.get(\"rack\", \"\").strip()\n",
    "    box = row.get(\"box\", \"\").strip()\n",
    "    # --- Material-specific storage rules ---\n",
    "    if material in BIOFLUIDS:  # fluids\n",
    "        if pos not in VALID_POS_FLUIDS:\n",
    "            errors.append(f\"Row {index}: Invalid pos '{pos}' for {material} (must be A1–H10)\")\n",
    "        if freezer not in [\"1\", \"2\", \"3\"]:\n",
    "            errors.append(f\"Row {index}: {material} must be stored in -80 freezers (1–3).\")\n",
    "\n",
    "    elif material in PAXGENE:\n",
    "        if pos not in VALID_POS_PAXGENE:\n",
    "            errors.append(f\"Row {index}: Invalid pos '{pos}' for PAXgene (must be A1–G7)\")\n",
    "        if freezer not in [\"1\", \"2\", \"3\"]:\n",
    "            errors.append(f\"Row {index}: PAXgene must be stored in -80 freezers (1–3).\")\n",
    "\n",
    "    elif material in DNA:\n",
    "        if pos not in VALID_POS_DNA_CELLS_PBMC:\n",
    "            errors.append(f\"Row {index}: Invalid pos '{pos}' for DNA (must be A1–J10)\")\n",
    "        if freezer != \"4deg\":\n",
    "            errors.append(f\"Row {index}: DNA must be stored in 4-degree freezer.\")\n",
    "\n",
    "    elif material in CELLS:\n",
    "        if pos not in VALID_POS_DNA_CELLS_PBMC:\n",
    "            errors.append(f\"Row {index}: Invalid pos '{pos}' for {material} (must be A1–J10)\")\n",
    "        if freezer != \"nitrogen\":\n",
    "            errors.append(f\"Row {index}: {material} must be stored in nitrogen tank.\")\n",
    "\n",
    "    else:\n",
    "        errors.append(f\"Row {index}: Unknown or unsupported material '{material}'\")\n",
    "        \n",
    "    #Fängt Material ab\n",
    "\n",
    "    # --- General checks still valid ---\n",
    "    if rack and rack not in VALID_RACK:\n",
    "        errors.append(f\"Row {index}: Invalid rack '{rack}'\")\n",
    "\n",
    "    if box and box not in VALID_BOX:\n",
    "        errors.append(f\"Row {index}: Invalid box '{box}'\")\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "\n",
    "def validate_file(path, label):\n",
    "    \"\"\"\n",
    "    Validates an entire CSV file for structure and row-level values.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the CSV file\n",
    "        label (str): Descriptive label (e.g. \"Import file\")\n",
    "\n",
    "    Returns:\n",
    "        None – exits with error if validation fails\n",
    "    \"\"\"\n",
    "    print(f\" Checking {label}: {path}\")\n",
    "    headers, rows = read_csv(path)\n",
    "\n",
    "    # Check for required column headers\n",
    "    structure_errors = check_structure(headers)\n",
    "    if structure_errors:\n",
    "        print(f\" Missing required columns in {label}: {structure_errors}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Validate each row\n",
    "    all_errors = []\n",
    "    for i, row in enumerate(rows, start=2):  # Line 1 is header\n",
    "        #calls validate row in for loop\n",
    "        row_errors = validate_row(row, i)\n",
    "        all_errors.extend(row_errors)\n",
    "    \n",
    "    #returns evaluation errors if any of the above occurs\n",
    "    if all_errors:\n",
    "        print(f\" {len(all_errors)} validation error(s) in {label}:\")\n",
    "        for e in all_errors:\n",
    "            print(\" -\", e)\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(f\" {label} passed all validation checks.\\n\")\n",
    "\n",
    "\n",
    "def get_occupied_positions(rows):\n",
    "    \"\"\"\n",
    "    Extracts all occupied positions from a list of data rows.\n",
    "\n",
    "    Args:\n",
    "        rows (List[Dict]): Data rows (e.g. from reference file)\n",
    "\n",
    "    Returns:\n",
    "        Set[Tuple[str, str, str, str]]: Set of (freezer, rack, box, pos)\n",
    "    \"\"\"\n",
    "    positions = set()\n",
    "    for row in rows:\n",
    "        key = (\n",
    "            row.get(\"freezer\", \"\").strip(),\n",
    "            row.get(\"rack\", \"\").strip(),\n",
    "            row.get(\"box\", \"\").strip(),\n",
    "            row.get(\"pos\", \"\").strip(),\n",
    "        )\n",
    "        if all(key):\n",
    "            positions.add(key)\n",
    "    return positions\n",
    "\n",
    "\n",
    "def check_duplicate_positions(import_rows, occupied_positions):\n",
    "    \"\"\"\n",
    "    Compares import rows against existing positions and raises errors for conflicts.\n",
    "\n",
    "    Args:\n",
    "        import_rows (List[Dict]): Rows from the import file\n",
    "        occupied_positions (Set[Tuple]): Set of existing (freezer, rack, box, pos)\n",
    "\n",
    "    Returns:\n",
    "        None – prints and exits if duplicates are found\n",
    "    \"\"\"\n",
    "    duplicate_count = 0\n",
    "    for i, row in enumerate(import_rows, start=2):\n",
    "        key = (\n",
    "            row.get(\"freezer\", \"\").strip(),\n",
    "            row.get(\"rack\", \"\").strip(),\n",
    "            row.get(\"box\", \"\").strip(),\n",
    "            row.get(\"pos\", \"\").strip(),\n",
    "        )\n",
    "        if key in occupied_positions:\n",
    "            print(f\"Row {i}: Position {key} is already occupied in existing data.\")\n",
    "            duplicate_count += 1\n",
    "\n",
    "    if duplicate_count == 0:\n",
    "        print(\"No duplicate positions found between import and reference data.\")\n",
    "    else:\n",
    "        print(f\"{duplicate_count} duplicate position error(s) found.\")\n",
    "\n",
    "    return duplicate_count\n",
    "\n",
    "def check_internal_duplicates(rows, label):\n",
    "    \"\"\"\n",
    "    Checks for duplicate positions within a single file (usually the reference data).\n",
    "\n",
    "    Args:\n",
    "        rows (List[Dict]): Rows to check\n",
    "        label (str): Descriptive name for error output\n",
    "\n",
    "    Returns:\n",
    "        None – prints warning and exits if internal duplicates found\n",
    "    \"\"\"\n",
    "    position_map = {}\n",
    "\n",
    "    for i, row in enumerate(rows, start=2):  # row index starts from line 2\n",
    "        key = (\n",
    "            row.get(\"freezer\", \"\").strip(),\n",
    "            row.get(\"rack\", \"\").strip(),\n",
    "            row.get(\"box\", \"\").strip(),\n",
    "            row.get(\"pos\", \"\").strip(),\n",
    "        )\n",
    "\n",
    "        if all(key):\n",
    "            position_map.setdefault(key, []).append(i)\n",
    "\n",
    "    # Look for positions used more than once\n",
    "    duplicates = {k: v for k, v in position_map.items() if len(v) > 1}\n",
    "    if duplicates:\n",
    "        print(f\" Warning: Duplicate positions found within {label}:\")\n",
    "        for key, indices in duplicates.items():\n",
    "            print(f\" - Position {key} found on rows {indices}\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(f\"No duplicate positions found within {label}.\")\n",
    "        \n",
    "    return \n",
    "\n",
    "        \n",
    "def check_internal_tube_id_duplicates(rows, label):\n",
    "    \"\"\"\n",
    "    Checks for duplicate tube_id values within a single dataset (e.g. the reference file).\n",
    "\n",
    "    Args:\n",
    "        rows (List[Dict]): Data rows to check\n",
    "        label (str): Name of the file being checked (for reporting)\n",
    "\n",
    "    Returns:\n",
    "        None – exits if duplicates are found\n",
    "    \"\"\"\n",
    "    tube_id_map = {}\n",
    "\n",
    "    for i, row in enumerate(rows, start=2):\n",
    "        tid = row.get(\"tube_id\", \"\").strip()\n",
    "        if tid:\n",
    "            tube_id_map.setdefault(tid, []).append(i)\n",
    "\n",
    "    duplicates = {tid: idxs for tid, idxs in tube_id_map.items() if len(idxs) > 1}\n",
    "\n",
    "    if duplicates:\n",
    "        print(f\"Duplicate tube_id(s) found in {label}:\")\n",
    "        for tid, idxs in duplicates.items():\n",
    "            print(f\" - tube_id '{tid}' appears in rows {idxs}\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(f\"All tube_id values in {label} are unique.\")\n",
    "\n",
    "def assign_redcap_ids(import_rows, reference_rows):\n",
    "    \n",
    "    \n",
    "    #### This is probably not necessary - because the study ID on recap will go!!!\n",
    "    \n",
    "    \"\"\"\n",
    "    Assigns REDCap record_id based on pat_id (patient ID).\n",
    "    If pat_id exists in reference, reuse the same REDCap ID.\n",
    "    If not, assign a new one (max ID + 1).\n",
    "    \n",
    "    ##this needs to be changed. The pat ID is the lokal ID of sophie. Wenn ich nur pat_id benutze \n",
    "    was macht dann die Zuordnung? Das ist wirklich tricky. \n",
    "\n",
    "    Args:\n",
    "        import_rows (List[Dict]): Rows to be imported\n",
    "        reference_rows (List[Dict]): Existing REDCap data\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[Dict], int]: Updated import_rows with assigned record_id, \n",
    "                                and number of new record_ids assigned\n",
    "    \"\"\"\n",
    "    pat_to_record = {}\n",
    "    existing_ids = set()\n",
    "\n",
    "    for row in reference_rows:\n",
    "        record_id = row.get(\"record_id\", \"\").strip()\n",
    "        pat_id = row.get(\"pat_id\", \"\").strip()\n",
    "        if record_id and pat_id:\n",
    "            pat_to_record[pat_id] = record_id\n",
    "            existing_ids.add(int(record_id))\n",
    "\n",
    "    next_record_id = max(existing_ids) + 1 if existing_ids else 1\n",
    "    new_ids_count = 0\n",
    "\n",
    "    for row in import_rows:\n",
    "        pat_id = row.get(\"pat_id\", \"\").strip()\n",
    "\n",
    "        if not pat_id:\n",
    "            print(\"Missing pat_id in import row.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        if pat_id in pat_to_record:\n",
    "            row[\"record_id\"] = pat_to_record[pat_id]\n",
    "        else:\n",
    "            row[\"record_id\"] = str(next_record_id)\n",
    "            pat_to_record[pat_id] = str(next_record_id)\n",
    "            next_record_id += 1\n",
    "            new_ids_count += 1\n",
    "\n",
    "    print(\"REDCap record_id assigned based on pat_id.\")\n",
    "    return import_rows, new_ids_count\n",
    "\n",
    "def is_position_occupied(freezer, rack, box, pos, occupied_positions):\n",
    "    \"\"\"\n",
    "    Validates the position and checks if it is occupied.\n",
    "\n",
    "    Args:\n",
    "        freezer (str): Freezer number or name (e.g. \"1\", \"2\", \"nitrogen\")\n",
    "        rack (str): Rack number (1–100)\n",
    "        box (str): Box number (1–100)\n",
    "        pos (str): Position (e.g., A1–H12)\n",
    "        occupied_positions (Set[Tuple[str, str, str, str]]): Known used positions\n",
    "\n",
    "    Returns:\n",
    "        bool: True if occupied, False if available\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If input values are invalid\n",
    "    \"\"\"\n",
    "\n",
    "    freezer = str(freezer).strip()\n",
    "    rack = str(rack).strip()\n",
    "    box = str(box).strip()\n",
    "    pos = str(pos).strip().upper()\n",
    "\n",
    "    valid_freezers = {\"1\", \"2\", \"3\", \"nitrogen\"}\n",
    "    if freezer not in valid_freezers:\n",
    "        raise ValueError(f\"Invalid freezer: '{freezer}' (must be 1, 2, 3, or nitrogen)\")\n",
    "\n",
    "    if not rack.isdigit() or not (1 <= int(rack) <= 100):\n",
    "        raise ValueError(f\"Invalid rack: '{rack}' (must be integer 1–100)\")\n",
    "\n",
    "    if not box.isdigit() or not (1 <= int(box) <= 100):\n",
    "        raise ValueError(f\"Invalid box: '{box}' (must be integer 1–100)\")\n",
    "\n",
    "    if not re.match(r\"^[A-H](?:[1-9]|1[0-2])$\", pos):\n",
    "        raise ValueError(f\"Invalid position: '{pos}' (must be A1–H12)\")\n",
    "\n",
    "    key = (freezer, rack, box, pos)\n",
    "    return key in occupied_positions\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def write_report(filename, import_file, reference_file, import_rows, new_ids_count, duplicate_positions_count):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Biorepository Data Validation Report\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\\n\")\n",
    "        f.write(\"Input files:\\n\")\n",
    "        f.write(f\" - Import: {import_file}\\n\")\n",
    "        f.write(f\" - Reference: {reference_file}\\n\\n\")\n",
    "        f.write(\"Summary:\\n\")\n",
    "        f.write(f\" - Number of import rows processed: {len(import_rows)}\\n\")\n",
    "        f.write(f\" - Number of new pat_ids added: {new_ids_count}\\n\")\n",
    "        f.write(f\" - Number of duplicate positions found: {duplicate_positions_count}\\n\")\n",
    "        record_ids = [int(row[\"record_id\"]) for row in import_rows if \"record_id\" in row]\n",
    "        if record_ids:\n",
    "            f.write(f\" - Assigned record_id range: {min(record_ids)} to {max(record_ids)}\\n\")\n",
    "        f.write(\"\\nWarnings / Errors:\\n\")\n",
    "        f.write(\" - None\\n\\n\")\n",
    "        f.write(\"Validation completed successfully!\\n\")\n",
    "\n",
    "            \n",
    "# === Script Entry Point ===\n",
    "\n",
    "# Step 1: Validate both files\n",
    "#_, import_rows = read_csv(\"import.csv\")\n",
    "#_, ref_rows = read_csv(\"data.csv\")\n",
    "\n",
    "#validate_file(\"import.csv\", \"Import file\")\n",
    "#validate_file(\"data.csv\", \"Reference data file\")\n",
    "\n",
    "# Step 2: Check for occupied positions\n",
    "#occupied = get_occupied_positions(ref_rows)\n",
    "#check_duplicate_positions(import_rows, occupied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59f7f1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checking Import file: /home/aaron/Desktop/BioVal/data/NDEGTest_import_file.csv\n",
      " Import file passed all validation checks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#validate test data\n",
    "validate_file(\"/home/aaron/Desktop/BioVal/data/NDEGTest_import_file.csv\", \"Import file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b41270f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, import_rows = read_csv(\"/home/aaron/Desktop/BioVal/data/NDEGTest_import_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25bbe540",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ref_rows = read_csv(\"/home/aaron/Desktop/BioVal/data/NDEGTest_ref_file.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5af9ed53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checking Import file: /home/aaron/Desktop/BioVal/data/NDEGTest_import_file.csv\n",
      " Import file passed all validation checks.\n",
      "\n",
      " Checking data file: /home/aaron/Desktop/BioVal/data/NDEGTest_ref_file.csv\n",
      " 1 validation error(s) in data file:\n",
      " - Row 9: fibroblasten must be stored in nitrogen tank.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "validate_file(\"/home/aaron/Desktop/BioVal/data/NDEGTest_import_file.csv\", \"Import file\")\n",
    "validate_file(\"/home/aaron/Desktop/BioVal/data/NDEGTest_ref_file.csv\", \"data file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a32c9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate positions found within data file.\n",
      "All tube_id values in Reference data file are unique.\n"
     ]
    }
   ],
   "source": [
    "check_internal_duplicates(ref_rows, \"data file\")\n",
    "check_internal_tube_id_duplicates(ref_rows, \"Reference data file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "275fd2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDCap record_id assigned based on pat_id.\n"
     ]
    }
   ],
   "source": [
    "import_rows, account_id = assign_redcap_ids(import_rows, ref_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c1dca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate positions found between import and reference data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occupied = get_occupied_positions(ref_rows)\n",
    "check_duplicate_positions(import_rows, occupied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23ed5690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position (1, 1, 1, G1) is free. \n"
     ]
    }
   ],
   "source": [
    "occupied = get_occupied_positions(ref_rows)\n",
    "\n",
    "# Check a specific position manually\n",
    "freezer = \"1\"\n",
    "rack = \"1\"\n",
    "box = \"1\"\n",
    "pos = \"G1\"\n",
    "\n",
    "if is_position_occupied(freezer, rack, box, pos, occupied):\n",
    "    print(f\"Position ({freezer}, {rack}, {box}, {pos}) is already occupied. Please try another one.\")\n",
    "else:\n",
    "    print(f\"Position ({freezer}, {rack}, {box}, {pos}) is free. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "895d5265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "\n",
    "def run_validation():\n",
    "    import_path = filedialog.askopenfilename(title=\"Select Import CSV\")\n",
    "    ref_path = filedialog.askopenfilename(title=\"Select Reference CSV\")\n",
    "\n",
    "    if not import_path or not ref_path:\n",
    "        messagebox.showerror(\"Error\", \"Both files must be selected.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Call your existing validation functions here, e.g.:\n",
    "        _, import_rows = read_csv(import_path)\n",
    "        _, ref_rows = read_csv(ref_path)\n",
    "        print(import_path)\n",
    "        validate_file(import_path, \"Import file\")\n",
    "        validate_file(ref_path, \"Reference data\")\n",
    "        import_rows, new_ids_count = assign_redcap_ids(import_rows, ref_rows)\n",
    "        duplicate_positions_count = check_duplicate_positions(import_rows, ref_rows)\n",
    "        messagebox.showinfo(\"Success\", \"Validation completed successfully!\")\n",
    "        \n",
    "        # Ask user where to save the report\n",
    "        report_path = filedialog.asksaveasfilename(\n",
    "            defaultextension=\".txt\",\n",
    "            filetypes=[(\"Text files\", \"*.txt\")],\n",
    "            title=\"Save Validation Report As\"\n",
    "        )\n",
    "        if report_path:\n",
    "            write_report(report_path, import_path, ref_path, import_rows, new_ids_count, duplicate_positions_count)\n",
    "            messagebox.showinfo(\"Success\", f\"Validation completed!\\nReport saved at:\\n{report_path}\")\n",
    "        else:\n",
    "            messagebox.showinfo(\"Success\", \"Validation completed! No report was saved.\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Validation Error\", str(e))\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Biorepository Data Validator\")\n",
    "\n",
    "btn = tk.Button(root, text=\"Run Validation\", command=run_validation)\n",
    "btn.pack(padx=20, pady=20)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25174c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk  # Pillow muss installiert sein: pip install pillow\n",
    "\n",
    "def run_validation():\n",
    "    import_path = filedialog.askopenfilename(title=\"Select Import CSV\")\n",
    "    ref_path = filedialog.askopenfilename(title=\"Select Reference CSV\")\n",
    "\n",
    "    if not import_path or not ref_path:\n",
    "        messagebox.showerror(\"Error\", \"Both files must be selected.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Beispiel: CSV lesen & validieren (Funktionen müssen definiert sein)\n",
    "        _, import_rows = read_csv(import_path)\n",
    "        _, ref_rows = read_csv(ref_path)\n",
    "        validate_file(import_path, \"Import file\")\n",
    "        validate_file(ref_path, \"Reference data\")\n",
    "        import_rows, new_ids_count = assign_redcap_ids(import_rows, ref_rows)\n",
    "        duplicate_positions_count = check_duplicate_positions(import_rows, ref_rows)\n",
    "\n",
    "        # Bericht speichern\n",
    "        report_path = filedialog.asksaveasfilename(\n",
    "            defaultextension=\".txt\",\n",
    "            filetypes=[(\"Text files\", \"*.txt\")],\n",
    "            title=\"Save Validation Report As\"\n",
    "        )\n",
    "        if report_path:\n",
    "            write_report(report_path, import_path, ref_path, import_rows, new_ids_count, duplicate_positions_count)\n",
    "            messagebox.showinfo(\"Success\", f\"Validation completed!\\nReport saved at:\\n{report_path}\")\n",
    "        else:\n",
    "            messagebox.showinfo(\"Success\", \"Validation completed! No report was saved.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Validation Error\", str(e))\n",
    "\n",
    "\n",
    "# --- GUI Setup ---\n",
    "root = tk.Tk()\n",
    "root.title(\"BioVal – Biorepository Validator\")\n",
    "root.geometry(\"600x400\")\n",
    "\n",
    "main_frame = ttk.Frame(root, padding=20)\n",
    "main_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "# --- Optional Image ---\n",
    "try:\n",
    "    img = Image.open(\"logo.jpeg\")  # <-- Dein Bildpfad\n",
    "    img = img.resize((150, 150))\n",
    "    photo = ImageTk.PhotoImage(img)\n",
    "    logo_label = ttk.Label(main_frame, image=photo)\n",
    "    logo_label.image = photo\n",
    "    logo_label.pack(pady=(0, 10))\n",
    "except Exception:\n",
    "    print(\"No image found – skipping logo.\")\n",
    "\n",
    "# --- Welcome Text ---\n",
    "welcome = ttk.Label(\n",
    "    main_frame,\n",
    "    text=(\n",
    "        \"Welcome to BioVal!\\n\\n\"\n",
    "        \"This tool helps you validate biorepository REDCap import files.\\n\"\n",
    "        \"You’ll be prompted to select:\\n\"\n",
    "        \" - A new import CSV file\\n - the data you want to upload\"\n",
    "        \" - A reference dataset for comparison - the data already stored in RedCap \\n\\n\"\n",
    "        \"The tool checks patient IDs, sample positions, and generates a report.\"\n",
    "    ),\n",
    "    justify=\"center\",\n",
    "    wraplength=500\n",
    ")\n",
    "welcome.pack(pady=10)\n",
    "\n",
    "# --- Start Button ---\n",
    "start_button = ttk.Button(main_frame, text=\"Run Validation\", command=run_validation)\n",
    "start_button.pack(pady=20)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814cba31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
