{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e5de916",
   "metadata": {},
   "source": [
    "# Biorepsoitory Validation Code - BioVal \n",
    "\n",
    "Code validates individually the current redcap repository and the biorep data intended to be uploaded.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f2fb955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example für Download von RedCap using requests;\n",
    "import requests\n",
    "\n",
    "\n",
    "api_url = \"https://redcap.uni-heidelberg.de/api/\"\n",
    "api_token = \"19C2091A845FCAB1954F79E7F1A44374\"\n",
    "\n",
    "data = {\n",
    "    'token': api_token,\n",
    "    'content': 'record',\n",
    "    'format': 'json',\n",
    "    'type': 'flat',\n",
    "    'forms[0]': 'biorepository',  # Name des Instruments/Forms\n",
    "    'rawOrLabel': 'raw',\n",
    "    'rawOrLabelHeaders': 'raw',\n",
    "    'exportSurveyFields': 'true',\n",
    "    'exportDataAccessGroups': 'true'\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, data=data)\n",
    "records = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f2e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required python libaries\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "\n",
    "# === Define allowed values and required fields ===\n",
    "REQUIRED_FIELDS = [\n",
    "    \"study_id\", \"lab_id\", \"redcap_event_name\", \"biomaterial\", \"tube_pos\",\n",
    "    \"tube_id\", \"box_id\", \"freezer\", \"rack\", \"box\", \"tube_status\"\n",
    "]\n",
    "\n",
    "#Valid Biomaterial in aliquots\n",
    "VALID_MATERIALS = [\n",
    "    \"csf\", \"csf pellet\", \"dna\", \"edta plasma\", \"fibroblasten\",\n",
    "    \"paxgene\", \"pbmc\", \"serum\", \"urin\"\n",
    "]\n",
    "\n",
    "#Study_id pattern is in the order XXX-XXX-XXX with x being a natural number\n",
    "STUDY_ID_PATTERN = re.compile(r\"^\\d{3}-\\d{3}-\\d{3}$\") #d means here digit betwenn 0-9\n",
    "\n",
    "#Valid redcap events/ #Redcap event name stellvertretend für Arm der Studie\n",
    "VALID_EVENTS = [\"baseline_arm_1\", \"screening_arm_1\", \"follow_up_arm_1\"]\n",
    "#Das muss noch verändert werden\n",
    "\n",
    "VALID_tube_status = [\"\"]\n",
    "\n",
    "#Allowed matrices (positions) per biomaterial\n",
    "VALID_POS_FLUIDS = [f\"{row}{col}\" for row in \"ABCDEFGH\" for col in range(1, 13)]\n",
    "VALID_POS_PAXGENE = [f\"{row}{col}\" for row in \"ABCDEFG\" for col in range(1, 8)]\n",
    "VALID_POS_DNA_CELLS_PBMC =  [f\"{row}{col}\" for row in \"ABCDEFGHJ\" for col in range(1, 11)]\n",
    "\n",
    "#Freezers\n",
    "VALID_FREEZER = [\"1\", \"2\", \"3\", \"nitrogen\", \"4deg\"]\n",
    "\n",
    "#Boxes (same for all, unless exception later)\n",
    "VALID_BOX = [str(i) for i in range(1, 43)]  # 1–42\n",
    "\n",
    "#Racks\n",
    "VALID_RACK = [str(i) for i in range(1, 101)]  # 1–100\n",
    "\n",
    "\n",
    "\n",
    "STORAGE_RULES = {\n",
    "    \"BIOFLUID\": {\n",
    "        \"freezers\": [\"1\", \"2\", \"3\"],\n",
    "        \"racks\": list(map(str, range(1, 8))),   # 1–7\n",
    "        \"boxes_per_rack\": 7,\n",
    "        \"rows\": list(\"ABCDEFGH\"),\n",
    "        \"cols\": list(map(str, range(1, 13))),   # 1–12\n",
    "    },\n",
    "\n",
    "    \"PAXGENE\": {\n",
    "        \"freezers\": [\"1\", \"2\", \"3\"],\n",
    "        \"racks\": list(map(str, range(1, 8))),\n",
    "        \"boxes_per_rack\": 7,\n",
    "        \"rows\": list(\"ABCDEFG\"),\n",
    "        \"cols\": list(map(str, range(1, 8))),    # 1–7\n",
    "    },\n",
    "\n",
    "    \"DNA\": {\n",
    "        \"freezers\": [\"4deg\"],\n",
    "        \"racks\": list(map(str, range(1, 8))),\n",
    "        \"boxes_per_rack\": 7,\n",
    "        \"rows\": list(\"ABCDEFGHIJ\"),\n",
    "        \"cols\": list(map(str, range(1, 11))),   # 1–10\n",
    "    },\n",
    "\n",
    "    \"CELLS\": {\n",
    "        \"freezers\": [\"nitrogen\"],\n",
    "        \"racks\": list(map(str, range(1, 8))),   # assumption for now\n",
    "        \"boxes_per_rack\": 14,                   # boxnum fortlaufend\n",
    "        \"rows\": list(\"ABCDEFGHIJ\"),\n",
    "        \"cols\": list(map(str, range(1, 11))),\n",
    "    },\n",
    "}\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a950a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Functions === \n",
    "# Helperfunction, Validation function \n",
    "\n",
    "def read_csv(path):\n",
    "    \"\"\"\n",
    "    Helper function. Reads a CSV file and returns its headers and row data.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the CSV file\n",
    "\n",
    "    Returns:\n",
    "        tuple: (List[str] headers, List[Dict] rows)\n",
    "    \"\"\"\n",
    "    with open(path, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        rows = list(reader)\n",
    "    return reader.fieldnames, rows\n",
    "\n",
    "\n",
    "def check_structure(headers):\n",
    "    \"\"\"\n",
    "    Validation function. Checks whether all required fields are present in the CSV headers.\n",
    "\n",
    "    Args:\n",
    "        headers (List[str]): Column headers from the CSV\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of missing required fields (if any)\n",
    "    \"\"\"\n",
    "    missing = [field for field in REQUIRED_FIELDS if field not in headers]\n",
    "    return missing\n",
    "\n",
    "\n",
    "\n",
    "def validate_row(row, index):\n",
    "    \"\"\"\n",
    "    Validation function. Validates a single row for required values and correct formats if needed.\n",
    "    The validation process can be done for any type of data - to be uploaded ones or the RedCap Reference\n",
    "    data. \n",
    "    \n",
    "    Steps: \n",
    "    (1) Checks again for the Required fields (it does that to safe it as error message)\n",
    "    (2) Checks the materialspecific storage rules. Checks \n",
    "    (3) \n",
    "    Args:\n",
    "        row (Dict): A row from the CSV as a dictionary\n",
    "        index (int): The row number (for error reporting)\n",
    "\n",
    "    Returns:\n",
    "        errors List[str]: List of validation error messages for this row\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "\n",
    "    # (1) Required fields   #das ist aktuell doppelt\n",
    "    for field in REQUIRED_FIELDS:\n",
    "        if row.get(field, \"\").strip() == \"\":\n",
    "            errors.append(f\"Row {index}: Missing value in '{field}'\")\n",
    "    # (2) Checks the Biomaterialspecific storage rules\n",
    "    # Get material \n",
    "    biomaterial = row.get(\"biomaterial\", \"\").strip().lower()\n",
    "    tube_pos = row.get(\"tube_pos\", \"\").strip()\n",
    "    freezer = row.get(\"freezer\", \"\").strip()\n",
    "    rack = row.get(\"rack\", \"\").strip()\n",
    "    box = row.get(\"box\", \"\").strip()\n",
    "    #  Material-specific storage rules - safe in errors if there is a mistake\n",
    "    if biomaterial in BIOFLUIDS:  # fluids\n",
    "        if tube_pos not in VALID_POS_FLUIDS:\n",
    "            errors.append(f\"Row {index}: Invalid tube-pos '{tub_pos}' for {biomaterial} (must be A1–H10)\")\n",
    "        if freezer not in [\"1\", \"2\", \"3\"]:\n",
    "            errors.append(f\"Row {index}: {biomaterial} must be stored in -80 freezers (1–3).\")\n",
    "\n",
    "    elif biomaterial in PAXGENE:\n",
    "        if tube_pos not in VALID_POS_PAXGENE:\n",
    "            errors.append(f\"Row {index}: Invalid tube-pos '{tube_pos}' for PAXgene (must be A1–G7)\")\n",
    "        if freezer not in [\"1\", \"2\", \"3\"]:\n",
    "            errors.append(f\"Row {index}: PAXgene must be stored in -80 freezers (1–3).\")\n",
    "\n",
    "    elif biomaterial in DNA:\n",
    "        if tube_pos not in VALID_POS_DNA_CELLS_PBMC:\n",
    "            errors.append(f\"Row {index}: Invalid tube-pos '{tube_pos}' for DNA (must be A1–J10)\")\n",
    "        if freezer != \"4deg\":\n",
    "            errors.append(f\"Row {index}: DNA must be stored in 4-degree freezer.\")\n",
    "\n",
    "    elif biomaterial in CELLS:\n",
    "        if tube_pos not in VALID_POS_DNA_CELLS_PBMC:\n",
    "            errors.append(f\"Row {index}: Invalid tube-pos '{tube_pos}' for {biomaterial} (must be A1–J10)\")\n",
    "        if freezer != \"nitrogen\":\n",
    "            errors.append(f\"Row {index}: {biomaterial} must be stored in nitrogen tank.\")\n",
    "    #Eception\n",
    "    else:\n",
    "        errors.append(f\"Row {index}: Unknown or unsupported material '{biomaterial}'\")\n",
    "        \n",
    "    # Please hier noch den Check einfügen für den Tube_status\n",
    "\n",
    "    # General checks still valid - hier muss eigentlich unterschieden werden zwischen Racks \n",
    "    # da z.B. cells ja in den Tank gehen und da ist die Struktur anders\n",
    "    if rack and rack not in VALID_RACK:\n",
    "        errors.append(f\"Row {index}: Invalid rack '{rack}'\")\n",
    "\n",
    "    if box and box not in VALID_BOX:\n",
    "        errors.append(f\"Row {index}: Invalid box '{box}'\")\n",
    "\n",
    "    return errors\n",
    "        \n",
    "def validate_file(path, label):\n",
    "    \"\"\"\n",
    "    Core function from GUI. Validates an entire CSV file and raises ValueError if anything is wrong. The validation\n",
    "    is done line by line.\n",
    "    \n",
    "    Args:\n",
    "        path (str): Path to the CSV file\n",
    "        label (str): Descriptive label (e.g. \"Import file\")\n",
    "\n",
    "    Returns:\n",
    "        rows List[dict]: List of rows from the to be validated file. The row is handeled like a dictionary.\n",
    "    \"\"\"\n",
    "    print(f\" Checking {label}: {path}\")\n",
    "    headers, rows = read_csv(path)\n",
    "    \n",
    "    # Check for required column headers\n",
    "    structure_errors = check_structure(headers)\n",
    "    if structure_errors:\n",
    "        raise ValueError(f\"Missing required columns in {label}: {structure_errors}\")\n",
    "    #errors hier definieren und dann mitgeben anstatt den Validation check for required columns doppelt zu machen\n",
    "    # Validate each row; could be done vectorized probably even faster but for now it is ok!\n",
    "    for i, row in enumerate(rows, start=2):\n",
    "        validate_row(row, i)  # will raise immediately if invalid\n",
    "\n",
    "    print(f\" {label} passed all validation checks.\\n\")\n",
    "    return rows  # return rows if valid\n",
    "\n",
    "#hier muss auch der status integriert werden\n",
    "def get_occupied_positions(rows):\n",
    "    \"\"\"\n",
    "    Core function from GUI. Extracts all occupied positions from a list of data rows.\n",
    "\n",
    "    Args:\n",
    "        rows (List[Dict]): Data rows (e.g. from reference file)\n",
    "\n",
    "    Returns:\n",
    "        positions Set[Tuple[str, str, str, str]]: Set of (freezer, rack, box, pos)\n",
    "    \"\"\"\n",
    "    positions = set()\n",
    "    for row in rows:\n",
    "        key = (\n",
    "            row.get(\"freezer\", \"\").strip(),\n",
    "            row.get(\"rack\", \"\").strip(),\n",
    "            row.get(\"box\", \"\").strip(),\n",
    "            row.get(\"tube_pos\", \"\").strip(),\n",
    "        )\n",
    "        if all(key):\n",
    "            positions.add(key)\n",
    "    return positions\n",
    "\n",
    "\n",
    "\n",
    "def get_occupied_positions(rows):\n",
    "    \"\"\"\n",
    "    Core function from GUI. Extracts all occupied positions from a list of data rows, only if\n",
    "    they match the tube_status stored. \n",
    "\n",
    "    Args:\n",
    "        rows (List[Dict]): Data rows (e.g. from reference file)\n",
    "\n",
    "    Returns:\n",
    "        positions Set[Tuple[str, str, str, str]]: Set of (freezer, rack, box, pos)\n",
    "    \"\"\"\n",
    "    positions = set()\n",
    "\n",
    "    for row in rows:\n",
    "        status = row.get(\"tube_status\", \"\").strip()\n",
    "\n",
    "        # Only \"Stored\" tubes occupy a position\n",
    "        if status != \"1\":\n",
    "            continue\n",
    "\n",
    "        key = (\n",
    "            row.get(\"freezer\", \"\").strip(),\n",
    "            row.get(\"rack\", \"\").strip(),\n",
    "            row.get(\"box\", \"\").strip(),\n",
    "            row.get(\"tube_pos\", \"\").strip(),\n",
    "        )\n",
    "\n",
    "        if all(key):\n",
    "            positions.add(key)\n",
    "\n",
    "    return positions\n",
    "\n",
    "\n",
    "\n",
    "def check_duplicate_positions(import_rows, occupied_positions, label=\"Import vs Reference\"):\n",
    "    \"\"\"\n",
    "    Core function from GUI. Compares import rows against existing positions and raises errors for conflicts.\n",
    "\n",
    "    Args:\n",
    "        import_rows (List[Dict]): Rows from the import file\n",
    "        occupied_positions (Set[Tuple]): Set of existing (freezer, rack, box, pos)\n",
    "        label (str): Descriptive name for error reporting\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if duplicate positions are found or 0 if none are found\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    for i, row in enumerate(import_rows, start=2):\n",
    "        key = (\n",
    "            row.get(\"freezer\", \"\").strip(),\n",
    "            row.get(\"rack\", \"\").strip(),\n",
    "            row.get(\"box\", \"\").strip(),\n",
    "            row.get(\"tube_pos\", \"\").strip(),\n",
    "        )\n",
    "        if key in occupied_positions:\n",
    "            errors.append(f\"Row {i}: Position {key} is already occupied in reference data.\")\n",
    "\n",
    "    if errors:\n",
    "        raise ValueError(f\"{label} – {len(errors)} duplicate position error(s):\\n\" + \"\\n\".join(errors))\n",
    "    else:\n",
    "        print(f\"No duplicate positions found between import and reference data.\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "def check_internal_duplicates(rows, label):\n",
    "    \"\"\"\n",
    "    Core function in GUI. Checks for duplicate positions within a single file.\n",
    "\n",
    "    Args:\n",
    "        rows (List[Dict]): Rows to check\n",
    "        label (str): Descriptive name for error output\n",
    "\n",
    "    Returns:\n",
    "        ValueError: if internal duplicates found otherwise returns\n",
    "    \"\"\"\n",
    "    position_map = {}\n",
    "\n",
    "    for i, row in enumerate(rows, start=2):  # row index starts from line 2\n",
    "        key = (\n",
    "            row.get(\"freezer\", \"\").strip(),\n",
    "            row.get(\"rack\", \"\").strip(),\n",
    "            row.get(\"box\", \"\").strip(),\n",
    "            row.get(\"tube_pos\", \"\").strip(),\n",
    "        )\n",
    "\n",
    "        if all(key):\n",
    "            position_map.setdefault(key, []).append(i)\n",
    "\n",
    "    # Look for positions used more than once\n",
    "    duplicates = {k: v for k, v in position_map.items() if len(v) > 1}\n",
    "    \n",
    "    # Duplicates Handling\n",
    "    if duplicates: \n",
    "        details = \"\\n\".join([f\" - Position {k} found on rows {v}\" for k, v in duplicates.items()])\n",
    "        raise ValueError(f\"Duplicate positions found within {label}:\\n{details}\")\n",
    "    else:\n",
    "        print(f\"No duplicate positions found within {label}.\")\n",
    "        \n",
    "    return \n",
    "\n",
    "def check_internal_tube_id_duplicates(rows, label):\n",
    "    \"\"\"\n",
    "    Validation function. Checks for duplicate tube_id values within a single dataset (e.g. the reference file).\n",
    "\n",
    "    Args:\n",
    "        rows (List[Dict]): Data rows to check\n",
    "        label (str): Name of the file being checked (for reporting)\n",
    "\n",
    "    Returns:\n",
    "        None: exits if duplicates are found\n",
    "    \"\"\"\n",
    "    tube_id_map = {}\n",
    "\n",
    "    for i, row in enumerate(rows, start=2):\n",
    "        tid = row.get(\"tube_id\", \"\").strip()\n",
    "        if tid:\n",
    "            tube_id_map.setdefault(tid, []).append(i)\n",
    "\n",
    "    duplicates = {tid: idxs for tid, idxs in tube_id_map.items() if len(idxs) > 1}\n",
    "\n",
    "    if duplicates:\n",
    "        print(f\"Duplicate tube_id(s) found in {label}:\")\n",
    "        for tid, idxs in duplicates.items():\n",
    "            print(f\" - tube_id '{tid}' appears in rows {idxs}\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(f\"All tube_id values in {label} are unique.\")\n",
    "\n",
    "def write_report(filename, import_file, reference_file, labid_messages =None, import_rows=None,\n",
    "                 errors=None, recommendation=None):\n",
    "    \"\"\"\n",
    "    Writes a validation report to a text file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to save the report\n",
    "        import_file (str): Path to import CSV\n",
    "        reference_file (str): Path to reference CSV\n",
    "        import_rows (List[Dict], optional): Imported rows, for summary stats\n",
    "        errors (List[str], optional): List of error messages collected\n",
    "        recommendation (str, optional): Recommendation to upload or not\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Biorepository Data Validation Report\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "\n",
    "        f.write(\"Input files:\\n\")\n",
    "        f.write(f\" - Import: {import_file}\\n\")\n",
    "        f.write(f\" - Reference: {reference_file}\\n\\n\")\n",
    "\n",
    "        # Summary\n",
    "        f.write(\"Summary:\\n\")\n",
    "        if import_rows:\n",
    "            f.write(f\" - Number of import rows processed: {len(import_rows)}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        # Errors\n",
    "        f.write(\"Errors / Warnings:\\n\")\n",
    "        if errors and len(errors) > 0:\n",
    "            for e in errors:\n",
    "                f.write(f\" - {e}\\n\")\n",
    "        else:\n",
    "            f.write(\" - None\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # Lab Id assignment\n",
    "        f.write(\"Lab Id assignment\")\n",
    "        if labid_messages: \n",
    "            for msg in id_assignment_messages:\n",
    "                f.write(f\" - {msg}\\n\")\n",
    "        else:\n",
    "            f.write(\" - None\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # Recommendation\n",
    "        f.write(\"Recommendation:\\n\")\n",
    "        if recommendation:\n",
    "            f.write(f\"{recommendation}\\n\")\n",
    "        else:\n",
    "            f.write(\"No recommendation provided.\\n\")\n",
    "\n",
    "\n",
    "def download_reference_from_redcap(api_url, api_token, form_name=\"biorepository\"):\n",
    "    \"\"\"\n",
    "    Helper function form GUI. Downloads reference data directly from REDCap via API.\n",
    "\n",
    "    Args:\n",
    "        api_url (str): The REDCap API endpoint URL\n",
    "        api_token (str): Your REDCap API token\n",
    "        form_name (str): The name of the REDCap instrument to export\n",
    "\n",
    "    Returns:\n",
    "        records List[Dict]: A list of flat REDCap records\n",
    "    \"\"\"\n",
    "\n",
    "    data = {\n",
    "        'token': api_token,\n",
    "        'content': 'record',\n",
    "        'format': 'json',\n",
    "        'type': 'flat',\n",
    "        'forms[0]': form_name,\n",
    "        'rawOrLabel': 'raw',\n",
    "        'rawOrLabelHeaders': 'raw',\n",
    "        'exportSurveyFields': 'true',\n",
    "        'exportDataAccessGroups': 'true'\n",
    "    }\n",
    "    #EAFP style\n",
    "    try:\n",
    "        response = requests.post(api_url, data=data, timeout=20)\n",
    "\n",
    "        # API communication errors\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"REDCap API returned status code {response.status_code}: {response.text}\")\n",
    "\n",
    "        # JSON decode errors \n",
    "        try:\n",
    "            records = response.json()\n",
    "        except Exception:\n",
    "            raise Exception(\"Could not decode JSON returned from REDCap. Response was:\\n\" + response.text)\n",
    "\n",
    "        if not isinstance(records, list):\n",
    "            raise Exception(\"Unexpected API response format. Expected list of records.\")\n",
    "\n",
    "        print(f\"Successfully downloaded {len(records)} records from REDCap.\")\n",
    "        return records\n",
    "\n",
    "    except requests.exceptions.ConnectTimeout:\n",
    "        raise Exception(\"Connection timed out while contacting REDCap API.\")\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        raise Exception(\"Could not connect to REDCap. Check VPN, URL, or internet.\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"REDCap API error: {str(e)}\")\n",
    "\n",
    "\n",
    "def save_data_as_csv(records, out_path):\n",
    "    \"\"\"\n",
    "    Helper function form GUI. Safes data from to csv at out_path.\n",
    "\n",
    "    Args:\n",
    "        records List[Dict]: A list of flat REDCap records\n",
    "        out_path (str): Storage path\n",
    "    \"\"\"\n",
    "    if not records:\n",
    "        raise Exception(\"No records to write.\")\n",
    "\n",
    "    keys = sorted(records[0].keys())\n",
    "\n",
    "    with open(out_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(records)\n",
    "\n",
    "    print(f\"Data saved to {out_path}\")\n",
    "    \n",
    "    \n",
    "def build_patient_map(reference_rows):\n",
    "    \"\"\"\n",
    "    Helper function. Builds study_id → lab_patient_id mapping from REDCap reference data.\n",
    "    \n",
    "    study_to_lab \n",
    "    \n",
    "    Args:\n",
    "        refernce_rows: records form Reference Dataset. Usually csv file.\n",
    "\n",
    "    Returns:\n",
    "        study_to_lab List[Dict]: Mapping from study_id -> pat_id\n",
    "        lab_to_study List[Dict]: Mapping from lab_id -> study_id\n",
    "        used_lab_ids List: list of used lab ids. \n",
    "    \"\"\"\n",
    "\n",
    "    study_to_lab = {}\n",
    "    lab_to_study = {}\n",
    "    used_lab_ids = set()\n",
    "\n",
    "    for row in reference_rows:\n",
    "        study_id = row.get(\"study_id\", \"\").strip()\n",
    "        lab_id = row.get(\"lab_id\", \"\").strip()\n",
    "\n",
    "        if not study_id or not lab_id:\n",
    "            continue\n",
    "         \n",
    "        if study_id in study_to_lab and study_to_lab[study_id] != lab_id:\n",
    "            raise Exception(f\"Study ID {study_id} has multiple lab IDs.\")\n",
    "\n",
    "        if lab_id in lab_to_study and lab_to_study[lab_id] != study_id:\n",
    "            raise Exception(f\"Lab ID {lab_id} is linked to multiple study IDs.\")\n",
    "\n",
    "        lab_to_study[lab_id] = study_id\n",
    "        study_to_lab[study_id] = lab_id\n",
    "        used_lab_ids.add(int(lab_id))\n",
    "\n",
    "    return study_to_lab, lab_to_study, used_lab_ids\n",
    "\n",
    "def get_next_lab_patient_id(used_lab_ids):\n",
    "    \"\"\"\n",
    "    Helper function. Gets next available Lab ID.\n",
    "    \n",
    "    Args:\n",
    "        used_lab_ids List: list of used lab ids. \n",
    "    Returns:\n",
    "        Float: next available Lab ID \n",
    "    \"\"\"\n",
    "    #vielleicht sollte ich hier lieber einen string testen? ich will ja 00001 und nicht 1 \n",
    "    if not used_lab_ids:\n",
    "        return 1\n",
    "    return max(used_lab_ids) + 1\n",
    "\n",
    "def assign_lab_patient_ids(import_rows, reference_rows):\n",
    "    \"\"\"\n",
    "    Core function from Gui. Assigns lab_id based on study_id and reference data. The lab id does not need to be plugged in; \n",
    "    BioVal finds the last lab id in the reference data and automatically asigns to the to be importated\n",
    "    data the new lab id. \n",
    "    \n",
    "    Args:\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    # !!!!!!!!!!!!!!! Make absolutley sure, that the labID is never filled in; also wenn mal eine \"frei\" wird sozusagen\n",
    "    study_to_lab, lab_to_study, used_lab_ids = build_patient_map(reference_rows)\n",
    "    next_id = get_next_lab_patient_id(used_lab_ids)\n",
    "    labid_messages = [f\"Next available lab patient ID: {next_id:05d}\"]\n",
    "    \n",
    "    #ich checke hier actuell nur die imported rows! \n",
    "    for i, row in enumerate(import_rows, start=2):\n",
    "        study_id = row.get(\"study_id\", \"\").strip()\n",
    "\n",
    "        if not study_id:\n",
    "            raise Exception(f\"Row {i}: Missing study_id\")\n",
    "\n",
    "        if not STUDY_ID_PATTERN.match(study_id):\n",
    "            raise Exception(f\"Row {i}: Invalid study_id format '{study_id}'\")\n",
    "\n",
    "        if study_id in study_to_lab:\n",
    "            row[\"lab_id\"] = study_to_lab[study_id]\n",
    "        else:\n",
    "            lab_id = f\"{next_id:05d}\"\n",
    "            row[\"lab_id\"] = lab_id\n",
    "            study_to_lab[study_id] = lab_id\n",
    "            used_lab_ids.add(next_id)\n",
    "            next_id += 1\n",
    "            labid_messages.append(\n",
    "                f\"Assigned lab patient ID {lab_id} to study ID {study_id}\"\n",
    "            )\n",
    "\n",
    "    return import_rows, labid_messages\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def is_position_occupied(freezer, rack, box, pos, occupied_positions):\n",
    "    \"\"\"\n",
    "    Validation function. Validates the position and checks if it is occupied.\n",
    "\n",
    "    Args:\n",
    "        freezer (str): Freezer number or name (e.g. \"1\", \"2\", \"nitrogen\")\n",
    "        rack (str): Rack number (1–100)\n",
    "        box (str): Box number (1–100)\n",
    "        pos (str): Position (e.g., A1–H12)\n",
    "        occupied_positions (Set[Tuple[str, str, str, str]]): Known used positions\n",
    "\n",
    "    Returns:\n",
    "        bool: True if occupied, False if available\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If input values are invalid\n",
    "    \"\"\"\n",
    "\n",
    "    freezer = str(freezer).strip()\n",
    "    rack = str(rack).strip()\n",
    "    box = str(box).strip()\n",
    "    pos = str(pos).strip().upper()\n",
    "\n",
    "    valid_freezers = {\"1\", \"2\", \"3\", \"nitrogen\"}\n",
    "    if freezer not in valid_freezers:\n",
    "        raise ValueError(f\"Invalid freezer: '{freezer}' (must be 1, 2, 3, or nitrogen)\")\n",
    "\n",
    "    if not rack.isdigit() or not (1 <= int(rack) <= 100):\n",
    "        raise ValueError(f\"Invalid rack: '{rack}' (must be integer 1–100)\")\n",
    "\n",
    "    if not box.isdigit() or not (1 <= int(box) <= 100):\n",
    "        raise ValueError(f\"Invalid box: '{box}' (must be integer 1–100)\")\n",
    "\n",
    "    if not re.match(r\"^[A-H](?:[1-9]|1[0-2])$\", pos):\n",
    "        raise ValueError(f\"Invalid position: '{pos}' (must be A1–H12)\")\n",
    "\n",
    "    key = (freezer, rack, box, pos)\n",
    "    return key in occupied_positions\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "def generate_positions_for_material(material_key):\n",
    "    \"\"\"\n",
    "    Helper function. Generates the matrices for different Biomaterial according to the freezer\n",
    "    set-ups.\n",
    "\n",
    "    Args:\n",
    "        material_key (str): Biomaterial intended to store.\n",
    "\n",
    "    Returns:\n",
    "        positions (list): \n",
    "    Raises:\n",
    "        ValueError: If input values are invalid #not yet but would be good\n",
    "    \"\"\"\n",
    "    rules = STORAGE_RULES[material_key]\n",
    "    positions = set()\n",
    "\n",
    "    for freezer, rack in product(rules[\"freezers\"], rules[\"racks\"]):\n",
    "        for box in map(str, range(1, rules[\"boxes_per_rack\"] + 1)):\n",
    "            for row, col in product(rules[\"rows\"], rules[\"cols\"]):\n",
    "                pos = f\"{row}{col}\"\n",
    "                positions.add((freezer, rack, box, pos))\n",
    "\n",
    "    return positions\n",
    "\n",
    "\n",
    "def get_available_positions(material_key, reference_rows):\n",
    "    \"\"\"\n",
    "    GUI core Function. Generates the matrices for different Biomaterial according to the freezer\n",
    "    set-ups. Calculates which positions are occupied and returns the sorted positions.\n",
    "\n",
    "    Args:\n",
    "        material_key (str): Biomaterial intended to store.\n",
    "        reference_rows (List[Dict]): Existing REDCap data\n",
    " \n",
    "    Returns:\n",
    "        positions (list): Avaialbe positions for the selected Biomaterial.    \n",
    "    \"\"\"\n",
    "    all_pos = generate_positions_for_material(material_key)\n",
    "    occupied = get_occupied_positions(reference_rows)\n",
    "    return sorted(all_pos - occupied)\n",
    "\n",
    "FREEZER_ORDER = {\n",
    "    \"1\": 1,\n",
    "    \"2\": 2,\n",
    "    \"3\": 3,\n",
    "    \"4deg\": 4,\n",
    "    \"nitrogen\": 5,\n",
    "}\n",
    "\n",
    "def split_pos(pos):\n",
    "    \"\"\"\n",
    "    Helper function. Splits the tube position in row and column such that the sorting algorithm\n",
    "    is able to sort the positions after row and col sepperately. \n",
    "\n",
    "    Args:\n",
    "        pos (list): Available positions\n",
    " \n",
    "    Returns:\n",
    "        row (str): Row position in box depends on matrix  \n",
    "        col (int): Col position in box depends on matrix\n",
    "    \"\"\"\n",
    "    row = pos[0]\n",
    "    col = int(pos[1:])\n",
    "    return row, col\n",
    "\n",
    "\n",
    "def position_sort_key(item):\n",
    "    \"\"\"\n",
    "    Helper function. Generates a sort key for Python inbuild sorted() function, such that the \n",
    "    freezer position is sorted via freezer, rack, box, pos for any particular Biofluid.\n",
    "\n",
    "    Args:\n",
    "        item: \n",
    " \n",
    "    Returns:\n",
    "        positions (list): sorted positions       \n",
    "    \"\"\"\n",
    "    freezer, rack, box, pos = item\n",
    "    row, col = split_pos(pos)  #seperates it in for example A and 7 instead of A7, so that the sorting works \n",
    "    #print(type(col))\n",
    "    return (\n",
    "        FREEZER_ORDER.get(freezer, 99),\n",
    "        int(rack),\n",
    "        int(box),\n",
    "        row,\n",
    "        col,\n",
    "    )\n",
    "\n",
    "def pos_sort_key(pos):\n",
    "    row = pos[0]\n",
    "    col = int(pos[1:])\n",
    "    return (row, col)\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "def save_positions_to_csv(path, positions):\n",
    "    \"\"\"\n",
    "    Saves selected positions to CSV.\n",
    "\n",
    "    Columns:\n",
    "    freezer, rack, box, pos\n",
    "    \"\"\"\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"freezer\", \"rack\", \"box\", \"pos\"])\n",
    "        \n",
    "        for freezer, rack, box, pos in positions:\n",
    "            \n",
    "            freezer_code = FREEZER_ORDER[freezer]\n",
    "\n",
    "            \n",
    "            writer.writerow([pos, box, rack, freezer_code])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bde1d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded 8 records from REDCap.\n"
     ]
    }
   ],
   "source": [
    "#### Generate the available positions\n",
    "#downloads Biorep\n",
    "\n",
    "#ref_rows = read_csv(\"/home/aaron/Desktop/BioVal/data/Ref_file_test.csv\")\n",
    "reference_rows = download_reference_from_redcap(api_url, api_token)\n",
    "#save_reference_as_csv(records, \"/home/aaron/Desktop/BioVal/data/Ref_file_test.csv\"\n",
    "available_positions = get_available_positions(\"BIOFLUID\", reference_rows)\n",
    "\n",
    "available_positions = sorted(available_positions, key=position_sort_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5313800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '1', '1', 'A2'),\n",
       " ('1', '1', '1', 'A3'),\n",
       " ('1', '1', '1', 'A4'),\n",
       " ('1', '1', '1', 'A5'),\n",
       " ('1', '1', '1', 'A6'),\n",
       " ('1', '1', '1', 'A7'),\n",
       " ('1', '1', '1', 'A8'),\n",
       " ('1', '1', '1', 'A9'),\n",
       " ('1', '1', '1', 'A10'),\n",
       " ('1', '1', '1', 'A11'),\n",
       " ('1', '1', '1', 'A12'),\n",
       " ('1', '1', '1', 'B1'),\n",
       " ('1', '1', '1', 'B2'),\n",
       " ('1', '1', '1', 'B3'),\n",
       " ('1', '1', '1', 'B4'),\n",
       " ('1', '1', '1', 'B5'),\n",
       " ('1', '1', '1', 'B6'),\n",
       " ('1', '1', '1', 'B7'),\n",
       " ('1', '1', '1', 'B8'),\n",
       " ('1', '1', '1', 'B9'),\n",
       " ('1', '1', '1', 'B10'),\n",
       " ('1', '1', '1', 'B11'),\n",
       " ('1', '1', '1', 'B12'),\n",
       " ('1', '1', '1', 'C1'),\n",
       " ('1', '1', '1', 'C2'),\n",
       " ('1', '1', '1', 'C3'),\n",
       " ('1', '1', '1', 'C4'),\n",
       " ('1', '1', '1', 'C5'),\n",
       " ('1', '1', '1', 'C6'),\n",
       " ('1', '1', '1', 'C7'),\n",
       " ('1', '1', '1', 'C8'),\n",
       " ('1', '1', '1', 'C9'),\n",
       " ('1', '1', '1', 'C10'),\n",
       " ('1', '1', '1', 'C11'),\n",
       " ('1', '1', '1', 'C12'),\n",
       " ('1', '1', '1', 'D1'),\n",
       " ('1', '1', '1', 'D2'),\n",
       " ('1', '1', '1', 'D3'),\n",
       " ('1', '1', '1', 'D4'),\n",
       " ('1', '1', '1', 'D5')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_pos = select_positions_for_material(\"BIOFLUID\", available_positions)\n",
    "available_pos\n",
    "#save_positions_to_csv(\"/home/aaron/Desktop/BioVal/data/available_positions.csv\",available_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a75e8c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_positions_for_material(material, available_positions):\n",
    "    \"\"\"\n",
    "    GUI core function. Selects available positions based on STORAGE_RULES for BIOFLUID, PAXGENE, DNA\n",
    "    and CELLS. \n",
    "\n",
    "    Args:\n",
    "        material (str): Biomaterial (must exist in STORAGE_RULES (Global var))\n",
    "        available_positions (list): List of available positions\n",
    "\n",
    "    Returns:\n",
    "        list: Selected positions\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If material has no storage rule\n",
    "    \"\"\"\n",
    "    material = material.strip().upper()\n",
    "\n",
    "    if material not in STORAGE_RULES:\n",
    "        raise ValueError(\n",
    "            f\"Material '{material}' has no defined STORAGE_RULE.\"\n",
    "        )\n",
    "\n",
    "    # Biofluids get special selection logic; 15 at least in one box.\n",
    "    if material == \"BIOFLUID\":\n",
    "        return select_positions_biofluids(available_positions)\n",
    "\n",
    "    # All others use single-position logic because it is more likely to have single aliquots\n",
    "    return select_positions_single(material, available_positions)\n",
    "\n",
    "\n",
    "    \n",
    "def select_positions_single(material, available_positions, positionnumber = 20):\n",
    "    \"\"\"\n",
    "    Helper function. Selects single positions (default 20) sequentially for PAXGENE, CELLS and DNA. \n",
    "\n",
    "\n",
    "    Args: \n",
    "        material (str): Biomaterial (must exist in STORAGE_RULES (Global var))\n",
    "        available_positions (list): List of available positions\n",
    "    Returns:\n",
    "        list: Selected sorted positions    \n",
    "    \"\"\"\n",
    "    return sorted(available_positions, key=position_sort_key)[:positionnumber]\n",
    "\n",
    "\n",
    "def select_positions_biofluids(available_positions):\n",
    "    \"\"\"\n",
    "    Helper function. Selects positions per box sequentially for BIOFLUIDS. \n",
    "\n",
    "    Args: \n",
    "        available_positions (list): List of available positions\n",
    "    Returns:\n",
    "        list: Selected sorted positions    \n",
    "    \"\"\"\n",
    "    box_map = group_positions_by_box(available_positions)\n",
    "\n",
    "    selected = []\n",
    "    box_count = 0\n",
    "\n",
    "    for (freezer, rack, box), positions in box_map.items():\n",
    "        if len(positions) < 15:\n",
    "            continue\n",
    "\n",
    "        box_count += 1\n",
    "        for pos in positions:\n",
    "            selected.append((freezer, rack, box, pos))\n",
    "            if len(selected) >= 40:\n",
    "                return selected\n",
    "\n",
    "        if box_count >= 2:\n",
    "            break\n",
    "\n",
    "    return selected\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def group_positions_by_box(positions):\n",
    "    \"\"\"\n",
    "    Helper function. Groups positions by (freezer, rack, box).\n",
    "    args\n",
    "        positions (list): List of available positions\n",
    "    Returns:\n",
    "        box_map: Dict[(freezer, rack, box), List[pos]]\n",
    "    \"\"\"\n",
    "    box_map = defaultdict(list)\n",
    "\n",
    "    for freezer, rack, box, pos in positions:\n",
    "        box_map[(freezer, rack, box)].append(pos)\n",
    "\n",
    "    # sort positions inside each box\n",
    "    for key in box_map:\n",
    "        box_map[key] = sorted(box_map[key], key=pos_sort_key)\n",
    "\n",
    "    return box_map\n",
    "\n",
    "FREEZER_ORDER = {\n",
    "    \"1\": 1,\n",
    "    \"2\": 2,\n",
    "    \"3\": 3,\n",
    "    \"4deg\": 4,\n",
    "    \"nitrogen\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db8c4386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFür die Biofluids gibt es pro Rack (Gestell); 7 Schubladen a 6 Boxpositionen; die Boxen haben dann widerum ABCDEFGH 1-12. \\n\\nVariable\\tWertbeispiel\\tBedeutung\\npos\\tB3\\tRaster-Position in der Box\\ntube_id\\t20250123-1\\tEindeutige Probenkennung\\nbox_id\\tBX-00017\\tBox-Nummer\\nfreezer\\t2\\tTiefkühler Nummer 2\\nrack\\t14\\tRack (Gestell) Nummer 14 im Schrank\\nbox\\t31\\tBox Nummer 31 im Rack (die Schulade wird nicht spezifisch genannt)\\nA1-H12\\tD7\\tAlternative Positionsangabe in 96er-Box\\nnitrogen\\t-\\tLagerort im Stickstofftank (anstelle von „freezer“)\\n\\nOk box meint die position 1-42 im Rack.!\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Unterschied zwischen Biofluids und Cells \n",
    "\"\"\"\n",
    "Biofluids: CSF (Cerebrospinalfluid), EDTA Plasam (Also nicht geronnen), Serum (geronnen abzentrifugiert), Urin, CSF Pellets\n",
    "Cells: Fibroblasten, PBMC (Peripher mononukläre Blutzellen)?, \n",
    "Other: DNA, PAXgene (RNA)\n",
    "\n",
    "Specific Fluids/Cells go into specific locations. \n",
    "\"\"\"\n",
    "\n",
    "### Für Positions: \n",
    "\"\"\"\n",
    "Für die Biofluids gibt es pro Rack (Gestell); 7 Schubladen a 6 Boxpositionen; die Boxen haben dann widerum ABCDEFGH 1-12. \n",
    "\n",
    "Variable\tWertbeispiel\tBedeutung\n",
    "pos\tB3\tRaster-Position in der Box\n",
    "tube_id\t20250123-1\tEindeutige Probenkennung\n",
    "box_id\tBX-00017\tBox-Nummer\n",
    "freezer\t2\tTiefkühler Nummer 2\n",
    "rack\t14\tRack (Gestell) Nummer 14 im Schrank\n",
    "box\t31\tBox Nummer 31 im Rack (die Schulade wird nicht spezifisch genannt)\n",
    "A1-H12\tD7\tAlternative Positionsangabe in 96er-Box\n",
    "nitrogen\t-\tLagerort im Stickstofftank (anstelle von „freezer“)\n",
    "\n",
    "Ok box meint die position 1-42 im Rack.!\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28401aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded 7 records from REDCap.\n",
      "Reference data saved to /home/aaron/Desktop/BioVal/data/Ref_file_test.csv\n"
     ]
    }
   ],
   "source": [
    "#downloads Biorep\n",
    "api_url = \"https://redcap.uni-heidelberg.de/api/\"\n",
    "api_token = \"19C2091A845FCAB1954F79E7F1A44374\"\n",
    "records = download_reference_from_redcap(api_url, api_token)\n",
    "\n",
    "save_reference_as_csv(records, \"/home/aaron/Desktop/BioVal/data/Ref_file_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d85525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({}, set())"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, ref_rows = read_csv(\"/home/aaron/Desktop/BioVal/data/Ref_file_test.csv\")\n",
    "build_patient_map(ref_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4753578a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'accession_nr': '',\n",
       "  'biomaterial': '',\n",
       "  'biorepository_complete': '0',\n",
       "  'box': '2',\n",
       "  'box_id': '200',\n",
       "  'cell_number': '',\n",
       "  'cohort': '',\n",
       "  'comment': '',\n",
       "  'date_received': '',\n",
       "  'extern_processed': '',\n",
       "  'extraction': '',\n",
       "  'extraction_time': '',\n",
       "  'fasting': '',\n",
       "  'fibro_passage': '',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'freezer': '1',\n",
       "  'lab_id': '',\n",
       "  'processed': '',\n",
       "  'processing_time': '',\n",
       "  'rack': '1',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'study': '',\n",
       "  'study_id': '1',\n",
       "  'study_visit': '',\n",
       "  'thaw_date': '',\n",
       "  'tube_id': '2345',\n",
       "  'tube_pos': '',\n",
       "  'virus_diag': '',\n",
       "  'volume': ''},\n",
       " {'accession_nr': '',\n",
       "  'biomaterial': '',\n",
       "  'biorepository_complete': '0',\n",
       "  'box': '1',\n",
       "  'box_id': '1',\n",
       "  'cell_number': '',\n",
       "  'cohort': '',\n",
       "  'comment': '',\n",
       "  'date_received': '',\n",
       "  'extern_processed': '',\n",
       "  'extraction': '',\n",
       "  'extraction_time': '',\n",
       "  'fasting': '',\n",
       "  'fibro_passage': '',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'freezer': '1',\n",
       "  'lab_id': '',\n",
       "  'processed': '',\n",
       "  'processing_time': '',\n",
       "  'rack': '1',\n",
       "  'redcap_event_name': 'baseline_arm_1',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'study': '',\n",
       "  'study_id': '1',\n",
       "  'study_visit': '',\n",
       "  'thaw_date': '',\n",
       "  'tube_id': '23456',\n",
       "  'tube_pos': '',\n",
       "  'virus_diag': '',\n",
       "  'volume': ''},\n",
       " {'accession_nr': '',\n",
       "  'biomaterial': '',\n",
       "  'biorepository_complete': '0',\n",
       "  'box': '2',\n",
       "  'box_id': '200',\n",
       "  'cell_number': '',\n",
       "  'cohort': '',\n",
       "  'comment': '',\n",
       "  'date_received': '',\n",
       "  'extern_processed': '',\n",
       "  'extraction': '',\n",
       "  'extraction_time': '',\n",
       "  'fasting': '',\n",
       "  'fibro_passage': '',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'freezer': '1',\n",
       "  'lab_id': '',\n",
       "  'processed': '',\n",
       "  'processing_time': '',\n",
       "  'rack': '1',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'study': '',\n",
       "  'study_id': '2',\n",
       "  'study_visit': '',\n",
       "  'thaw_date': '',\n",
       "  'tube_id': '2345',\n",
       "  'tube_pos': '',\n",
       "  'virus_diag': '',\n",
       "  'volume': ''},\n",
       " {'accession_nr': '',\n",
       "  'biomaterial': '',\n",
       "  'biorepository_complete': '0',\n",
       "  'box': '1',\n",
       "  'box_id': '1',\n",
       "  'cell_number': '',\n",
       "  'cohort': '',\n",
       "  'comment': '',\n",
       "  'date_received': '',\n",
       "  'extern_processed': '',\n",
       "  'extraction': '',\n",
       "  'extraction_time': '',\n",
       "  'fasting': '',\n",
       "  'fibro_passage': '',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'freezer': '1',\n",
       "  'lab_id': '',\n",
       "  'processed': '',\n",
       "  'processing_time': '',\n",
       "  'rack': '1',\n",
       "  'redcap_event_name': 'baseline_arm_1',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'study': '',\n",
       "  'study_id': '2',\n",
       "  'study_visit': '',\n",
       "  'thaw_date': '',\n",
       "  'tube_id': '23333',\n",
       "  'tube_pos': '',\n",
       "  'virus_diag': '',\n",
       "  'volume': ''},\n",
       " {'accession_nr': '',\n",
       "  'biomaterial': '',\n",
       "  'biorepository_complete': '0',\n",
       "  'box': '1',\n",
       "  'box_id': '1',\n",
       "  'cell_number': '',\n",
       "  'cohort': '',\n",
       "  'comment': '',\n",
       "  'date_received': '',\n",
       "  'extern_processed': '',\n",
       "  'extraction': '',\n",
       "  'extraction_time': '',\n",
       "  'fasting': '',\n",
       "  'fibro_passage': '',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'freezer': '1',\n",
       "  'lab_id': '',\n",
       "  'processed': '',\n",
       "  'processing_time': '',\n",
       "  'rack': '1',\n",
       "  'redcap_event_name': 'follow_up_arm_1',\n",
       "  'redcap_repeat_instance': '1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'study': '',\n",
       "  'study_id': '2',\n",
       "  'study_visit': '',\n",
       "  'thaw_date': '',\n",
       "  'tube_id': '45677',\n",
       "  'tube_pos': '',\n",
       "  'virus_diag': '',\n",
       "  'volume': ''},\n",
       " {'accession_nr': '',\n",
       "  'biomaterial': '',\n",
       "  'biorepository_complete': '0',\n",
       "  'box': '1',\n",
       "  'box_id': '1',\n",
       "  'cell_number': '',\n",
       "  'cohort': '',\n",
       "  'comment': '',\n",
       "  'date_received': '',\n",
       "  'extern_processed': '',\n",
       "  'extraction': '',\n",
       "  'extraction_time': '',\n",
       "  'fasting': '',\n",
       "  'fibro_passage': '',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'freezer': '1',\n",
       "  'lab_id': '',\n",
       "  'processed': '',\n",
       "  'processing_time': '',\n",
       "  'rack': '1',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'study': '',\n",
       "  'study_id': '3',\n",
       "  'study_visit': '',\n",
       "  'thaw_date': '',\n",
       "  'tube_id': '1223456',\n",
       "  'tube_pos': '',\n",
       "  'virus_diag': '',\n",
       "  'volume': ''},\n",
       " {'accession_nr': '',\n",
       "  'biomaterial': '',\n",
       "  'biorepository_complete': '0',\n",
       "  'box': '1',\n",
       "  'box_id': '1',\n",
       "  'cell_number': '',\n",
       "  'cohort': '',\n",
       "  'comment': '',\n",
       "  'date_received': '',\n",
       "  'extern_processed': '',\n",
       "  'extraction': '',\n",
       "  'extraction_time': '',\n",
       "  'fasting': '',\n",
       "  'fibro_passage': '',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'freezer': '1',\n",
       "  'lab_id': '',\n",
       "  'processed': '',\n",
       "  'processing_time': '',\n",
       "  'rack': '1',\n",
       "  'redcap_event_name': 'follow_up_arm_1',\n",
       "  'redcap_repeat_instance': '1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'study': '',\n",
       "  'study_id': '3',\n",
       "  'study_visit': '',\n",
       "  'thaw_date': '',\n",
       "  'tube_id': '56454',\n",
       "  'tube_pos': '',\n",
       "  'virus_diag': '',\n",
       "  'volume': ''}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20699e7e",
   "metadata": {},
   "source": [
    "# RUN IT Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977dd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# die beispiele funktionieren aufgrund der anderen datenstruktur nicht mehr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "59f7f1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checking Import file: /home/aaron/Desktop/BioVal/data/NDEGTest_import_file_double_position.csv\n",
      " Import file passed all validation checks.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'study_id': '1',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'lab_id': '124 123 4ll',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': 'CSF',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': 'A1',\n",
       "  'tube_id': '2345',\n",
       "  'box_id': '',\n",
       "  'box': '1',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '',\n",
       "  '': '0'},\n",
       " {'study_id': '2',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'lab_id': '111 111 111',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': 'Serum',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': 'A2',\n",
       "  'tube_id': '12234',\n",
       "  'box_id': '',\n",
       "  'box': '1',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '',\n",
       "  '': '0'}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate test data\n",
    "validate_file(\"/home/aaron/Desktop/BioVal/data/NDEGTest_import_file_double_position.csv\", \"Import file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b41270f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, import_rows = read_csv(\"/home/aaron/Desktop/BioVal/data/NDEGTest_import_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "25bbe540",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ref_rows = read_csv(\"/home/aaron/Desktop/BioVal/data/Biorepository_ref_file_2026-01-10_1511.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5af9ed53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checking Import file: /home/aaron/Desktop/BioVal/data/NDEGTest_import_file.csv\n",
      " Import file passed all validation checks.\n",
      "\n",
      " Checking data file: /home/aaron/Desktop/BioVal/data/Biorepository_ref_file_2026-01-10_1511.csv\n",
      " data file passed all validation checks.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'study_id': '222-222-222',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'lab_id': '1',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': '',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': '',\n",
       "  'tube_id': '2345',\n",
       "  'box_id': '200',\n",
       "  'box': '2',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'study_id': '222-222-222',\n",
       "  'redcap_event_name': 'baseline_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'lab_id': '1',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': '',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': '',\n",
       "  'tube_id': '23456',\n",
       "  'box_id': '1',\n",
       "  'box': '1',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'study_id': '333-333-333',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'lab_id': '2',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': '',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': '',\n",
       "  'tube_id': '11111',\n",
       "  'box_id': '200',\n",
       "  'box': '2',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'study_id': '333-333-333',\n",
       "  'redcap_event_name': 'baseline_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'lab_id': '2',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': '',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': '',\n",
       "  'tube_id': '23333',\n",
       "  'box_id': '1',\n",
       "  'box': '1',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'study_id': '333-333-333',\n",
       "  'redcap_event_name': 'follow_up_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '1',\n",
       "  'lab_id': '2',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': '',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': '',\n",
       "  'tube_id': '45677',\n",
       "  'box_id': '1',\n",
       "  'box': '1',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'study_id': '444-444-444',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'lab_id': '3',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': '',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': '',\n",
       "  'tube_id': '1223456',\n",
       "  'box_id': '1',\n",
       "  'box': '1',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'study_id': '444-444-444',\n",
       "  'redcap_event_name': 'follow_up_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '1',\n",
       "  'lab_id': '3',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': '',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': '',\n",
       "  'tube_id': '56454',\n",
       "  'box_id': '1',\n",
       "  'box': '1',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '0'}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_file(\"/home/aaron/Desktop/BioVal/data/NDEGTest_import_file.csv\", \"Import file\")\n",
    "validate_file(\"/home/aaron/Desktop/BioVal/data/Biorepository_ref_file_2026-01-10_1511.csv\", \"data file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a32c9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate positions found within data file.\n",
      "All tube_id values in Reference data file are unique.\n"
     ]
    }
   ],
   "source": [
    "check_internal_duplicates(ref_rows, \"data file\")\n",
    "check_internal_tube_id_duplicates(ref_rows, \"Reference data file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "275fd2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDCap record_id assigned based on lab_id.\n"
     ]
    }
   ],
   "source": [
    "import_rows, account_id = assign_redcap_ids(import_rows, ref_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c1dca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate positions found between import and reference data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occupied = get_occupied_positions(ref_rows)\n",
    "check_duplicate_positions(import_rows, occupied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "23ed5690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position (1, 1, 1, G1) is free. \n"
     ]
    }
   ],
   "source": [
    "occupied = get_occupied_positions(ref_rows)\n",
    "\n",
    "# Check a specific position manually\n",
    "freezer = \"1\"\n",
    "rack = \"1\"\n",
    "box = \"1\"\n",
    "pos = \"G1\"\n",
    "\n",
    "if is_position_occupied(freezer, rack, box, pos, occupied):\n",
    "    print(f\"Position ({freezer}, {rack}, {box}, {pos}) is already occupied. Please try another one.\")\n",
    "else:\n",
    "    print(f\"Position ({freezer}, {rack}, {box}, {pos}) is free. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "94e14a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "map1,map2, used_lab_ids = build_patient_map(ref_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b87c76d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_lab_patient_id(used_lab_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ed2bfd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'study_id': '111-111-111',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'lab_id': '1',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': 'CSF',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': 'A12',\n",
       "  'tube_id': '2345',\n",
       "  'box_id': '1',\n",
       "  'box': '1',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '',\n",
       "  '': '0',\n",
       "  'record_id': '1',\n",
       "  'lab_patient_id': '00004'}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returns the import rows with new assigned lab ID\n",
    "assign_lab_patient_ids(import_rows,ref_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c080b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_for_material(parent):\n",
    "    dialog = tk.Toplevel(parent)\n",
    "    dialog.title(\"Select Biomaterial\")\n",
    "    dialog.geometry(\"300x150\")\n",
    "    dialog.grab_set()\n",
    "\n",
    "    tk.Label(dialog, text=\"Select biomaterial:\").pack(pady=10)\n",
    "\n",
    "    material_var = tk.StringVar()\n",
    "    combo = ttk.Combobox(\n",
    "        dialog,\n",
    "        textvariable=material_var,\n",
    "        values=sorted(STORAGE_RULES.keys()),\n",
    "        state=\"readonly\"\n",
    "    )\n",
    "    combo.pack()\n",
    "    combo.current(0)\n",
    "\n",
    "    result = {\"material\": None}\n",
    "\n",
    "    def confirm():\n",
    "        result[\"material\"] = material_var.get()\n",
    "        dialog.destroy()\n",
    "\n",
    "    ttk.Button(dialog, text=\"OK\", command=confirm).pack(pady=10)\n",
    "\n",
    "    dialog.wait_window()\n",
    "    return result[\"material\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07442fb3",
   "metadata": {},
   "source": [
    "# GUI - BioVal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b25174c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded 7 records from REDCap.\n",
      "Data saved to /home/aaron/Desktop/BioVal/data/Ref_file_test.csv\n",
      " Checking Import file: /home/aaron/Desktop/BioVal/data/NDEGTest_import_file.csv\n",
      " Import file passed all validation checks.\n",
      "\n",
      " Checking Reference data: /home/aaron/Desktop/BioVal/data/Ref_file_test.csv\n",
      " Reference data passed all validation checks.\n",
      "\n",
      "No duplicate positions found within Import file.\n",
      "No duplicate positions found within Reference date.\n",
      "No duplicate positions found between import and reference data.\n",
      "Data saved to /home/aaron/Desktop/BioVal/data/NDEGTest_import_file.csv\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk  # Pillow muss installiert sein: pip install pillow\n",
    "\n",
    "### aktuell ist der download mit eingeschlossen; \n",
    "### das ref file ist aufgrund der falschen Dateneingabe auf Redcap\n",
    "### fehlerhaft, deswegen kommt noch eine Fehlermeldung\n",
    "\n",
    "def run_validation():\n",
    "    import_path = filedialog.askopenfilename(title=\"Select Import CSV\")\n",
    "    #ref_path = filedialog.askopenfilename(title=\"Select Reference CSV\")\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    try:\n",
    "        # Beispiel: CSV lesen & validieren (Funktionen müssen definiert sein)\n",
    "        reference_rows = download_reference_from_redcap(api_url, api_token)\n",
    "        ref_path = \"/home/aaron/Desktop/BioVal/data/Ref_file_test.csv\"\n",
    "        save_data_as_csv(reference_rows,ref_path)\n",
    "        ## Hier List Übersicht, was ist frei im Freezer: \n",
    "        import_path = filedialog.askopenfilename(title=\"Select Import CSV\")\n",
    "        \n",
    "        \n",
    "        _, import_rows = read_csv(import_path)\n",
    "        #_, ref_rows = read_csv(ref_path)\n",
    "        #Check if either of the files have not the required fields and structure\n",
    "        validate_file(import_path, \"Import file\")\n",
    "        validate_file(ref_path, \"Reference data\")\n",
    "        #Check if they have internal dublicates\n",
    "        check_internal_duplicates(import_rows, \"Import file\")\n",
    "        check_internal_duplicates(ref_rows,\"Reference date\")\n",
    "        #Check occupied position in freezer #keeps at the moment track of the history! \n",
    "        occupied_pos = get_occupied_positions(ref_rows)\n",
    "        duplicate_positions_count = check_duplicate_positions(import_rows, occupied_pos)\n",
    "        #Check lab IDs autogenerate them if neccessary\n",
    "        import_rows, labid_messages = assign_lab_patient_ids(import_rows,ref_rows)\n",
    "        #hier fänd ichs noch gut, wenn da stehen würde im\n",
    "        #Val_report jo es wurde eine ID assigned\n",
    "        save_data_as_csv(import_rows,import_path)\n",
    "        \n",
    "        \n",
    "        # Bericht speichern\n",
    "        report_path = filedialog.asksaveasfilename(\n",
    "            defaultextension=\".txt\",\n",
    "            filetypes=[(\"Text files\", \"*.txt\")],\n",
    "            title=\"Save Validation Report As\"\n",
    "        )\n",
    "        if report_path:\n",
    "            #Write report . \n",
    "            write_report(report_path, import_path, ref_path, labid_messages, import_rows, duplicate_positions_count) #new_ids_count ist weg\n",
    "            messagebox.showinfo(\"Success\", f\"Validation completed!\\nReport saved at:\\n{report_path}\")\n",
    "        else:\n",
    "            messagebox.showinfo(\"Success\", \"Validation completed! No report was saved.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Validation Error\", str(e))\n",
    "\n",
    "\n",
    "# --- GUI Setup ---\n",
    "root = tk.Tk()\n",
    "root.title(\"BioVal – Biorepository Validator\")\n",
    "root.geometry(\"600x400\")\n",
    "\n",
    "main_frame = ttk.Frame(root, padding=20)\n",
    "main_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "# --- Optional Image ---\n",
    "try:\n",
    "    img = Image.open(\"logo.jpeg\")  # <-- Dein Bildpfad\n",
    "    img = img.resize((150, 150))\n",
    "    photo = ImageTk.PhotoImage(img)\n",
    "    logo_label = ttk.Label(main_frame, image=photo)\n",
    "    logo_label.image = photo\n",
    "    logo_label.pack(pady=(0, 10))\n",
    "except Exception:\n",
    "    print(\"No image found – skipping logo.\")\n",
    "\n",
    "# --- Welcome Text ---\n",
    "welcome = ttk.Label(\n",
    "    main_frame,\n",
    "    text=(\n",
    "        \"Welcome to BioVal!\\n\\n\"\n",
    "        \"This tool helps you validate biorepository REDCap import files.\\n\"\n",
    "        \"You’ll be prompted to select:\\n\"\n",
    "        \" - A new import CSV file\\n - the data you want to upload\"\n",
    "        \" - A reference dataset for comparison - the data already stored in RedCap \\n\\n\"\n",
    "        \"The tool checks patient IDs, sample positions, and generates a report.\"\n",
    "    ),\n",
    "    justify=\"center\",\n",
    "    wraplength=500\n",
    ")\n",
    "welcome.pack(pady=10)\n",
    "\n",
    "# --- Start Button ---\n",
    "start_button = ttk.Button(main_frame, text=\"Run Validation\", command=run_validation)\n",
    "start_button.pack(pady=20)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a97803",
   "metadata": {},
   "source": [
    "# Für Morgen \n",
    "\n",
    "#### BioVal: \n",
    "- Was ist seit letzdem Treffen passiert? \n",
    "    - BioVal hat jetzt eine tube_status variable, die Track über den Tube_status übernimmt\n",
    "        - Stored, shipped, discarded... and what you wish\n",
    "    - Außerdem hat BioVal jetzt eine labID, die sich automatisch generiert, wenn eine neue Treat-HSP ID mit Daten hochgeladen wird im Importfile. Die ID ist unique, das bedeutet, für jede TreatHSP ID gibt es nur ein labID; Die labID kann nicht frei werden, sie wird nur ein Mal vergeben und bleibt dann beständig gleich. Auch im Fall dass die Tubes weggeschmissen, freigegeben werden, kann die Tube ID nicht neu assigniert werden. \n",
    "    - Gerade mache ich noch die Visualisierung, damit ihr im Labor direkt sehen könntet, welche Plätze noch frei sind. \n",
    "\n",
    "#### Aufgaben: \n",
    "- Integration des fertigen Instruments in the RedCap RDRegistry Base; erst wenn absolut fertig \n",
    "- Laptop von Sophie ready machen; Python, Jupyter Notebook GitHub Download (02.02- in der Woche)\n",
    "- Testen, Testen, Testen \n",
    "    \n",
    "    \n",
    "#### Fragen: \n",
    "- Offen: \n",
    "    - Lab: Required field - an Sophie habe nicht ganz verstanden, worauf sie in der Mail heraus wollte. \"Könntest du mir bitte eine Auflistung geben welche Felder für den Upload essentiell sind damit Redcap die Probe zuordnen kann? Dann kann ich entsprechend nicht nötige Felder die anderweitig gepflegt sind löschen. Davor macht es keinen Sinn das Uploadfile usw. an die neuen Variablen anzupassen.\" \n",
    "    - Aissignation für Red\n",
    "    - Welche instances sind erlaubt; ist es ein required field? wo kann ich das einsehen? das muss ich wissen.\n",
    "    - Können wir nach dem Testen auf Development Phase die eingegebenen Daten auf die RD Registry Seite übertragen? Müsste ja eigentlich gehen. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d310dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def open_file(path):\n",
    "    if sys.platform.startswith(\"win\"):\n",
    "        os.startfile(path)              # Windows\n",
    "    elif sys.platform == \"darwin\":\n",
    "        subprocess.run([\"open\", path])  # macOS\n",
    "    else:\n",
    "        subprocess.run([\"xdg-open\", path])  # Linux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bee927d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded 8 records from REDCap.\n",
      "Data saved to /home/aaron/Desktop/BioVal/data/Ref_file_test.csv\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk  # Pillow muss installiert sein: pip install pillow\n",
    "import os\n",
    "\n",
    "\n",
    "def run_validation():\n",
    "    try:\n",
    "        # ===============================\n",
    "        # 1. Download reference data\n",
    "        # ===============================\n",
    "        reference_rows = download_reference_from_redcap(api_url, api_token)\n",
    "        ref_path = \"/home/aaron/Desktop/BioVal/data/Ref_file_test.csv\"\n",
    "        save_data_as_csv(reference_rows, ref_path)\n",
    "\n",
    "        # ===============================\n",
    "        # 2. NEW: Show available positions\n",
    "        # ===============================\n",
    "        material = ask_for_material(root)\n",
    "        if not material:\n",
    "            messagebox.showinfo(\"Cancelled\", \"No biomaterial selected.\")\n",
    "            return\n",
    "\n",
    "        available_positions = get_available_positions(material, reference_rows)\n",
    "\n",
    "        selected_positions = select_positions_for_material(\n",
    "            material,\n",
    "            available_positions\n",
    "        )\n",
    "\n",
    "        csv_path = filedialog.asksaveasfilename(\n",
    "            defaultextension=\".csv\",\n",
    "            filetypes=[(\"CSV files\", \"*.csv\")],\n",
    "            title=\"Save Available Positions\",\n",
    "            initialfile=f\"available_positions_{material}.csv\"\n",
    "        )\n",
    "\n",
    "        if csv_path:\n",
    "            save_positions_to_csv(csv_path, selected_positions)\n",
    "            open_file(csv_path)\n",
    "\n",
    "        # ===============================\n",
    "        # 3. Continue with import validation\n",
    "        # ===============================\n",
    "        import_path = filedialog.askopenfilename(title=\"Select Import CSV\")\n",
    "        _, import_rows = read_csv(import_path)\n",
    "\n",
    "        validate_file(import_path, \"Import file\")\n",
    "        validate_file(ref_path, \"Reference data\")\n",
    "\n",
    "        check_internal_duplicates(import_rows, \"Import file\")\n",
    "        check_internal_duplicates(reference_rows, \"Reference data\")\n",
    "\n",
    "        occupied_pos = get_occupied_positions(reference_rows)\n",
    "        duplicate_positions_count = check_duplicate_positions(import_rows, occupied_pos)\n",
    "\n",
    "        import_rows, labid_messages = assign_lab_patient_ids(import_rows, reference_rows)\n",
    "        save_data_as_csv(import_rows, import_path)\n",
    "\n",
    "        # ===============================\n",
    "        # 4. Report\n",
    "        # ===============================\n",
    "        report_path = filedialog.asksaveasfilename(\n",
    "            defaultextension=\".txt\",\n",
    "            filetypes=[(\"Text files\", \"*.txt\")],\n",
    "            title=\"Save Validation Report As\"\n",
    "        )\n",
    "\n",
    "        if report_path:\n",
    "            write_report(\n",
    "                report_path,\n",
    "                import_path,\n",
    "                ref_path,\n",
    "                labid_messages,\n",
    "                import_rows,\n",
    "                duplicate_positions_count\n",
    "            )\n",
    "            messagebox.showinfo(\"Success\", \"Validation completed!\")\n",
    "        else:\n",
    "            messagebox.showinfo(\"Success\", \"Validation completed! No report saved.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Validation Error\", str(e))\n",
    "\n",
    "# --- GUI Setup ---\n",
    "root = tk.Tk()\n",
    "root.title(\"BioVal – Biorepository Validator\")\n",
    "root.geometry(\"600x400\")\n",
    "\n",
    "main_frame = ttk.Frame(root, padding=20)\n",
    "main_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "# --- Optional Image ---\n",
    "try:\n",
    "    img = Image.open(\"logo.jpeg\")  # <-- Dein Bildpfad\n",
    "    img = img.resize((150, 150))\n",
    "    photo = ImageTk.PhotoImage(img)\n",
    "    logo_label = ttk.Label(main_frame, image=photo)\n",
    "    logo_label.image = photo\n",
    "    logo_label.pack(pady=(0, 10))\n",
    "except Exception:\n",
    "    print(\"No image found – skipping logo.\")\n",
    "\n",
    "# --- Welcome Text ---\n",
    "welcome = ttk.Label(\n",
    "    main_frame,\n",
    "    text=(\n",
    "        \"Welcome to BioVal!\\n\\n\"\n",
    "        \"This tool helps you validate biorepository REDCap import files.\\n\"\n",
    "        \"You’ll be prompted to select:\\n\"\n",
    "        \" - A new import CSV file\\n - the data you want to upload\"\n",
    "        \" - A reference dataset for comparison - the data already stored in RedCap \\n\\n\"\n",
    "        \"The tool checks patient IDs, sample positions, and generates a report.\"\n",
    "    ),\n",
    "    justify=\"center\",\n",
    "    wraplength=500\n",
    ")\n",
    "welcome.pack(pady=10)\n",
    "\n",
    "# --- Start Button ---\n",
    "start_button = ttk.Button(main_frame, text=\"Run Validation\", command=run_validation)\n",
    "start_button.pack(pady=20)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642d16cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
