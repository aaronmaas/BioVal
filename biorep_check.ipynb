{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e5de916",
   "metadata": {},
   "source": [
    "# Biorepsoitory Validation Code - BioVal \n",
    "\n",
    "Code validates individually the current redcap repository and the biorep data intended to be uploaded.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f2fb955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'study_id': '1', 'redcap_event_name': 'screening_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': '', 'lab_id': '', 'cohort': '', 'study': '', 'study_visit': '', 'fasting': '', 'extraction_time': '', 'extraction': '', 'processing_time': '', 'processed': '', 'extern_processed': '', 'date_received': '', 'biomaterial': '', 'volume': '', 'cell_number': '', 'tube_pos': '', 'tube_id': '2345', 'box_id': '200', 'box': '2', 'rack': '1', 'freezer': '1', 'freeze_date': '', 'freeze_time': '', 'fibro_passage': '', 'virus_diag': '', 'thaw_date': '', 'sent_date': '', 'sent_project': '', 'reserved_date': '', 'reserved_for': '', 'accession_nr': '', 'comment': '', 'biorepository_complete': '0'}, {'study_id': '1', 'redcap_event_name': 'baseline_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': '', 'lab_id': '', 'cohort': '', 'study': '', 'study_visit': '', 'fasting': '', 'extraction_time': '', 'extraction': '', 'processing_time': '', 'processed': '', 'extern_processed': '', 'date_received': '', 'biomaterial': '', 'volume': '', 'cell_number': '', 'tube_pos': '', 'tube_id': '23456', 'box_id': '1', 'box': '1', 'rack': '1', 'freezer': '1', 'freeze_date': '', 'freeze_time': '', 'fibro_passage': '', 'virus_diag': '', 'thaw_date': '', 'sent_date': '', 'sent_project': '', 'reserved_date': '', 'reserved_for': '', 'accession_nr': '', 'comment': '', 'biorepository_complete': '0'}, {'study_id': '2', 'redcap_event_name': 'screening_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': '', 'lab_id': '', 'cohort': '', 'study': '', 'study_visit': '', 'fasting': '', 'extraction_time': '', 'extraction': '', 'processing_time': '', 'processed': '', 'extern_processed': '', 'date_received': '', 'biomaterial': '', 'volume': '', 'cell_number': '', 'tube_pos': '', 'tube_id': '2345', 'box_id': '200', 'box': '2', 'rack': '1', 'freezer': '1', 'freeze_date': '', 'freeze_time': '', 'fibro_passage': '', 'virus_diag': '', 'thaw_date': '', 'sent_date': '', 'sent_project': '', 'reserved_date': '', 'reserved_for': '', 'accession_nr': '', 'comment': '', 'biorepository_complete': '0'}, {'study_id': '2', 'redcap_event_name': 'baseline_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': '', 'lab_id': '', 'cohort': '', 'study': '', 'study_visit': '', 'fasting': '', 'extraction_time': '', 'extraction': '', 'processing_time': '', 'processed': '', 'extern_processed': '', 'date_received': '', 'biomaterial': '', 'volume': '', 'cell_number': '', 'tube_pos': '', 'tube_id': '23333', 'box_id': '1', 'box': '1', 'rack': '1', 'freezer': '1', 'freeze_date': '', 'freeze_time': '', 'fibro_passage': '', 'virus_diag': '', 'thaw_date': '', 'sent_date': '', 'sent_project': '', 'reserved_date': '', 'reserved_for': '', 'accession_nr': '', 'comment': '', 'biorepository_complete': '0'}, {'study_id': '2', 'redcap_event_name': 'follow_up_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'lab_id': '', 'cohort': '', 'study': '', 'study_visit': '', 'fasting': '', 'extraction_time': '', 'extraction': '', 'processing_time': '', 'processed': '', 'extern_processed': '', 'date_received': '', 'biomaterial': '', 'volume': '', 'cell_number': '', 'tube_pos': '', 'tube_id': '45677', 'box_id': '1', 'box': '1', 'rack': '1', 'freezer': '1', 'freeze_date': '', 'freeze_time': '', 'fibro_passage': '', 'virus_diag': '', 'thaw_date': '', 'sent_date': '', 'sent_project': '', 'reserved_date': '', 'reserved_for': '', 'accession_nr': '', 'comment': '', 'biorepository_complete': '0'}, {'study_id': '3', 'redcap_event_name': 'screening_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': '', 'lab_id': '', 'cohort': '', 'study': '', 'study_visit': '', 'fasting': '', 'extraction_time': '', 'extraction': '', 'processing_time': '', 'processed': '', 'extern_processed': '', 'date_received': '', 'biomaterial': '', 'volume': '', 'cell_number': '', 'tube_pos': '', 'tube_id': '1223456', 'box_id': '1', 'box': '1', 'rack': '1', 'freezer': '1', 'freeze_date': '', 'freeze_time': '', 'fibro_passage': '', 'virus_diag': '', 'thaw_date': '', 'sent_date': '', 'sent_project': '', 'reserved_date': '', 'reserved_for': '', 'accession_nr': '', 'comment': '', 'biorepository_complete': '0'}, {'study_id': '3', 'redcap_event_name': 'follow_up_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'lab_id': '', 'cohort': '', 'study': '', 'study_visit': '', 'fasting': '', 'extraction_time': '', 'extraction': '', 'processing_time': '', 'processed': '', 'extern_processed': '', 'date_received': '', 'biomaterial': '', 'volume': '', 'cell_number': '', 'tube_pos': '', 'tube_id': '56454', 'box_id': '1', 'box': '1', 'rack': '1', 'freezer': '1', 'freeze_date': '', 'freeze_time': '', 'fibro_passage': '', 'virus_diag': '', 'thaw_date': '', 'sent_date': '', 'sent_project': '', 'reserved_date': '', 'reserved_for': '', 'accession_nr': '', 'comment': '', 'biorepository_complete': '0'}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_url = \"https://redcap.uni-heidelberg.de/api/\"\n",
    "api_token = \"19C2091A845FCAB1954F79E7F1A44374\"\n",
    "\n",
    "data = {\n",
    "    'token': api_token,\n",
    "    'content': 'record',\n",
    "    'format': 'json',\n",
    "    'type': 'flat',\n",
    "    'forms[0]': 'biorepository',  # Name des Instruments/Forms\n",
    "    'rawOrLabel': 'raw',\n",
    "    'rawOrLabelHeaders': 'raw',\n",
    "    'exportSurveyFields': 'true',\n",
    "    'exportDataAccessGroups': 'true'\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, data=data)\n",
    "records = response.json()\n",
    "\n",
    "print(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f397938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLOBAL PARAMS\n",
    "\n",
    "REQUIRED_FIELDS = [\n",
    "    \"study_id\", #TreatHSP ID\n",
    "    \"lab_id\",    #does sophie use this? yes! we want to use this but need to find a solution here; should autonumber it\n",
    "    \"redcap_event_name\",\n",
    "    \"biomaterial\",\n",
    "    \"tube_pos\",\n",
    "    \"tube_id\",\n",
    "    \"box_id\",\n",
    "    \"freezer\",\n",
    "    \"rack\",\n",
    "    \"box\",\n",
    "]\n",
    "\n",
    "#Biorep Sampel Materials\n",
    "VALID_MATERIALS = [\n",
    "    \"CSF\", \"CSF Pellet\", \"DNA\", \"EDTA Plasma\", \"Fibroblasten\",\n",
    "    \"PAXgene\", \"PBMC\", \"Serum\", \"Urin\"\n",
    "]\n",
    "\n",
    "VALID_EVENTS = [\"baseline_arm_1\", \"screening_arm_1\", \"follow_up_arm_1\"]\n",
    "\n",
    "# Allowed matrices (positions) per material\n",
    "VALID_POS_FLUIDS = [f\"{row}{col}\" for row in \"ABCDEFGH\" for col in range(1, 13)]\n",
    "VALID_POS_PAXGENE = [f\"{row}{col}\" for row in \"ABCDEFG\" for col in range(1, 8)]\n",
    "VALID_POS_DNA_CELLS_PBMC =  [f\"{row}{col}\" for row in \"ABCDEFGHJ\" for col in range(1, 11)]\n",
    "\n",
    "import re\n",
    "\n",
    "STUDY_ID_PATTERN = re.compile(r\"^\\d{3}-\\d{3}-\\d{3}$\")\n",
    "\n",
    "\n",
    "# Freezers\n",
    "VALID_FREEZER = [\"1\", \"2\", \"3\", \"nitrogen\", \"4deg\"]\n",
    "\n",
    "# Boxes (same for all, unless exception later)\n",
    "VALID_BOX = [str(i) for i in range(1, 43)]  # 1–42\n",
    "\n",
    "# Racks\n",
    "VALID_RACK = [str(i) for i in range(1, 101)]  # 1–100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c3f2e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import re\n",
    "\n",
    "# --- Define allowed values and required fields ---\n",
    "\n",
    "REQUIRED_FIELDS = [\n",
    "    \"study_id\", \"lab_id\", \"redcap_event_name\", \"biomaterial\", \"tube_pos\",\n",
    "    \"tube_id\", \"box_id\", \"freezer\", \"rack\", \"box\"\n",
    "]\n",
    "\n",
    "#here i should assign a status variable this is very important; \n",
    "\n",
    "VALID_MATERIALS = [\n",
    "    \"csf\", \"csf pellet\", \"dna\", \"edta plasma\", \"fibroblasten\",\n",
    "    \"paxgene\", \"pbmc\", \"serum\", \"urin\"\n",
    "]\n",
    "\n",
    "STUDY_ID_PATTERN = re.compile(r\"^\\d{3}-\\d{3}-\\d{3}$\")\n",
    "\n",
    "\n",
    "### Unterschied zwischen Biofluids und Cells \n",
    "\"\"\"\n",
    "Biofluids: CSF (Cerebrospinalfluid), EDTA Plasam (Also nicht geronnen), Serum (geronnen abzentrifugiert), Urin, CSF Pellets\n",
    "Cells: Fibroblasten, PBMC (Peripher mononukläre Blutzellen)?, \n",
    "Other: DNA, PAXgene (RNA)\n",
    "\n",
    "Specific Fluids/Cells go into specific locations. \n",
    "\"\"\"\n",
    "\n",
    "### Für Positions: \n",
    "\"\"\"\n",
    "Für die Biofluids gibt es pro Rack (Gestell); 7 Schubladen a 6 Boxpositionen; die Boxen haben dann widerum ABCDEFGH 1-12. \n",
    "\n",
    "Variable\tWertbeispiel\tBedeutung\n",
    "pos\tB3\tRaster-Position in der Box\n",
    "tube_id\t20250123-1\tEindeutige Probenkennung\n",
    "box_id\tBX-00017\tBox-Nummer\n",
    "freezer\t2\tTiefkühler Nummer 2\n",
    "rack\t14\tRack (Gestell) Nummer 14 im Schrank\n",
    "box\t31\tBox Nummer 31 im Rack (die Schulade wird nicht spezifisch genannt)\n",
    "A1-H12\tD7\tAlternative Positionsangabe in 96er-Box\n",
    "nitrogen\t-\tLagerort im Stickstofftank (anstelle von „freezer“)\n",
    "\n",
    "Ok box meint die position 1-42 im Rack.!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Positions A1–H12 (plate layout)\n",
    "#VALID_POS = [f\"{row}{col}\" for row in \"ABCDEFGH\" for col in range(1, 13)]\n",
    "#VALID_RACK = list(map(str, range(1, 101)))  # 1–100\n",
    "#VALID_BOX = [f\"{box}\" for box in range(1,43)] #42 positions per Rack\n",
    "#VALID_FREEZER = [\"1\", \"2\", \"3\", \"nitrogen\"]\n",
    "VALID_EVENTS = [\"baseline_arm_1\", \"screening_arm_1\", \"follow_up_arm_1\"]\n",
    "\n",
    "# Allowed matrices (positions) per material\n",
    "VALID_POS_FLUIDS = [f\"{row}{col}\" for row in \"ABCDEFGH\" for col in range(1, 13)]\n",
    "VALID_POS_PAXGENE = [f\"{row}{col}\" for row in \"ABCDEFG\" for col in range(1, 8)]\n",
    "VALID_POS_DNA_CELLS_PBMC =  [f\"{row}{col}\" for row in \"ABCDEFGHJ\" for col in range(1, 11)]\n",
    "\n",
    "# Freezers\n",
    "VALID_FREEZER = [\"1\", \"2\", \"3\", \"nitrogen\", \"4deg\"]\n",
    "\n",
    "# Boxes (same for all, unless exception later)\n",
    "VALID_BOX = [str(i) for i in range(1, 43)]  # 1–42\n",
    "\n",
    "# Racks\n",
    "VALID_RACK = [str(i) for i in range(1, 101)]  # 1–100\n",
    "\n",
    "# === Functions ===\n",
    "\n",
    "def read_csv(path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns its headers and row data.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the CSV file\n",
    "\n",
    "    Returns:\n",
    "        tuple: (List[str] headers, List[Dict] rows)\n",
    "    \"\"\"\n",
    "    with open(path, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        rows = list(reader)\n",
    "    return reader.fieldnames, rows\n",
    "\n",
    "\n",
    "def check_structure(headers):\n",
    "    \"\"\"\n",
    "    Checks whether all required fields are present in the CSV headers.\n",
    "\n",
    "    Args:\n",
    "        headers (List[str]): Column headers from the CSV\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of missing required fields (if any)\n",
    "    \"\"\"\n",
    "    missing = [field for field in REQUIRED_FIELDS if field not in headers]\n",
    "    return missing\n",
    "\n",
    "\n",
    "def validate_row_v0(row, index):\n",
    "    \"\"\"\n",
    "    Old version\n",
    "    Validates a single row for required values and correct formats.\n",
    "\n",
    "    Args:\n",
    "        row (Dict): A row from the CSV as a dictionary\n",
    "        index (int): The row number (for error reporting)\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of validation error messages for this row\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "\n",
    "    # Check if all required fields are non-empty\n",
    "    for field in REQUIRED_FIELDS:\n",
    "        if row.get(field, \"\").strip() == \"\":\n",
    "            errors.append(f\"Row {index}: Missing value in '{field}'\")\n",
    "\n",
    "    ######## General Validation - is everything there?         \n",
    "            \n",
    "    # Validate lab_id format (3x alphanumeric with spaces)\n",
    "    lab_id = row.get(\"lab_id\", \"\").strip()\n",
    "    if lab_id and not re.match(r\"^[A-Za-z0-9]{3} [A-Za-z0-9]{3} [A-Za-z0-9]{3}$\", lab_id):\n",
    "        errors.append(f\"Row {index}: Invalid lab_id format: '{lab_id}'\")\n",
    "        #that is not necessary anymore sophie will use something else\n",
    "\n",
    "    # Validate other fields only if they're present\n",
    "    if row.get(\"biomaterial\") and row[\"biomaterial\"] not in VALID_MATERIALS:\n",
    "        errors.append(f\"Row {index}: Invalid Biomaterial: '{row['biomaterial']}'\")\n",
    "\n",
    "    if row.get(\"tube_pos\") and row[tube_pos] not in VALID_POS:\n",
    "        errors.append(f\"Row {index}: Invalid tube-pos: '{row['tube_pos']}'\")\n",
    "\n",
    "    if row.get(\"freezer\") and row[\"freezer\"] not in VALID_FREEZER:\n",
    "        errors.append(f\"Row {index}: Invalid freezer: '{row['freezer']}'\")\n",
    "\n",
    "    if row.get(\"rack\") and row[\"rack\"] not in VALID_RACK:\n",
    "        errors.append(f\"Row {index}: Invalid rack: '{row['rack']}'\")\n",
    "\n",
    "    if row.get(\"box\") and row[\"box\"] not in VALID_BOX:\n",
    "        errors.append(f\"Row {index}: Invalid box: '{row['box']}'\")\n",
    "\n",
    "    if row.get(\"redcap_event_name\") and row[\"redcap_event_name\"] not in VALID_EVENTS:\n",
    "        errors.append(f\"Row {index}: Invalid redcap_event_name: '{row['redcap_event_name']}'\")\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "# === Material → Freezer mapping === Import for sepparation of the different materials\n",
    "BIOFLUIDS = [\"urin\", \"edta plasma\", \"serum\", \"csf\", \"csf pellet\"]\n",
    "PAXGENE = [\"paxgene\"]\n",
    "DNA = [\"dna\"]\n",
    "CELLS = [\"fibroblasten\", \"pbmc\"]\n",
    "\n",
    "#lets normalize to lower case\n",
    "\n",
    "MATERIAL_TO_FREEZER = {\n",
    "    **{m: [\"1\", \"2\", \"3\"] for m in BIOFLUIDS},   # Biofluids → -80 freezers\n",
    "    **{m: [\"nitrogen\"] for m in CELLS},          # Cells → nitrogen\n",
    "    **{m: [\"4deg\"] for m in DNA},                # DNA -> 4 Deg freezer\n",
    "    **{m: [\"1\", \"2\", \"3\"] for m in PAXGENE}      # Paxgene -> -80 freezers\n",
    "}\n",
    "\n",
    "def validate_row_v1(row, index):\n",
    "    \"\"\"\n",
    "    Validates a single row for required values and correct formats.\n",
    "\n",
    "    Args:\n",
    "        row (Dict): A row from the CSV as a dictionary\n",
    "        index (int): The row number (for error reporting)\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of validation error messages for this row\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "\n",
    "    # Check if all required fields are non-empty\n",
    "    for field in REQUIRED_FIELDS:\n",
    "        if row.get(field, \"\").strip() == \"\":\n",
    "            errors.append(f\"Row {index}: Missing value in '{field}'\")\n",
    "\n",
    "    ######## General Validation ########\n",
    "            \n",
    "    # Validate lab_id format (DISABLED if Sophie will use different format)\n",
    "    # lab_id = row.get(\"lab_id\", \"\").strip()\n",
    "    # if lab_id and not re.match(r\"^[A-Za-z0-9]{3} [A-Za-z0-9]{3} [A-Za-z0-9]{3}$\", lab_id):\n",
    "    #     errors.append(f\"Row {index}: Invalid lab_id format: '{lab_id}'\")\n",
    "\n",
    "    # Validate material\n",
    "    if row.get(\"biomaterial\") and row[\"biomaterial\"] not in VALID_MATERIALS:\n",
    "        errors.append(f\"Row {index}: Invalid material: '{row['biomaterial']}'\")\n",
    "\n",
    "    # Validate pos\n",
    "    if row.get(tube_pos) and row[tube_pos] not in VALID_POS:\n",
    "        errors.append(f\"Row {index}: Invalid tube-pos: '{row['tube_pos']}'\")\n",
    "\n",
    "    # Validate freezer\n",
    "    if row.get(\"freezer\") and row[\"freezer\"] not in VALID_FREEZER:\n",
    "        errors.append(f\"Row {index}: Invalid freezer: '{row['freezer']}'\")\n",
    "\n",
    "    # Validate rack\n",
    "    if row.get(\"rack\") and row[\"rack\"] not in VALID_RACK:\n",
    "        errors.append(f\"Row {index}: Invalid rack: '{row['rack']}'\")\n",
    "\n",
    "    # Validate box\n",
    "    if row.get(\"box\") and row[\"box\"] not in VALID_BOX:\n",
    "        errors.append(f\"Row {index}: Invalid box: '{row['box']}'\")\n",
    "\n",
    "    # Validate event name\n",
    "    if row.get(\"redcap_event_name\") and row[\"redcap_event_name\"] not in VALID_EVENTS:\n",
    "        errors.append(f\"Row {index}: Invalid redcap_event_name: '{row['redcap_event_name']}'\")\n",
    "\n",
    "    ######## Material-specific Freezer Rule ########\n",
    "    biomaterial = row.get(\"biomaterial\", \"\").strip()\n",
    "    freezer = row.get(\"freezer\", \"\").strip()\n",
    "\n",
    "    if biomaterial and freezer:\n",
    "        allowed_freezers = MATERIAL_TO_FREEZER.get(biomaterial, [])\n",
    "        if allowed_freezers and freezer not in allowed_freezers:\n",
    "            errors.append(\n",
    "                f\"Row {index}: Invalid freezer '{freezer}' for material '{biomaterial}'. \"\n",
    "                f\"Allowed freezers: {allowed_freezers}\"\n",
    "            )\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "def validate_row(row, index):\n",
    "    errors = []\n",
    "\n",
    "    # --- Required fields ---\n",
    "    for field in REQUIRED_FIELDS:\n",
    "        if row.get(field, \"\").strip() == \"\":\n",
    "            errors.append(f\"Row {index}: Missing value in '{field}'\")\n",
    "\n",
    "    # --- Get material ---\n",
    "    biomaterial = row.get(\"biomaterial\", \"\").strip().lower()\n",
    "    tube_pos = row.get(\"tube_pos\", \"\").strip()\n",
    "    freezer = row.get(\"freezer\", \"\").strip()\n",
    "    rack = row.get(\"rack\", \"\").strip()\n",
    "    box = row.get(\"box\", \"\").strip()\n",
    "    # --- Material-specific storage rules ---\n",
    "    if biomaterial in BIOFLUIDS:  # fluids\n",
    "        if tube_pos not in VALID_POS_FLUIDS:\n",
    "            errors.append(f\"Row {index}: Invalid tube-pos '{tub_pos}' for {biomaterial} (must be A1–H10)\")\n",
    "        if freezer not in [\"1\", \"2\", \"3\"]:\n",
    "            errors.append(f\"Row {index}: {biomaterial} must be stored in -80 freezers (1–3).\")\n",
    "\n",
    "    elif biomaterial in PAXGENE:\n",
    "        if tube_pos not in VALID_POS_PAXGENE:\n",
    "            errors.append(f\"Row {index}: Invalid tube-pos '{tube_pos}' for PAXgene (must be A1–G7)\")\n",
    "        if freezer not in [\"1\", \"2\", \"3\"]:\n",
    "            errors.append(f\"Row {index}: PAXgene must be stored in -80 freezers (1–3).\")\n",
    "\n",
    "    elif biomaterial in DNA:\n",
    "        if tube_pos not in VALID_POS_DNA_CELLS_PBMC:\n",
    "            errors.append(f\"Row {index}: Invalid tube-pos '{tube_pos}' for DNA (must be A1–J10)\")\n",
    "        if freezer != \"4deg\":\n",
    "            errors.append(f\"Row {index}: DNA must be stored in 4-degree freezer.\")\n",
    "\n",
    "    elif biomaterial in CELLS:\n",
    "        if tube_pos not in VALID_POS_DNA_CELLS_PBMC:\n",
    "            errors.append(f\"Row {index}: Invalid tube-pos '{tube_pos}' for {biomaterial} (must be A1–J10)\")\n",
    "        if freezer != \"nitrogen\":\n",
    "            errors.append(f\"Row {index}: {biomaterial} must be stored in nitrogen tank.\")\n",
    "\n",
    "    else:\n",
    "        errors.append(f\"Row {index}: Unknown or unsupported material '{biomaterial}'\")\n",
    "        \n",
    "    #Fängt Material ab\n",
    "\n",
    "    # --- General checks still valid ---\n",
    "    if rack and rack not in VALID_RACK:\n",
    "        errors.append(f\"Row {index}: Invalid rack '{rack}'\")\n",
    "\n",
    "    if box and box not in VALID_BOX:\n",
    "        errors.append(f\"Row {index}: Invalid box '{box}'\")\n",
    "\n",
    "    return errors\n",
    "\n",
    "\n",
    "\n",
    "def validate_file_v1(path, label):\n",
    "    \"\"\"\n",
    "    Validates an entire CSV file for structure and row-level values.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the CSV file\n",
    "        label (str): Descriptive label (e.g. \"Import file\")\n",
    "\n",
    "    Returns:\n",
    "        None – exits with error if validation fails\n",
    "    \"\"\"\n",
    "    print(f\" Checking {label}: {path}\")\n",
    "    headers, rows = read_csv(path)\n",
    "\n",
    "    # Check for required column headers\n",
    "    structure_errors = check_structure(headers)\n",
    "    if structure_errors:\n",
    "        print(f\" Missing required columns in {label}: {structure_errors}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Validate each row\n",
    "    all_errors = []\n",
    "    for i, row in enumerate(rows, start=2):  # Line 1 is header\n",
    "        #calls validate row in for loop\n",
    "        row_errors = validate_row(row, i)\n",
    "        all_errors.extend(row_errors)\n",
    "    \n",
    "    #returns evaluation errors if any of the above occurs\n",
    "    if all_errors:\n",
    "        print(f\" {len(all_errors)} validation error(s) in {label}:\")  ##mach hier auch eher ein error rais\n",
    "        for e in all_errors:\n",
    "            print(\" -\", e)\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(f\" {label} passed all validation checks.\\n\")\n",
    "        \n",
    "        \n",
    "def validate_file(path, label):\n",
    "    \"\"\"\n",
    "    Validates an entire CSV file and raises ValueError if anything is wrong.\n",
    "    \"\"\"\n",
    "    print(f\" Checking {label}: {path}\")\n",
    "    headers, rows = read_csv(path)\n",
    "\n",
    "    # Check for required column headers\n",
    "    structure_errors = check_structure(headers)\n",
    "    if structure_errors:\n",
    "        raise ValueError(f\"Missing required columns in {label}: {structure_errors}\")\n",
    "\n",
    "    # Validate each row\n",
    "    for i, row in enumerate(rows, start=2):\n",
    "        validate_row(row, i)  # will raise immediately if invalid\n",
    "\n",
    "    print(f\" {label} passed all validation checks.\\n\")\n",
    "    return rows  # return rows if valid\n",
    "\n",
    "\n",
    "\n",
    "def get_occupied_positions(rows):\n",
    "    \"\"\"\n",
    "    Extracts all occupied positions from a list of data rows.\n",
    "\n",
    "    Args:\n",
    "        rows (List[Dict]): Data rows (e.g. from reference file)\n",
    "\n",
    "    Returns:\n",
    "        Set[Tuple[str, str, str, str]]: Set of (freezer, rack, box, pos)\n",
    "    \"\"\"\n",
    "    positions = set()\n",
    "    for row in rows:\n",
    "        key = (\n",
    "            row.get(\"freezer\", \"\").strip(),\n",
    "            row.get(\"rack\", \"\").strip(),\n",
    "            row.get(\"box\", \"\").strip(),\n",
    "            row.get(\"tube_pos\", \"\").strip(),\n",
    "        )\n",
    "        if all(key):\n",
    "            positions.add(key)\n",
    "    return positions\n",
    "\n",
    "\n",
    "def check_duplicate_positions_v1(import_rows, occupied_positions):\n",
    "    \"\"\"\n",
    "    Compares import rows against existing positions and raises errors for conflicts.\n",
    "\n",
    "    Args:\n",
    "        import_rows (List[Dict]): Rows from the import file\n",
    "        occupied_positions (Set[Tuple]): Set of existing (freezer, rack, box, pos)\n",
    "\n",
    "    Returns:\n",
    "        None – prints and exits if duplicates are found\n",
    "    \"\"\"\n",
    "    duplicate_count = 0\n",
    "    for i, row in enumerate(import_rows, start=2):\n",
    "        key = (\n",
    "            row.get(\"freezer\", \"\").strip(),\n",
    "            row.get(\"rack\", \"\").strip(),\n",
    "            row.get(\"box\", \"\").strip(),\n",
    "            row.get(\"tube_pos\", \"\").strip(),\n",
    "        )\n",
    "        if key in occupied_positions:\n",
    "            print(f\"Row {i}: Position {key} is already occupied in existing data.\")\n",
    "            duplicate_count += 1\n",
    "\n",
    "    if duplicate_count == 0:\n",
    "        print(\"No duplicate positions found between import and reference data.\")\n",
    "    else:\n",
    "        print(f\"{duplicate_count} duplicate position error(s) found.\")\n",
    "    return duplicate_count\n",
    "\n",
    "\n",
    "def check_duplicate_positions(import_rows, occupied_positions, label=\"Import vs Reference\"):\n",
    "    \"\"\"\n",
    "    Compares import rows against existing positions and raises errors for conflicts.\n",
    "\n",
    "    Args:\n",
    "        import_rows (List[Dict]): Rows from the import file\n",
    "        occupied_positions (Set[Tuple]): Set of existing (freezer, rack, box, pos)\n",
    "        label (str): Descriptive name for error reporting\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if duplicate positions are found\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    for i, row in enumerate(import_rows, start=2):\n",
    "        key = (\n",
    "            row.get(\"freezer\", \"\").strip(),\n",
    "            row.get(\"rack\", \"\").strip(),\n",
    "            row.get(\"box\", \"\").strip(),\n",
    "            row.get(\"tube_pos\", \"\").strip(),\n",
    "        )\n",
    "        if key in occupied_positions:\n",
    "            errors.append(f\"Row {i}: Position {key} is already occupied in reference data.\")\n",
    "\n",
    "    if errors:\n",
    "        raise ValueError(f\"{label} – {len(errors)} duplicate position error(s):\\n\" + \"\\n\".join(errors))\n",
    "    else:\n",
    "        print(f\"No duplicate positions found between import and reference data.\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "def check_internal_duplicates(rows, label):\n",
    "    \"\"\"\n",
    "    Checks for duplicate positions within a single file (usually the reference data).\n",
    "\n",
    "    Args:\n",
    "        rows (List[Dict]): Rows to check\n",
    "        label (str): Descriptive name for error output\n",
    "\n",
    "    Returns:\n",
    "        None – prints warning and exits if internal duplicates found\n",
    "    \"\"\"\n",
    "    position_map = {}\n",
    "\n",
    "    for i, row in enumerate(rows, start=2):  # row index starts from line 2\n",
    "        key = (\n",
    "            row.get(\"freezer\", \"\").strip(),\n",
    "            row.get(\"rack\", \"\").strip(),\n",
    "            row.get(\"box\", \"\").strip(),\n",
    "            row.get(\"tube_pos\", \"\").strip(),\n",
    "        )\n",
    "\n",
    "        if all(key):\n",
    "            position_map.setdefault(key, []).append(i)\n",
    "\n",
    "    # Look for positions used more than once\n",
    "    duplicates = {k: v for k, v in position_map.items() if len(v) > 1}\n",
    "    if duplicates:\n",
    "        details = \"\\n\".join([f\" - Position {k} found on rows {v}\" for k, v in duplicates.items()])\n",
    "        raise ValueError(f\"Duplicate positions found within {label}:\\n{details}\")\n",
    "    else:\n",
    "        print(f\"No duplicate positions found within {label}.\")\n",
    "        \n",
    "    return \n",
    "\n",
    "def check_internal_tube_id_duplicates(rows, label):\n",
    "    \"\"\"\n",
    "    Checks for duplicate tube_id values within a single dataset (e.g. the reference file).\n",
    "\n",
    "    Args:\n",
    "        rows (List[Dict]): Data rows to check\n",
    "        label (str): Name of the file being checked (for reporting)\n",
    "\n",
    "    Returns:\n",
    "        None – exits if duplicates are found\n",
    "    \"\"\"\n",
    "    tube_id_map = {}\n",
    "\n",
    "    for i, row in enumerate(rows, start=2):\n",
    "        tid = row.get(\"tube_id\", \"\").strip()\n",
    "        if tid:\n",
    "            tube_id_map.setdefault(tid, []).append(i)\n",
    "\n",
    "    duplicates = {tid: idxs for tid, idxs in tube_id_map.items() if len(idxs) > 1}\n",
    "\n",
    "    if duplicates:\n",
    "        print(f\"Duplicate tube_id(s) found in {label}:\")\n",
    "        for tid, idxs in duplicates.items():\n",
    "            print(f\" - tube_id '{tid}' appears in rows {idxs}\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(f\"All tube_id values in {label} are unique.\")\n",
    "\n",
    "def assign_redcap_ids(import_rows, reference_rows):\n",
    "    \n",
    "    \n",
    "    #### This is probably not necessary - because the study ID on recap will go!!!\n",
    "    \n",
    "    \"\"\"\n",
    "    Assigns REDCap record_id based on lab_id (patient ID).\n",
    "    If lab_id exists in reference, reuse the same REDCap ID.\n",
    "    If not, assign a new one (max ID + 1).\n",
    "    \n",
    "    ##this needs to be changed. The pat ID is the lokal ID of sophie. Wenn ich nur lab_id benutze \n",
    "    was macht dann die Zuordnung? Das ist wirklich tricky. \n",
    "\n",
    "    Args:\n",
    "        import_rows (List[Dict]): Rows to be imported\n",
    "        reference_rows (List[Dict]): Existing REDCap data\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[Dict], int]: Updated import_rows with assigned record_id, \n",
    "                                and number of new record_ids assigned\n",
    "    \"\"\"\n",
    "    pat_to_record = {}\n",
    "    existing_ids = set()\n",
    "\n",
    "    for row in reference_rows:\n",
    "        record_id = row.get(\"record_id\", \"\").strip()\n",
    "        lab_id = row.get(\"lab_id\", \"\").strip()\n",
    "        if record_id and lab_id:\n",
    "            pat_to_record[lab_id] = record_id\n",
    "            existing_ids.add(int(record_id))\n",
    "\n",
    "    next_record_id = max(existing_ids) + 1 if existing_ids else 1\n",
    "    new_ids_count = 0\n",
    "\n",
    "    for row in import_rows:\n",
    "        lab_id = row.get(\"lab_id\", \"\").strip()\n",
    "\n",
    "        if not lab_id:\n",
    "            print(\"Missing lab_id in import row.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        if lab_id in pat_to_record:\n",
    "            row[\"record_id\"] = pat_to_record[lab_id]\n",
    "        else:\n",
    "            row[\"record_id\"] = str(next_record_id)\n",
    "            pat_to_record[lab_id] = str(next_record_id)\n",
    "            next_record_id += 1\n",
    "            new_ids_count += 1\n",
    "\n",
    "    print(\"REDCap record_id assigned based on lab_id.\")\n",
    "    return import_rows, new_ids_count\n",
    "\n",
    "def is_position_occupied(freezer, rack, box, pos, occupied_positions):\n",
    "    \"\"\"\n",
    "    Validates the position and checks if it is occupied.\n",
    "\n",
    "    Args:\n",
    "        freezer (str): Freezer number or name (e.g. \"1\", \"2\", \"nitrogen\")\n",
    "        rack (str): Rack number (1–100)\n",
    "        box (str): Box number (1–100)\n",
    "        pos (str): Position (e.g., A1–H12)\n",
    "        occupied_positions (Set[Tuple[str, str, str, str]]): Known used positions\n",
    "\n",
    "    Returns:\n",
    "        bool: True if occupied, False if available\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If input values are invalid\n",
    "    \"\"\"\n",
    "\n",
    "    freezer = str(freezer).strip()\n",
    "    rack = str(rack).strip()\n",
    "    box = str(box).strip()\n",
    "    pos = str(pos).strip().upper()\n",
    "\n",
    "    valid_freezers = {\"1\", \"2\", \"3\", \"nitrogen\"}\n",
    "    if freezer not in valid_freezers:\n",
    "        raise ValueError(f\"Invalid freezer: '{freezer}' (must be 1, 2, 3, or nitrogen)\")\n",
    "\n",
    "    if not rack.isdigit() or not (1 <= int(rack) <= 100):\n",
    "        raise ValueError(f\"Invalid rack: '{rack}' (must be integer 1–100)\")\n",
    "\n",
    "    if not box.isdigit() or not (1 <= int(box) <= 100):\n",
    "        raise ValueError(f\"Invalid box: '{box}' (must be integer 1–100)\")\n",
    "\n",
    "    if not re.match(r\"^[A-H](?:[1-9]|1[0-2])$\", pos):\n",
    "        raise ValueError(f\"Invalid position: '{pos}' (must be A1–H12)\")\n",
    "\n",
    "    key = (freezer, rack, box, pos)\n",
    "    return key in occupied_positions\n",
    "\n",
    "from datetime import datetime\n",
    "'''\n",
    "def write_report(filename, import_file, reference_file, import_rows, duplicate_positions_count): #new_ids_count ist aktuell nicht dabei\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Biorepository Data Validation Report\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\\n\")\n",
    "        f.write(\"Input files:\\n\")\n",
    "        f.write(f\" - Import: {import_file}\\n\")\n",
    "        f.write(f\" - Reference: {reference_file}\\n\\n\")\n",
    "        f.write(\"Summary:\\n\")\n",
    "        f.write(f\" - Number of import rows processed: {len(import_rows)}\\n\")\n",
    "        #f.write(f\" - Number of new lab_ids added: {new_ids_count}\\n\")\n",
    "        f.write(f\" - Number of duplicate positions found: {duplicate_positions_count}\\n\")\n",
    "        record_ids = [int(row[\"record_id\"]) for row in import_rows if \"record_id\" in row]\n",
    "        if record_ids:\n",
    "            f.write(f\" - Assigned record_id range: {min(record_ids)} to {max(record_ids)}\\n\")\n",
    "        f.write(\"\\nWarnings / Errors:\\n\")\n",
    "        f.write(\" - None\\n\\n\")\n",
    "        f.write(\"Validation completed successfully!\\n\")\n",
    "'''    \n",
    "        \n",
    "from datetime import datetime\n",
    "\n",
    "def write_report(filename, import_file, reference_file, import_rows, success, error_message=None):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Biorepository Data Validation Report\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\\n\")\n",
    "        f.write(\"Input files:\\n\")\n",
    "        f.write(f\" - Import: {import_file}\\n\")\n",
    "        f.write(f\" - Reference: {reference_file}\\n\\n\")\n",
    "\n",
    "        if success:\n",
    "            f.write(\"✅ Validation completed successfully.\\n\")\n",
    "            f.write(\"Recommendation: Safe to upload to REDCap.\\n\")\n",
    "        else:\n",
    "            f.write(\"❌ Validation failed.\\n\")\n",
    "            f.write(\"Error details:\\n\")\n",
    "            f.write(error_message + \"\\n\\n\")\n",
    "            f.write(\"Recommendation: Do NOT upload to REDCap.\\n\")\n",
    "            \n",
    "            \n",
    "\n",
    "            from datetime import datetime\n",
    "\n",
    "def write_report(filename, import_file, reference_file, import_rows=None,\n",
    "                 errors=None, recommendation=None):\n",
    "    \"\"\"\n",
    "    Writes a validation report to a text file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to save the report\n",
    "        import_file (str): Path to import CSV\n",
    "        reference_file (str): Path to reference CSV\n",
    "        import_rows (List[Dict], optional): Imported rows, for summary stats\n",
    "        errors (List[str], optional): List of error messages collected\n",
    "        recommendation (str, optional): Recommendation to upload or not\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Biorepository Data Validation Report\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "\n",
    "        f.write(\"Input files:\\n\")\n",
    "        f.write(f\" - Import: {import_file}\\n\")\n",
    "        f.write(f\" - Reference: {reference_file}\\n\\n\")\n",
    "\n",
    "        # Summary\n",
    "        f.write(\"Summary:\\n\")\n",
    "        if import_rows:\n",
    "            f.write(f\" - Number of import rows processed: {len(import_rows)}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        # Errors\n",
    "        f.write(\"Errors / Warnings:\\n\")\n",
    "        if errors and len(errors) > 0:\n",
    "            for e in errors:\n",
    "                f.write(f\" - {e}\\n\")\n",
    "        else:\n",
    "            f.write(\" - None\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        # Recommendation\n",
    "        f.write(\"Recommendation:\\n\")\n",
    "        if recommendation:\n",
    "            f.write(f\"{recommendation}\\n\")\n",
    "        else:\n",
    "            f.write(\"No recommendation provided.\\n\")\n",
    "\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "def download_reference_from_redcap(api_url, api_token, form_name=\"biorepository\"):\n",
    "    \"\"\"\n",
    "    Downloads reference data directly from REDCap via API.\n",
    "\n",
    "    Args:\n",
    "        api_url (str): The REDCap API endpoint URL\n",
    "        api_token (str): Your REDCap API token\n",
    "        form_name (str): The name of the REDCap instrument to export\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of flat REDCap records\n",
    "    \"\"\"\n",
    "\n",
    "    data = {\n",
    "        'token': api_token,\n",
    "        'content': 'record',\n",
    "        'format': 'json',\n",
    "        'type': 'flat',\n",
    "        'forms[0]': form_name,\n",
    "        'rawOrLabel': 'raw',\n",
    "        'rawOrLabelHeaders': 'raw',\n",
    "        'exportSurveyFields': 'true',\n",
    "        'exportDataAccessGroups': 'true'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(api_url, data=data, timeout=20)\n",
    "\n",
    "        # API communication errors\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"REDCap API returned status code {response.status_code}: {response.text}\")\n",
    "\n",
    "        # JSON decode errors \n",
    "        try:\n",
    "            records = response.json()\n",
    "        except Exception:\n",
    "            raise Exception(\"Could not decode JSON returned from REDCap. Response was:\\n\" + response.text)\n",
    "\n",
    "        if not isinstance(records, list):\n",
    "            raise Exception(\"Unexpected API response format. Expected list of records.\")\n",
    "\n",
    "        print(f\"Successfully downloaded {len(records)} records from REDCap.\")\n",
    "        return records\n",
    "\n",
    "    except requests.exceptions.ConnectTimeout:\n",
    "        raise Exception(\"Connection timed out while contacting REDCap API.\")\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        raise Exception(\"Could not connect to REDCap. Check VPN, URL, or internet.\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"REDCap API error: {str(e)}\")\n",
    "\n",
    "\n",
    "def save_reference_as_csv(records, out_path):\n",
    "    if not records:\n",
    "        raise Exception(\"No records to write.\")\n",
    "\n",
    "    keys = sorted(records[0].keys())\n",
    "\n",
    "    with open(out_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(records)\n",
    "\n",
    "    print(f\"Reference data saved to {out_path}\")\n",
    "    \n",
    "    \n",
    "def build_patient_map(reference_rows):\n",
    "    \"\"\"\n",
    "    Builds study_id → lab_patient_id mapping from REDCap reference data.\n",
    "    \n",
    "    study_to_lab \n",
    "    \n",
    "    Args:\n",
    "        refernce_rows: records form Reference Dataset. Usually csv file.\n",
    "\n",
    "    Returns:\n",
    "        study_to_lab List[Dict]: Mapping from study_id -> pat_id\n",
    "        lab_to_study List[Dict]: Mapping from lab_id -> study_id\n",
    "        used_lab_ids: list of used lab ids. \n",
    "    \"\"\"\n",
    "\n",
    "    study_to_lab = {}\n",
    "    lab_to_study = {}\n",
    "    used_lab_ids = set()\n",
    "\n",
    "    for row in reference_rows:\n",
    "        study_id = row.get(\"study_id\", \"\").strip()\n",
    "        lab_id = row.get(\"lab_id\", \"\").strip()\n",
    "\n",
    "        if not study_id or not lab_id:\n",
    "            continue\n",
    "         \n",
    "        if study_id in study_to_lab and study_to_lab[study_id] != lab_id:\n",
    "            raise Exception(f\"Study ID {study_id} has multiple lab IDs.\")\n",
    "\n",
    "        if lab_id in lab_to_study and lab_to_study[lab_id] != study_id:\n",
    "            raise Exception(f\"Lab ID {lab_id} is linked to multiple study IDs.\")\n",
    "\n",
    "        lab_to_study[lab_id] = study_id\n",
    "        study_to_lab[study_id] = lab_id\n",
    "        used_lab_ids.add(int(lab_id))\n",
    "\n",
    "    return study_to_lab, lab_to_study, used_lab_ids\n",
    "\n",
    "def get_next_lab_patient_id(used_lab_ids):\n",
    "    if not used_lab_ids:\n",
    "        return 1\n",
    "    return max(used_lab_ids) + 1\n",
    "\n",
    "def assign_lab_patient_ids(import_rows, reference_rows):\n",
    "    \"\"\"\n",
    "    Assigns lab_id based on study_id and reference data. The lab id does not need to be plugged in; \n",
    "    BioVal finds the last lab id in the reference data and automatically asigns to the to be importated\n",
    "    data the new lab id. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    study_to_lab, lab_to_study, used_lab_ids = build_patient_map(reference_rows)\n",
    "    next_id = get_next_lab_patient_id(used_lab_ids)\n",
    "\n",
    "    for i, row in enumerate(import_rows, start=2):\n",
    "        study_id = row.get(\"study_id\", \"\").strip()\n",
    "\n",
    "        if not study_id:\n",
    "            raise Exception(f\"Row {i}: Missing study_id\")\n",
    "\n",
    "        if not STUDY_ID_PATTERN.match(study_id):\n",
    "            raise Exception(f\"Row {i}: Invalid study_id format '{study_id}'\")\n",
    "\n",
    "        if study_id in study_to_lab:\n",
    "            row[\"lab_patient_id\"] = study_to_lab[study_id]\n",
    "        else:\n",
    "            lab_id = f\"{next_id:05d}\"\n",
    "            row[\"lab_patient_id\"] = lab_id\n",
    "            study_to_lab[study_id] = lab_id\n",
    "            used_lab_ids.add(next_id)\n",
    "            next_id += 1\n",
    "\n",
    "    return import_rows\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28401aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded 7 records from REDCap.\n",
      "Reference data saved to /home/aaron/Desktop/BioVal/data/Ref_file_test.csv\n"
     ]
    }
   ],
   "source": [
    "#downloads Biorep\n",
    "api_url = \"https://redcap.uni-heidelberg.de/api/\"\n",
    "api_token = \"19C2091A845FCAB1954F79E7F1A44374\"\n",
    "records = download_reference_from_redcap(api_url, api_token)\n",
    "\n",
    "save_reference_as_csv(records, \"/home/aaron/Desktop/BioVal/data/Ref_file_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d85525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({}, set())"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, ref_rows = read_csv(\"/home/aaron/Desktop/BioVal/data/Ref_file_test.csv\")\n",
    "build_patient_map(ref_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4753578a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'accession_nr': '',\n",
       "  'biomaterial': '',\n",
       "  'biorepository_complete': '0',\n",
       "  'box': '2',\n",
       "  'box_id': '200',\n",
       "  'cell_number': '',\n",
       "  'cohort': '',\n",
       "  'comment': '',\n",
       "  'date_received': '',\n",
       "  'extern_processed': '',\n",
       "  'extraction': '',\n",
       "  'extraction_time': '',\n",
       "  'fasting': '',\n",
       "  'fibro_passage': '',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'freezer': '1',\n",
       "  'lab_id': '',\n",
       "  'processed': '',\n",
       "  'processing_time': '',\n",
       "  'rack': '1',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'study': '',\n",
       "  'study_id': '1',\n",
       "  'study_visit': '',\n",
       "  'thaw_date': '',\n",
       "  'tube_id': '2345',\n",
       "  'tube_pos': '',\n",
       "  'virus_diag': '',\n",
       "  'volume': ''},\n",
       " {'accession_nr': '',\n",
       "  'biomaterial': '',\n",
       "  'biorepository_complete': '0',\n",
       "  'box': '1',\n",
       "  'box_id': '1',\n",
       "  'cell_number': '',\n",
       "  'cohort': '',\n",
       "  'comment': '',\n",
       "  'date_received': '',\n",
       "  'extern_processed': '',\n",
       "  'extraction': '',\n",
       "  'extraction_time': '',\n",
       "  'fasting': '',\n",
       "  'fibro_passage': '',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'freezer': '1',\n",
       "  'lab_id': '',\n",
       "  'processed': '',\n",
       "  'processing_time': '',\n",
       "  'rack': '1',\n",
       "  'redcap_event_name': 'baseline_arm_1',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'study': '',\n",
       "  'study_id': '1',\n",
       "  'study_visit': '',\n",
       "  'thaw_date': '',\n",
       "  'tube_id': '23456',\n",
       "  'tube_pos': '',\n",
       "  'virus_diag': '',\n",
       "  'volume': ''},\n",
       " {'accession_nr': '',\n",
       "  'biomaterial': '',\n",
       "  'biorepository_complete': '0',\n",
       "  'box': '2',\n",
       "  'box_id': '200',\n",
       "  'cell_number': '',\n",
       "  'cohort': '',\n",
       "  'comment': '',\n",
       "  'date_received': '',\n",
       "  'extern_processed': '',\n",
       "  'extraction': '',\n",
       "  'extraction_time': '',\n",
       "  'fasting': '',\n",
       "  'fibro_passage': '',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'freezer': '1',\n",
       "  'lab_id': '',\n",
       "  'processed': '',\n",
       "  'processing_time': '',\n",
       "  'rack': '1',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'study': '',\n",
       "  'study_id': '2',\n",
       "  'study_visit': '',\n",
       "  'thaw_date': '',\n",
       "  'tube_id': '2345',\n",
       "  'tube_pos': '',\n",
       "  'virus_diag': '',\n",
       "  'volume': ''},\n",
       " {'accession_nr': '',\n",
       "  'biomaterial': '',\n",
       "  'biorepository_complete': '0',\n",
       "  'box': '1',\n",
       "  'box_id': '1',\n",
       "  'cell_number': '',\n",
       "  'cohort': '',\n",
       "  'comment': '',\n",
       "  'date_received': '',\n",
       "  'extern_processed': '',\n",
       "  'extraction': '',\n",
       "  'extraction_time': '',\n",
       "  'fasting': '',\n",
       "  'fibro_passage': '',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'freezer': '1',\n",
       "  'lab_id': '',\n",
       "  'processed': '',\n",
       "  'processing_time': '',\n",
       "  'rack': '1',\n",
       "  'redcap_event_name': 'baseline_arm_1',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'study': '',\n",
       "  'study_id': '2',\n",
       "  'study_visit': '',\n",
       "  'thaw_date': '',\n",
       "  'tube_id': '23333',\n",
       "  'tube_pos': '',\n",
       "  'virus_diag': '',\n",
       "  'volume': ''},\n",
       " {'accession_nr': '',\n",
       "  'biomaterial': '',\n",
       "  'biorepository_complete': '0',\n",
       "  'box': '1',\n",
       "  'box_id': '1',\n",
       "  'cell_number': '',\n",
       "  'cohort': '',\n",
       "  'comment': '',\n",
       "  'date_received': '',\n",
       "  'extern_processed': '',\n",
       "  'extraction': '',\n",
       "  'extraction_time': '',\n",
       "  'fasting': '',\n",
       "  'fibro_passage': '',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'freezer': '1',\n",
       "  'lab_id': '',\n",
       "  'processed': '',\n",
       "  'processing_time': '',\n",
       "  'rack': '1',\n",
       "  'redcap_event_name': 'follow_up_arm_1',\n",
       "  'redcap_repeat_instance': '1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'study': '',\n",
       "  'study_id': '2',\n",
       "  'study_visit': '',\n",
       "  'thaw_date': '',\n",
       "  'tube_id': '45677',\n",
       "  'tube_pos': '',\n",
       "  'virus_diag': '',\n",
       "  'volume': ''},\n",
       " {'accession_nr': '',\n",
       "  'biomaterial': '',\n",
       "  'biorepository_complete': '0',\n",
       "  'box': '1',\n",
       "  'box_id': '1',\n",
       "  'cell_number': '',\n",
       "  'cohort': '',\n",
       "  'comment': '',\n",
       "  'date_received': '',\n",
       "  'extern_processed': '',\n",
       "  'extraction': '',\n",
       "  'extraction_time': '',\n",
       "  'fasting': '',\n",
       "  'fibro_passage': '',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'freezer': '1',\n",
       "  'lab_id': '',\n",
       "  'processed': '',\n",
       "  'processing_time': '',\n",
       "  'rack': '1',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'study': '',\n",
       "  'study_id': '3',\n",
       "  'study_visit': '',\n",
       "  'thaw_date': '',\n",
       "  'tube_id': '1223456',\n",
       "  'tube_pos': '',\n",
       "  'virus_diag': '',\n",
       "  'volume': ''},\n",
       " {'accession_nr': '',\n",
       "  'biomaterial': '',\n",
       "  'biorepository_complete': '0',\n",
       "  'box': '1',\n",
       "  'box_id': '1',\n",
       "  'cell_number': '',\n",
       "  'cohort': '',\n",
       "  'comment': '',\n",
       "  'date_received': '',\n",
       "  'extern_processed': '',\n",
       "  'extraction': '',\n",
       "  'extraction_time': '',\n",
       "  'fasting': '',\n",
       "  'fibro_passage': '',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'freezer': '1',\n",
       "  'lab_id': '',\n",
       "  'processed': '',\n",
       "  'processing_time': '',\n",
       "  'rack': '1',\n",
       "  'redcap_event_name': 'follow_up_arm_1',\n",
       "  'redcap_repeat_instance': '1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'study': '',\n",
       "  'study_id': '3',\n",
       "  'study_visit': '',\n",
       "  'thaw_date': '',\n",
       "  'tube_id': '56454',\n",
       "  'tube_pos': '',\n",
       "  'virus_diag': '',\n",
       "  'volume': ''}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20699e7e",
   "metadata": {},
   "source": [
    "# RUN IT Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72176f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# die beispiele funktionieren aufgrund der anderen datenstruktur nicht mehr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "59f7f1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checking Import file: /home/aaron/Desktop/BioVal/data/NDEGTest_import_file_double_position.csv\n",
      " Import file passed all validation checks.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'study_id': '1',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'lab_id': '124 123 4ll',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': 'CSF',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': 'A1',\n",
       "  'tube_id': '2345',\n",
       "  'box_id': '',\n",
       "  'box': '1',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '',\n",
       "  '': '0'},\n",
       " {'study_id': '2',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'lab_id': '111 111 111',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': 'Serum',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': 'A2',\n",
       "  'tube_id': '12234',\n",
       "  'box_id': '',\n",
       "  'box': '1',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '',\n",
       "  '': '0'}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate test data\n",
    "validate_file(\"/home/aaron/Desktop/BioVal/data/NDEGTest_import_file_double_position.csv\", \"Import file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b41270f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, import_rows = read_csv(\"/home/aaron/Desktop/BioVal/data/NDEGTest_import_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "25bbe540",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ref_rows = read_csv(\"/home/aaron/Desktop/BioVal/data/Biorepository_ref_file_2026-01-10_1511.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5af9ed53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checking Import file: /home/aaron/Desktop/BioVal/data/NDEGTest_import_file.csv\n",
      " Import file passed all validation checks.\n",
      "\n",
      " Checking data file: /home/aaron/Desktop/BioVal/data/Biorepository_ref_file_2026-01-10_1511.csv\n",
      " data file passed all validation checks.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'study_id': '222-222-222',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'lab_id': '1',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': '',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': '',\n",
       "  'tube_id': '2345',\n",
       "  'box_id': '200',\n",
       "  'box': '2',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'study_id': '222-222-222',\n",
       "  'redcap_event_name': 'baseline_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'lab_id': '1',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': '',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': '',\n",
       "  'tube_id': '23456',\n",
       "  'box_id': '1',\n",
       "  'box': '1',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'study_id': '333-333-333',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'lab_id': '2',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': '',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': '',\n",
       "  'tube_id': '11111',\n",
       "  'box_id': '200',\n",
       "  'box': '2',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'study_id': '333-333-333',\n",
       "  'redcap_event_name': 'baseline_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'lab_id': '2',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': '',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': '',\n",
       "  'tube_id': '23333',\n",
       "  'box_id': '1',\n",
       "  'box': '1',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'study_id': '333-333-333',\n",
       "  'redcap_event_name': 'follow_up_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '1',\n",
       "  'lab_id': '2',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': '',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': '',\n",
       "  'tube_id': '45677',\n",
       "  'box_id': '1',\n",
       "  'box': '1',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'study_id': '444-444-444',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'lab_id': '3',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': '',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': '',\n",
       "  'tube_id': '1223456',\n",
       "  'box_id': '1',\n",
       "  'box': '1',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '0'},\n",
       " {'study_id': '444-444-444',\n",
       "  'redcap_event_name': 'follow_up_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '1',\n",
       "  'lab_id': '3',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': '',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': '',\n",
       "  'tube_id': '56454',\n",
       "  'box_id': '1',\n",
       "  'box': '1',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '0'}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_file(\"/home/aaron/Desktop/BioVal/data/NDEGTest_import_file.csv\", \"Import file\")\n",
    "validate_file(\"/home/aaron/Desktop/BioVal/data/Biorepository_ref_file_2026-01-10_1511.csv\", \"data file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a32c9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate positions found within data file.\n",
      "All tube_id values in Reference data file are unique.\n"
     ]
    }
   ],
   "source": [
    "check_internal_duplicates(ref_rows, \"data file\")\n",
    "check_internal_tube_id_duplicates(ref_rows, \"Reference data file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "275fd2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDCap record_id assigned based on lab_id.\n"
     ]
    }
   ],
   "source": [
    "import_rows, account_id = assign_redcap_ids(import_rows, ref_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c1dca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate positions found between import and reference data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occupied = get_occupied_positions(ref_rows)\n",
    "check_duplicate_positions(import_rows, occupied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "23ed5690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position (1, 1, 1, G1) is free. \n"
     ]
    }
   ],
   "source": [
    "occupied = get_occupied_positions(ref_rows)\n",
    "\n",
    "# Check a specific position manually\n",
    "freezer = \"1\"\n",
    "rack = \"1\"\n",
    "box = \"1\"\n",
    "pos = \"G1\"\n",
    "\n",
    "if is_position_occupied(freezer, rack, box, pos, occupied):\n",
    "    print(f\"Position ({freezer}, {rack}, {box}, {pos}) is already occupied. Please try another one.\")\n",
    "else:\n",
    "    print(f\"Position ({freezer}, {rack}, {box}, {pos}) is free. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd8a3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "map1,map2, used_lab_ids = build_patient_map(ref_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c7b1bb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_lab_patient_id(used_lab_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b9d0ffe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'study_id': '111-111-111',\n",
       "  'redcap_event_name': 'screening_arm_1',\n",
       "  'redcap_repeat_instrument': '',\n",
       "  'redcap_repeat_instance': '',\n",
       "  'lab_id': '1',\n",
       "  'cohort': '',\n",
       "  'study': '',\n",
       "  'study_visit': '',\n",
       "  'fasting': '',\n",
       "  'extraction_time': '',\n",
       "  'extraction': '',\n",
       "  'processing_time': '',\n",
       "  'processed': '',\n",
       "  'extern_processed': '',\n",
       "  'date_received': '',\n",
       "  'biomaterial': 'CSF',\n",
       "  'volume': '',\n",
       "  'cell_number': '',\n",
       "  'tube_pos': 'A12',\n",
       "  'tube_id': '2345',\n",
       "  'box_id': '1',\n",
       "  'box': '1',\n",
       "  'rack': '1',\n",
       "  'freezer': '1',\n",
       "  'freeze_date': '',\n",
       "  'freeze_time': '',\n",
       "  'fibro_passage': '',\n",
       "  'virus_diag': '',\n",
       "  'thaw_date': '',\n",
       "  'sent_date': '',\n",
       "  'sent_project': '',\n",
       "  'reserved_date': '',\n",
       "  'reserved_for': '',\n",
       "  'accession_nr': '',\n",
       "  'comment': '',\n",
       "  'biorepository_complete': '',\n",
       "  '': '0',\n",
       "  'record_id': '1',\n",
       "  'lab_patient_id': '00004'}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returns the import rows with new assigned lab ID\n",
    "assign_lab_patient_ids(import_rows,ref_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07442fb3",
   "metadata": {},
   "source": [
    "# GUI - BioVal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01af74c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk  # Pillow muss installiert sein: pip install pillow\n",
    "\n",
    "def run_validation():\n",
    "    import_path = filedialog.askopenfilename(title=\"Select Import CSV\")\n",
    "    #ref_path = filedialog.askopenfilename(title=\"Select Reference CSV\")\n",
    "    \n",
    "    if not import_path or not ref_path:\n",
    "        messagebox.showerror(\"Error\", \"Both files must be selected.\")\n",
    "        return\n",
    "    \n",
    "    errors = []\n",
    "\n",
    "    try:\n",
    "        validate_file(import_path, \"Import file\")\n",
    "    except ValueError as e:\n",
    "        errors.append(str(e))\n",
    "        \n",
    "    try:\n",
    "        reference_rows = download_reference_from_redcap(api_url, api_token)\n",
    "        ref_path = \"/home/aaron/Desktop/BioVal/data/Ref_file_test.csv\"\n",
    "        save_reference_as_csv(records,ref_path)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"API Error\", str(e))\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        validate_file(ref_path, \"Reference file\")\n",
    "    except ValueError as e:\n",
    "        errors.append(str(e))\n",
    "\n",
    "    try:\n",
    "        check_internal_duplicates(read_csv(import_path)[1], \"Import file\")\n",
    "    except ValueError as e:\n",
    "        errors.append(str(e))\n",
    "\n",
    "    try:\n",
    "        check_internal_duplicates(read_csv(ref_path)[1], \"Reference file\")\n",
    "    except ValueError as e:\n",
    "        errors.append(str(e))\n",
    "\n",
    "    try:\n",
    "        occupied_pos = get_occupied_positions(read_csv(ref_path)[1])\n",
    "        duplicate_positions_count = check_duplicate_positions(\n",
    "            read_csv(import_path)[1], occupied_pos)\n",
    "    except ValueError as e:\n",
    "        errors.append(str(e))\n",
    "    print(errors)\n",
    "    # === Decide what to do based on errors ===\n",
    "    if errors:\n",
    "        recommendation = \"❌ No upload. Errors must be fixed first.\"\n",
    "    else:\n",
    "        recommendation = \"✅ Upload safe.\"\n",
    "\n",
    "    report_path = filedialog.asksaveasfilename(\n",
    "        defaultextension=\".txt\",\n",
    "        filetypes=[(\"Text files\", \"*.txt\")],\n",
    "        title=\"Save Validation Report As\"\n",
    "    )\n",
    "    if report_path:\n",
    "        write_report(report_path, import_path, ref_path, read_csv(import_path)[1] , errors, recommendation)\n",
    "        messagebox.showinfo(\"Report\", f\"Report saved at {report_path}\")\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "# --- GUI Setup ---\n",
    "root = tk.Tk()\n",
    "root.title(\"BioVal – Biorepository Validator\")\n",
    "root.geometry(\"600x400\")\n",
    "\n",
    "main_frame = ttk.Frame(root, padding=20)\n",
    "main_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "# --- Optional Image ---\n",
    "try:\n",
    "    img = Image.open(\"logo.jpeg\")  # <-- Dein Bildpfad\n",
    "    img = img.resize((150, 150))\n",
    "    photo = ImageTk.PhotoImage(img)\n",
    "    logo_label = ttk.Label(main_frame, image=photo)\n",
    "    logo_label.image = photo\n",
    "    logo_label.pack(pady=(0, 10))\n",
    "except Exception:\n",
    "    print(\"No image found – skipping logo.\")\n",
    "\n",
    "# --- Welcome Text ---\n",
    "welcome = ttk.Label(\n",
    "    main_frame,\n",
    "    text=(\n",
    "        \"Welcome to BioVal!\\n\\n\"\n",
    "        \"This tool helps you validate biorepository REDCap import files.\\n\"\n",
    "        \"You’ll be prompted to select:\\n\"\n",
    "        \" - A new import CSV file\\n - the data you want to upload\"\n",
    "        \" - A reference dataset for comparison - the data already stored in RedCap \\n\\n\"\n",
    "        \"The tool checks patient IDs, sample positions, and generates a report.\"\n",
    "    ),\n",
    "    justify=\"center\",\n",
    "    wraplength=500\n",
    ")\n",
    "welcome.pack(pady=10)\n",
    "\n",
    "# --- Start Button ---\n",
    "start_button = ttk.Button(main_frame, text=\"Run Validation\", command=run_validation)\n",
    "start_button.pack(pady=20)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b25174c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded 7 records from REDCap.\n",
      "Reference data saved to /home/aaron/Desktop/BioVal/data/Ref_file_test.csv\n",
      " Checking Import file: /home/aaron/Desktop/BioVal/data/NDEGTest_import_file.csv\n",
      " Import file passed all validation checks.\n",
      "\n",
      " Checking Reference data: /home/aaron/Desktop/BioVal/data/Ref_file_test.csv\n",
      " Reference data passed all validation checks.\n",
      "\n",
      "No duplicate positions found within Import file.\n",
      "No duplicate positions found within Reference date.\n",
      "No duplicate positions found between import and reference data.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk  # Pillow muss installiert sein: pip install pillow\n",
    "\n",
    "### aktuell ist der download mit eingeschlossen; \n",
    "### das ref file ist aufgrund der falschen Dateneingabe auf Redcap\n",
    "### fehlerhaft, deswegen kommt noch eine Fehlermeldung\n",
    "\n",
    "def run_validation():\n",
    "    import_path = filedialog.askopenfilename(title=\"Select Import CSV\")\n",
    "    #ref_path = filedialog.askopenfilename(title=\"Select Reference CSV\")\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    try:\n",
    "        # Beispiel: CSV lesen & validieren (Funktionen müssen definiert sein)\n",
    "        reference_rows = download_reference_from_redcap(api_url, api_token)\n",
    "        ref_path = \"/home/aaron/Desktop/BioVal/data/Ref_file_test.csv\"\n",
    "        save_reference_as_csv(records,ref_path)\n",
    "        _, import_rows = read_csv(import_path)\n",
    "        _, ref_rows = read_csv(ref_path)\n",
    "        #Check if either of the files have not the required fields and structure\n",
    "        validate_file(import_path, \"Import file\")\n",
    "        validate_file(ref_path, \"Reference data\")\n",
    "        #Check if they have internal dublicates\n",
    "        check_internal_duplicates(import_rows, \"Import file\")\n",
    "        check_internal_duplicates(ref_rows,\"Reference date\")\n",
    "        #Die Red cap ID function muss geändert werden, wegen PaTID da brauchen wir aber das Gespräch mit Rebecca\n",
    "        #import_rows, new_ids_count = assign_redcap_ids(import_rows, ref_rows)\n",
    "        #Die Funktion macht nicht was sie soll.\n",
    "        occupied_pos = get_occupied_positions(ref_rows)\n",
    "        duplicate_positions_count = check_duplicate_positions(import_rows, occupied_pos)\n",
    "\n",
    "        # Bericht speichern\n",
    "        report_path = filedialog.asksaveasfilename(\n",
    "            defaultextension=\".txt\",\n",
    "            filetypes=[(\"Text files\", \"*.txt\")],\n",
    "            title=\"Save Validation Report As\"\n",
    "        )\n",
    "        if report_path:\n",
    "            #Write report . \n",
    "            write_report(report_path, import_path, ref_path, import_rows, duplicate_positions_count) #new_ids_count ist weg\n",
    "            messagebox.showinfo(\"Success\", f\"Validation completed!\\nReport saved at:\\n{report_path}\")\n",
    "        else:\n",
    "            messagebox.showinfo(\"Success\", \"Validation completed! No report was saved.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Validation Error\", str(e))\n",
    "\n",
    "\n",
    "# --- GUI Setup ---\n",
    "root = tk.Tk()\n",
    "root.title(\"BioVal – Biorepository Validator\")\n",
    "root.geometry(\"600x400\")\n",
    "\n",
    "main_frame = ttk.Frame(root, padding=20)\n",
    "main_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "# --- Optional Image ---\n",
    "try:\n",
    "    img = Image.open(\"logo.jpeg\")  # <-- Dein Bildpfad\n",
    "    img = img.resize((150, 150))\n",
    "    photo = ImageTk.PhotoImage(img)\n",
    "    logo_label = ttk.Label(main_frame, image=photo)\n",
    "    logo_label.image = photo\n",
    "    logo_label.pack(pady=(0, 10))\n",
    "except Exception:\n",
    "    print(\"No image found – skipping logo.\")\n",
    "\n",
    "# --- Welcome Text ---\n",
    "welcome = ttk.Label(\n",
    "    main_frame,\n",
    "    text=(\n",
    "        \"Welcome to BioVal!\\n\\n\"\n",
    "        \"This tool helps you validate biorepository REDCap import files.\\n\"\n",
    "        \"You’ll be prompted to select:\\n\"\n",
    "        \" - A new import CSV file\\n - the data you want to upload\"\n",
    "        \" - A reference dataset for comparison - the data already stored in RedCap \\n\\n\"\n",
    "        \"The tool checks patient IDs, sample positions, and generates a report.\"\n",
    "    ),\n",
    "    justify=\"center\",\n",
    "    wraplength=500\n",
    ")\n",
    "welcome.pack(pady=10)\n",
    "\n",
    "# --- Start Button ---\n",
    "start_button = ttk.Button(main_frame, text=\"Run Validation\", command=run_validation)\n",
    "start_button.pack(pady=20)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed1a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
